{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e5af1c-5abe-4448-b946-7fbf802d7b7e",
   "metadata": {},
   "source": [
    "# Workshop 3: Building AI Agents\n",
    "\n",
    "To recall what we did last week:\n",
    "- Learned about how LLMs work at a high level\n",
    "- Explored a few prompt engineering techniques\n",
    "- Explored some ways we can get structured output from LLMs\n",
    "- We had a few exercises on prompting, structured data extraction and tool selection\n",
    "\n",
    "Today:\n",
    "- We will code our way up to AI Agents and to a definition of what an \"Agent\" is\n",
    "- Discuss differences between workflows and agents\n",
    "- Identify building blocks for our Analytics agent\n",
    "- Hopefully add a functionality to explore the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b816204-859b-4106-8a01-5fa061aa5cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP & IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def generate(prompt, temperature=0):\n",
    "    \"\"\"Generate text using OpenAI's API\"\"\"\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc0c5b8-8177-487e-bfce-829d18d1f971",
   "metadata": {},
   "source": [
    "First, let's look at the following query:\n",
    "\n",
    "```\"What is 1234 * 5678?\"```\n",
    "\n",
    "The correct answer to that is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7760e877-f8af-49a7-8635-b4b73e9887f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7006652"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1234 * 5678"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df14b1cd-8e90-4ab8-b7f9-d1b538ffe236",
   "metadata": {},
   "source": [
    "**Let's see if a LLM can actually answer that accurately.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3042c05-8cc4-412c-b4ca-a3959bb7ebe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóíÔ∏è Prompt: What is 1234 * 5678? Please respond in the format number1 * number2 = product\n",
      "ü§ñ LLM says: 1234 * 5678 = 700665\n",
      "‚úÖ Actual answer: 7006652\n",
      "‚ùå Difference: 6305987\n"
     ]
    }
   ],
   "source": [
    "num1 = 1234\n",
    "num2 = 5678\n",
    "\n",
    "# Ask the LLM to calculate\n",
    "prompt = f\"What is {num1} * {num2}? Please respond in the format number1 * number2 = product\"\n",
    "llm_response = generate(prompt)\n",
    "\n",
    "print(f\"üóíÔ∏è Prompt: {prompt}\")\n",
    "print(f\"ü§ñ LLM says: {llm_response}\")\n",
    "print(f\"‚úÖ Actual answer: {num1 * num2}\")\n",
    "llm_answer = llm_response.split(\"=\")[1].strip()\n",
    "print(f\"‚ùå Difference: {abs(int(llm_answer.replace(',', '').replace(' ', '')) - (num1 * num2))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349970d4-7769-4d35-8c02-e0fa30c9d2ce",
   "metadata": {},
   "source": [
    "### What's going on?\n",
    "If we recall from the last workshop, LLMs are exactly what their name says, they are Language Models - they are trained to predict the next token (word/piece of text).\n",
    "\n",
    "So when asked `What is 1234 * 5678?`, tt's not actually multiplying the numbers - it's predicting what tokens are most likely to follow.\n",
    "\n",
    "The model has seen millions of examples like \"1200 √ó 5000 = 6000000\" and \"1300 √ó 6000 = 7800000\" during its training stage, so when it sees \"1234 √ó 5678\", it predicts the answer should \"look like\" something around 7 million. That's why it guessed \"700665\" - similar, but completely wrong value (actual: 7006652).\n",
    "\n",
    "**The key point:** LLMs learned what math looks like from its training data, but never learned the multiplication algorithm itself. It's the difference between memorizing \"2 √ó 2 = 4\" versus understanding that multiplication is repeated addition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a95d9b6-1ce7-4c27-816d-ebb34ea9205a",
   "metadata": {},
   "source": [
    "**Let's explore a few more examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c65bec6-bdea-4f61-838b-161228c9cd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good at text patterns:\n",
      "The next word after \"Large Language\" is often \"Model,\" as in \"Large Language Model\" (LLM), which refers to a type of artificial intelligence model designed to understand and generate human language.\n"
     ]
    }
   ],
   "source": [
    "# LLMs are good at predicting likely text\n",
    "print(\"\\nGood at text patterns:\")\n",
    "print(generate(\"The next word after 'Large Language' is usually...\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a8bdaff-db56-4253-b877-c0c7c4361c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have access to your file system or the ability to interact with your current directory. However, I can provide you with commands to list files in various operating systems.\n",
      "\n",
      "- **For Windows Command Prompt**:\n",
      "  ```cmd\n",
      "  dir\n",
      "  ```\n",
      "\n",
      "- **For Windows PowerShell**:\n",
      "  ```powershell\n",
      "  Get-ChildItem\n",
      "  ```\n",
      "\n",
      "- **For macOS or Linux Terminal**:\n",
      "  ```bash\n",
      "  ls\n",
      "  ```\n",
      "\n",
      "You can run one of these commands in your terminal or command prompt to see the files in your current directory.\n"
     ]
    }
   ],
   "source": [
    "print(generate(\"List all the files in the current directory\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "232e53a9-2ce1-4f8c-8644-fa12afb9cbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I‚Äôm sorry, but I can't provide real-time information, including the current time. However, you can easily check the current Eastern Time (ET) by looking it up on your device or using a world clock website.\n"
     ]
    }
   ],
   "source": [
    "print(generate(\"What is the exact current time (ET) right now?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0dd05c7f-6dcf-4fcd-8087-ad6b7687d9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm unable to provide real-time data, including current temperatures. However, you can easily find the current temperature in New York City by checking a weather website or using a weather app on your smartphone.\n"
     ]
    }
   ],
   "source": [
    "print(generate(\"What's the current temperature in New York City right now?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e83dd-f890-45fd-8f3c-4d41ad344dee",
   "metadata": {},
   "source": [
    "### KEY INSIGHT:\n",
    "LLMs can **ONLY** generate text. They cannot:\n",
    "- Perform actual calculations\n",
    "- Access files or databases\n",
    "- Check the current time\n",
    "- Fetch live data\n",
    "- Execute code\n",
    "- Send emails\n",
    "- Delete files\n",
    "- ......."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9930a15f-cde7-461c-bb7b-485e858c83c8",
   "metadata": {},
   "source": [
    "We saw in the previous example of `List all the files in the current directory` that even though the LLMs can't really access the filesystem and do the task that was asked, it was able to give instructions on exactly what we can do to achieve that goal. Let's explore a few examples and see if it holds for other examples as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f25b76f1-2ed8-45c0-b903-1e65b0f9883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate \\( 1234 \\times 5678 \\), you can use the standard multiplication method (also known as long multiplication). Here‚Äôs a step-by-step breakdown of the process:\n",
      "\n",
      "1. **Write the numbers vertically**: Write 1234 on top and 5678 below it, aligning the digits to the right.\n",
      "\n",
      "   ```\n",
      "     1234\n",
      "   x 5678\n",
      "   ```\n",
      "\n",
      "2. **Multiply the bottom number‚Äôs last digit (8) by the top number (1234)**:\n",
      "   - \\( 8 \\times 1234 = 9872 \\)\n",
      "\n",
      "   Write this result below the line.\n",
      "\n",
      "   ```\n",
      "     1234\n",
      "   x 5678\n",
      "   _______\n",
      "     9872   (this is 1234 * 8)\n",
      "   ```\n",
      "\n",
      "3. **Multiply the next digit (7) by the top number**:\n",
      "   - Since 7 is in the tens place, we actually multiply by 70.\n",
      "   - \\( 7 \\times 1234 = 8638 \\)\n",
      "   - Write this result one position to the left (as it represents 70).\n",
      "\n",
      "   ```\n",
      "     1234\n",
      "   x 5678\n",
      "   _______\n",
      "     9872   (this is 1234 * 8)\n",
      "   + 8638   (this is 1234 * 70, shifted one position to the left)\n",
      "   ```\n",
      "\n",
      "4. **Multiply the next digit (6) by the top number**:\n",
      "   - Since 6 is in the hundreds place, we multiply by 600.\n",
      "   - \\( 6 \\times 1234 = 7404 \\)\n",
      "   - Write this result two positions to the left.\n",
      "\n",
      "   ```\n",
      "     1234\n",
      "   x 5678\n",
      "   _______\n",
      "     9872   (this is 1234 * 8)\n",
      "   + 8638   (this is 1234 * 70)\n",
      "   + 7404   (this is 1234 * 600, shifted two positions to the left)\n",
      "   ```\n",
      "\n",
      "5. **Multiply the final digit (5) by the top number**:\n",
      "   - Since 5 is in the thousands place, we multiply by 5000.\n",
      "   - \\( 5 \\times 1234 = 6170 \\)\n",
      "   - Write this result three positions to the left.\n",
      "\n",
      "   ```\n",
      "     1234\n",
      "   x 5678\n",
      "   _______\n",
      "     9872   (this is 1234 * 8)\n",
      "   + 8638   (this is 1234 * 70)\n",
      "   + 7404   (this is 1234 * 600)\n",
      "   + 6170   (this is 1234 * 5000, shifted three positions to the left)\n",
      "   ```\n",
      "\n",
      "6. **Add all the results together**:\n",
      "   Now, you will sum all the intermediate results:\n",
      "\n",
      "   ```\n",
      "     9872\n",
      "   + 86380\n",
      "   + 740400\n",
      "   + 6170000\n",
      "   __________\n",
      "   = 7006652\n",
      "   ```\n",
      "\n",
      "The final result of \\( 1234 \\times 5678 \\) is \\( 7006652 \\). \n",
      "\n",
      "7. **Conclusion**: The product of \\( 1234 \\) and \\( 5678 \\) is \\( 7006652 \\). \n",
      "\n",
      "This method can also be verified using a calculator or by breaking down the numbers further, but long multiplication is a reliable and systematic approach.\n"
     ]
    }
   ],
   "source": [
    "print(generate(f\"How would you calculate {1234} * {5678}? Be specific about the method.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99020187-c787-4b30-8488-d12caa339ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To list files in the current directory, you can use the following commands depending on your operating system:\n",
      "\n",
      "### On Linux or macOS:\n",
      "You can use the `ls` command in the terminal:\n",
      "```bash\n",
      "ls\n",
      "```\n",
      "\n",
      "### On Windows:\n",
      "You can use the `dir` command in the Command Prompt:\n",
      "```cmd\n",
      "dir\n",
      "```\n",
      "\n",
      "If you are using PowerShell on Windows, you can use:\n",
      "```powershell\n",
      "Get-ChildItem\n",
      "```\n",
      "or simply:\n",
      "```powershell\n",
      "ls\n",
      "```\n",
      "as `ls` is an alias for `Get-ChildItem` in PowerShell.\n",
      "\n",
      "These commands will display the files and directories in the current working directory.\n"
     ]
    }
   ],
   "source": [
    "print(generate(\"What command or code would you run to list files in the current directory?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e06f8eb-01a0-43c9-ae1b-4713a52725f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Python, you can get the current time using the `datetime` module. Here is a simple example of how to do this:\n",
      "\n",
      "```python\n",
      "from datetime import datetime\n",
      "\n",
      "# Get the current time\n",
      "current_time = datetime.now()\n",
      "\n",
      "# Print the current time\n",
      "print(\"Current time:\", current_time)\n",
      "```\n",
      "\n",
      "If you want to format the output to show only the time, you can do so like this:\n",
      "\n",
      "```python\n",
      "from datetime import datetime\n",
      "\n",
      "# Get the current time\n",
      "current_time = datetime.now()\n",
      "\n",
      "# Format the time\n",
      "formatted_time = current_time.strftime(\"%H:%M:%S\")\n",
      "\n",
      "# Print the formatted time\n",
      "print(\"Current time:\", formatted_time)\n",
      "```\n",
      "\n",
      "In this example, `strftime` is used to format the time into a more readable format (hours:minutes:seconds). You can adjust the format string to display the time in different ways according to your needs.\n"
     ]
    }
   ],
   "source": [
    "print(generate(\"What Python code would get the current time?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21762e2c-fc9e-4c13-8c73-947d385afd65",
   "metadata": {},
   "source": [
    "### KEY INSIGHT:\n",
    "LLMs are excellent at understanding and describing and planning what needs to be done!\n",
    "\n",
    "### THOUGHT:\n",
    "What if instead of asking LLMs to **DO** things, we ask them to tell us **WHAT NEEDS TO BE DONE**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb4cc5ce-67cb-46de-8b1c-2bf74c1d3e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the three functions to see if they work:\n",
      "\n",
      "add_ints(5, 3) = 8\n",
      "multiply_ints(5, 3) = 15\n",
      "divide_ints(5, 3) = 1.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "def add_ints(x, y):\n",
    "    \"\"\"Add two integers\"\"\"\n",
    "    return x + y\n",
    "\n",
    "def multiply_ints(x, y):\n",
    "    \"\"\"Multiply two integers\"\"\"\n",
    "    return x * y\n",
    "\n",
    "def divide_ints(x, y):\n",
    "    \"\"\"Divide two integers\"\"\"\n",
    "    return x / y\n",
    "\n",
    "print(\"Testing the three functions to see if they work:\")\n",
    "print(f\"\\nadd_ints(5, 3) = {add_ints(5, 3)}\")\n",
    "print(f\"multiply_ints(5, 3) = {multiply_ints(5, 3)}\")\n",
    "print(f\"divide_ints(5, 3) = {divide_ints(5, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bfb33989-9915-437d-9812-a883eef6eef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ LLM response: multiply_ints(1234, 5678)\n",
      "üìù Type: <class 'str'>  üëà (still just text!)\n"
     ]
    }
   ],
   "source": [
    "# Ask the LLM to generate a function call (as text!)\n",
    "prompt = f\"\"\"You have access to these functions:\n",
    "- add_ints(x, y): Adds two integers\n",
    "- multiply_ints(x, y): Multiplies two integers\n",
    "- divide_ints(x, y): Divides two integers\n",
    "\n",
    "Please respond with what function needs to be called and with what arguments to fulfill the following query:\n",
    "Product of {num1} and {num2}\n",
    "\n",
    "Response format:\n",
    "Please respond with just the function call needed\n",
    "\"\"\"\n",
    "\n",
    "function_call_text = generate(prompt)\n",
    "print(f\"\\nü§ñ LLM response: {function_call_text}\")\n",
    "print(f\"üìù Type: {type(function_call_text)}  üëà (still just text!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4930a5d-3e3e-4777-91fa-b32058daf0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Execution result: 7006652\n",
      "üßÆ Correct result: 1234 * 5678 = 7006652\n",
      "‚ú® Perfect match! The LLM + Function = Correct Answer\n"
     ]
    }
   ],
   "source": [
    "# Execute the function call\n",
    "result = eval(function_call_text, {\"add_ints\": add_ints, \"multiply_ints\": multiply_ints, \"divide_ints\": divide_ints})\n",
    "print(f\"‚úÖ Execution result: {result}\")\n",
    "print(f\"üßÆ Correct result: {num1} * {num2} = {num1 * num2}\")\n",
    "print(f\"‚ú® Perfect match! The LLM + Function = Correct Answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b7b02acc-1d6d-442d-9c0d-14d4bcd6e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ User asks: Multiply 1234 and 5678?\n",
      "ü§ñ LLM generates: multiply_ints(1234, 5678)\n",
      "‚öôÔ∏è System executes: multiply_ints(1234, 5678) ‚Üí 7006652\n",
      "ü§ñ LLM responds: The product of 1234 and 5678 is 7,006,652.\n"
     ]
    }
   ],
   "source": [
    "# Complete conversation flow\n",
    "user_query = f\"Multiply {num1} and {num2}?\"\n",
    "\n",
    "print(f\"\\nüë§ User asks: {user_query}\")\n",
    "\n",
    "prompt = f\"\"\"You have access to these functions:\n",
    "- add_ints(x, y): Adds two integers\n",
    "- multiply_ints(x, y): Multiplies two integers\n",
    "- divide_ints(x, y): Divides two integers\n",
    "\n",
    "Please respond with what function needs to be called and with what arguments to fulfill the following query:\n",
    "{user_query}\n",
    "\n",
    "Response format:\n",
    "Please respond with just the function call needed\n",
    "\"\"\"\n",
    "\n",
    "function_call = generate(prompt)\n",
    "print(f\"ü§ñ LLM generates: {function_call}\")\n",
    "\n",
    "# Execute the function\n",
    "result = eval(function_call, {\"add_ints\": add_ints, \"multiply_ints\": multiply_ints, \"divide_ints\": divide_ints})\n",
    "print(f\"‚öôÔ∏è System executes: {function_call} ‚Üí {result}\")\n",
    "\n",
    "# LLM formats the response\n",
    "final_response = generate(f\"The user query was \\\"{user_query}\\\". The correct answer to that query is {result}. Now that you have the answer, please respond to the user appropriately.\")\n",
    "print(f\"ü§ñ LLM responds: {final_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f5d318-165e-4885-90cd-09873b4f9896",
   "metadata": {},
   "source": [
    "### What We Discovered:\n",
    "1. LLMs are text generators - They output strings, nothing else\n",
    "2. LLMs can't directly \"run\" things - No access to files, time, APIs, or calculations\n",
    "3. LLMs understand tasks - They know WHAT needs to be done (assuming the training data had some similar tasks)\n",
    "4. Function calling can bridge the gap - LLM writes instructions ‚Üí System executes ‚Üí LLM looks at the result ‚Üí Responds\n",
    "\n",
    "### Pattern:\n",
    "User Query ‚Üí LLM (thinks) ‚Üí Function Call (text) ‚Üí Execution (action) ‚Üí Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4800a-755e-4dd3-ba74-490c72e4d7d6",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173525af-7acb-4edd-81e1-fbed90d3b247",
   "metadata": {},
   "source": [
    "We've seen that LLMs can tell us which function to call and with what parameters pretty reliably.\n",
    "But these examples were too simple, and real-world tasks often need multiple steps to be performed to achieve something meaningful.\n",
    "So, let's look at something a bit more complicated.\n",
    "\n",
    "Here is a sample scenario:\n",
    "\n",
    "#### SCENARIO: Emergency Room (ER) Wait Time System\n",
    "\n",
    "Imagine you're building a system to help people find the fastest ER service.\n",
    "We have real-time data from multiple hospitals:\n",
    "- Current number of patients waiting at each hospital\n",
    "- Historical average treatment time per patient (varies by hospital)\n",
    "- Distance from user to each hospital\n",
    "\n",
    "**The challenge**: An LLM alone CANNOT answer these queries because:\n",
    "1. It doesn't know how many people are CURRENTLY waiting (changes every minute)\n",
    "2. It doesn't have access to each hospital's specific average treatment times\n",
    "3. It can't calculate real wait times without this live data\n",
    "\n",
    "But we have seen that if we have the right functions that do have access to the required data/information, the LLM can understand what the user wants, and generate plausible plans to answer the query.\n",
    "\n",
    "So let's build a simple application using that idea, and see if we can create something that can answer questions like:\n",
    "- What's the wait at General Hospital?\n",
    "- Which ER will see me fastest?\n",
    "- Should I drive further for shorter wait?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa07ab-7702-4e28-a225-80c0cdd56fdd",
   "metadata": {},
   "source": [
    "First, let's define some functions that can:\n",
    "- Return the current queue length at a given hospital\n",
    "- Return the average treatment time at a given hospital\n",
    "- Calculate the wait time given the current queue length and the average treatment time at a given hospital\n",
    "- Get distance to the given hospital\n",
    "- Calculate the travel time to the hospital\n",
    "- Return a list of all nearby hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "13f301b8-1bb7-4a65-a540-09f274ad383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_queue_length(hospital: str):\n",
    "    \"\"\"Get number of patients currently waiting\n",
    "    This is just dummy data for the purposes of illustration, but in practice this would connect to some source that can provide realtime data\"\"\"\n",
    "    \n",
    "    # Simulated REAL-TIME data\n",
    "    current_queues = {\n",
    "        'General Hospital': 12,\n",
    "        'St. Mary Medical': 5,\n",
    "        'City Emergency': 18,\n",
    "        'University Hospital': 8,\n",
    "        'Riverside Clinic': 3\n",
    "    }\n",
    "    return current_queues.get(hospital, 0)\n",
    "\n",
    "def get_treatment_time(hospital: str):\n",
    "    \"\"\"Get average minutes per patient at this hospital\n",
    "    Again, this is just dummy data for the purposes of illustration, but in practice this would connect to some source that can provide realtime data\"\"\"\n",
    "    \n",
    "    avg_times = {\n",
    "        'General Hospital': 25,\n",
    "        'St. Mary Medical': 45,\n",
    "        'City Emergency': 35,\n",
    "        'University Hospital': 40,\n",
    "        'Riverside Clinic': 20\n",
    "    }\n",
    "    return avg_times.get(hospital, 30)\n",
    "\n",
    "def calculate_wait(queue: int, avg_time: int):\n",
    "    \"\"\"Calculate expected wait in minutes\"\"\"\n",
    "    return queue * avg_time\n",
    "\n",
    "def get_distance(hospital: str):\n",
    "    \"\"\"Get miles from current location to hospital (Static, dummy data)\"\"\"\n",
    "    distances = {\n",
    "        'General Hospital': 2.5,\n",
    "        'St. Mary Medical': 4.0,\n",
    "        'City Emergency': 1.2,\n",
    "        'University Hospital': 6.0,\n",
    "        'Riverside Clinic': 3.3\n",
    "    }\n",
    "    return distances.get(hospital, 0)\n",
    "\n",
    "def calculate_travel_time(distance: float):\n",
    "    \"\"\"Returns the travel time, given the distance (assuming 2 minutes per mile for this example)\"\"\"\n",
    "    return distance * 2\n",
    "\n",
    "def list_hospitals():\n",
    "    \"\"\"Get list of all hospitals nearby\"\"\"\n",
    "    return ['General Hospital', 'St. Mary Medical', 'City Emergency', \n",
    "            'University Hospital', 'Riverside Clinic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac4ea14-ac7f-4baa-b54e-d4679475ddf1",
   "metadata": {},
   "source": [
    "We've defined the following functions:\n",
    "- **get_queue_length(hospital)** - Returns the current queue at a given hospital\n",
    "- **get_treatment_time(hospital)** - Returns the avg minutes per patient\n",
    "- **calculate_wait(queue, time)** - Returns the total wait time given the current queue length and the average treatment time\n",
    "- **get_distance(hospital)** - Returns the distance to the hospital\n",
    "- **calculate_travel_time(distance)** - Returns the travel time given the distance\n",
    "- **list_hospitals()** - Returns a list of all nearby hospitals\n",
    "\n",
    "**Let's test each function to see if they work:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4c1339b2-670b-4c50-a6bf-f0ee3645f619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue at General Hospital: 12 patients waiting\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Check queue at one hospital\n",
    "hospital = 'General Hospital'\n",
    "queue = get_queue_length(hospital)\n",
    "print(f\"Queue at {hospital}: {queue} patients waiting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fdb467ea-4312-4100-ae56-e4accf82f56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average treatment time: 25 minutes per patient\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Get treatment time\n",
    "avg_time = get_treatment_time(hospital)\n",
    "print(f\"Average treatment time: {avg_time} minutes per patient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ece2bb1d-f0f4-40c8-88d2-92191d736a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected wait: 300 minutes (5.0 hours)\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Calculate wait\n",
    "wait = calculate_wait(queue, avg_time)\n",
    "print(f\"Expected wait: {wait} minutes ({wait/60:.1f} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9ea9d79c-b042-463a-ba84-b94f1597bfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 2.5 miles away\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Check distance\n",
    "distance = get_distance(hospital)\n",
    "print(f\"Distance: {distance} miles away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eb8e9165-22a7-4c9f-b924-849ad590a8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel time: 5.0 mins\n"
     ]
    }
   ],
   "source": [
    "# Test 5: Calculate travel time\n",
    "traveltime = calculate_travel_time(2.5)\n",
    "print(f\"Travel time: {traveltime} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "df78e222-9030-40ca-abe9-75ec255760db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All hospitals: ['General Hospital', 'St. Mary Medical', 'City Emergency', 'University Hospital', 'Riverside Clinic']\n"
     ]
    }
   ],
   "source": [
    "# Test 6: List all hospitals\n",
    "print(f\"\\nAll hospitals: {list_hospitals()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d0588-4d57-45a7-af6b-7988d439c3bd",
   "metadata": {},
   "source": [
    "Now let's manually walk through a simple query and what needs to be done to answer it:\n",
    "\n",
    "#### **Query** What's the wait time at General Hospital?\n",
    "\n",
    "**ü§î To answer this, we need to:**\n",
    "1. Check how many people are waiting now at General Hospital\n",
    "2. Get the average treatment time per patient at General Hospital\n",
    "3. Calculate total wait time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "977f623a-9edf-456f-8ad6-4d6f3910ee3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Current queue = 12 patients\n",
      "Step 2: Avg time per patient = 25 minutes\n",
      "Step 3: Total wait = 12 √ó 25 = 300 minutes\n",
      "\n",
      "‚úÖ Wait time at General Hospital is 300 minutes (5.0 hours)\n"
     ]
    }
   ],
   "source": [
    "hospital = 'General Hospital'\n",
    "\n",
    "# Step 1: Get current queue\n",
    "queue = get_queue_length(hospital)\n",
    "print(f\"Step 1: Current queue = {queue} patients\")\n",
    "\n",
    "# Step 2: Get average time\n",
    "avg_time = get_treatment_time(hospital)\n",
    "print(f\"Step 2: Avg time per patient = {avg_time} minutes\")\n",
    "\n",
    "# Step 3: Calculate total wait\n",
    "wait_time = calculate_wait(queue, avg_time)\n",
    "print(f\"Step 3: Total wait = {queue} √ó {avg_time} = {wait_time} minutes\")\n",
    "\n",
    "print(f\"\\n‚úÖ Wait time at {hospital} is {wait_time} minutes ({wait_time/60:.1f} hours)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4836766-60a1-4740-b100-c576ccbb545e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d170bee-5206-49ba-bfd5-bcbf51d3c029",
   "metadata": {},
   "source": [
    "Let's look at a different, slightly more complicated query:\n",
    "\n",
    "#### **Query**: Which hospital will see me the fastest? (ignoring travel time)\n",
    "\n",
    "**ü§î To answer this question, we need to:**\n",
    "1. Check ALL hospitals\n",
    "2. Calculate wait time for EACH\n",
    "3. Find the minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f546b14b-c39f-416e-bff6-36da3ff04cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ User query: Which hospital will see me the fastest? (ignoring travel time)\n",
      "General Hospital     - 12 patients √ó 25 min = 300 min wait\n",
      "St. Mary Medical     -  5 patients √ó 45 min = 225 min wait\n",
      "City Emergency       - 18 patients √ó 35 min = 630 min wait\n",
      "University Hospital  -  8 patients √ó 40 min = 320 min wait\n",
      "Riverside Clinic     -  3 patients √ó 20 min =  60 min wait\n",
      "\n",
      "‚úÖ Answer: Riverside Clinic has shortest wait (60 minutes)\n"
     ]
    }
   ],
   "source": [
    "# Query Type 2: Find the best option\n",
    "query = \"Which hospital will see me the fastest? (ignoring travel time)\"\n",
    "\n",
    "print(f\"üë§ User query: {query}\")\n",
    "\n",
    "# Check all hospitals\n",
    "results = []\n",
    "\n",
    "for hospital in list_hospitals():\n",
    "    queue = get_queue_length(hospital)\n",
    "    avg_time = get_treatment_time(hospital)\n",
    "    wait = calculate_wait(queue, avg_time)\n",
    "    results.append((hospital, wait, queue))\n",
    "    print(f\"{hospital:20} - {queue:2} patients √ó {avg_time:2} min = {wait:3} min wait\")\n",
    "\n",
    "# Find the best option\n",
    "best = min(results, key=lambda x: x[1])\n",
    "print(f\"\\n‚úÖ Answer: {best[0]} has shortest wait ({best[1]} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec76ec-eee2-4b11-8669-9fce32d5bd95",
   "metadata": {},
   "source": [
    "Next, lets try the same query, but also factor in the travel time:\n",
    "\n",
    "#### **Query**: Which hospital will treat me soonest, including travel time?\n",
    "\n",
    "**ü§î To answer this, we need to:\n",
    "1. Calculate wait time for each hospital\n",
    "2. Calculate travel time to each hospital\n",
    "3. Add travel times to wait times to get total time for each hospital\n",
    "4. Find optimal total time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "90a79675-3099-4617-ad40-a265a8e1a1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ User query: Which hospital will treat me soonest, including travel time?\n",
      "\n",
      "ü§î Even more complex! We need to:\n",
      "  1. Calculate wait time for each hospital\n",
      "  2. Add travel time (assume 2 minutes per mile)\n",
      "  3. Find optimal total time\n",
      "\n",
      "Coordinating even more tools:\n",
      "\n",
      "Hospital             Wait     Travel   Total   \n",
      "--------------------------------------------------\n",
      "General Hospital     300      5        305     \n",
      "St. Mary Medical     225      8        233     \n",
      "City Emergency       630      2        632     \n",
      "University Hospital  320      12       332     \n",
      "Riverside Clinic     60       7        67      \n",
      "\n",
      "‚úÖ Answer: Riverside Clinic is fastest overall\n",
      "   (Wait: 60 min + Travel: 7 min = 67 min total)\n"
     ]
    }
   ],
   "source": [
    "# Query Type 3: Most complex - optimize total time\n",
    "query = \"Which hospital will treat me soonest, including travel time?\"\n",
    "\n",
    "print(f\"üë§ User query: {query}\")\n",
    "print(\"\\nü§î Even more complex! We need to:\")\n",
    "print(\"  1. Calculate wait time for each hospital\")\n",
    "print(\"  2. Add travel time (assume 2 minutes per mile)\")\n",
    "print(\"  3. Find optimal total time\")\n",
    "print(\"\\nCoordinating even more tools:\\n\")\n",
    "\n",
    "# Travel speed assumption\n",
    "MINUTES_PER_MILE = 2\n",
    "\n",
    "results = []\n",
    "print(f\"{'Hospital':<20} {'Wait':<8} {'Travel':<8} {'Total':<8}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for hospital in list_hospitals():\n",
    "    # Get wait time\n",
    "    queue = get_queue_length(hospital)\n",
    "    avg_time = get_treatment_time(hospital)\n",
    "    wait = calculate_wait(queue, avg_time)\n",
    "    \n",
    "    # Get travel time\n",
    "    distance = get_distance(hospital)\n",
    "    travel_time = distance * MINUTES_PER_MILE\n",
    "    \n",
    "    # Calculate total\n",
    "    total = wait + travel_time\n",
    "    \n",
    "    results.append((hospital, wait, travel_time, total))\n",
    "    print(f\"{hospital:<20} {wait:<8} {travel_time:<8.0f} {total:<8.0f}\")\n",
    "\n",
    "# Find optimal\n",
    "best = min(results, key=lambda x: x[3])\n",
    "print(f\"\\n‚úÖ Answer: {best[0]} is fastest overall\")\n",
    "print(f\"   (Wait: {best[1]} min + Travel: {best[2]:.0f} min = {best[3]:.0f} min total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787edc46-67e8-4ab8-8fd5-c4565e218fc5",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb881368-7de8-44b1-8697-1425c3334130",
   "metadata": {},
   "source": [
    "Now all these steps are hardcoded by us, providing very little flexibility. Let's see if a LLM can create a plan for any given query, similar to ours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2ba67ffe-e622-4847-a46b-28065d832736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Testing LLM's understanding:\n",
      "\n",
      "Query: 'What's the wait at St. Mary Medical?'\n",
      "\n",
      "LLM response:\n",
      "1. get_queue_length(\"General Hospital\")\n",
      "2. get_treatment_time(\"General Hospital\")\n",
      "3. calculate_wait(queue, time)\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What's the wait at General Hospital?\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You have these ER tools:\n",
    "- get_queue_length(hospital) - Returns the current queue at a given hospital\n",
    "- get_treatment_time(hospital) - Returns the avg minutes per patient\n",
    "- calculate_wait(queue, time) - Returns the total wait time given the current queue length and the average treatment time\n",
    "- get_distance(hospital) - Returns the distance to the hospital\n",
    "- calculate_travel_time(distance) - Returns the travel time given the distance\n",
    "- list_hospitals() - Returns a list of all nearby hospitals\n",
    "\n",
    "User query: {user_query}\n",
    "\n",
    "What functions should be called and in what order?\n",
    "Just list the function calls needed.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ü§ñ Testing LLM's understanding:\")\n",
    "print(\"\\nQuery: 'What's the wait at St. Mary Medical?'\")\n",
    "print(\"\\nLLM response:\")\n",
    "response = generate(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dd86e7ad-62ed-491f-84ca-8944ced9456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Let's execute that:\n",
      "Result: 300 minutes wait at General Hospital\n"
     ]
    }
   ],
   "source": [
    "# Execute what the LLM suggested\n",
    "print(\"\\nüìä Let's execute that:\")\n",
    "queue = get_queue_length(\"General Hospital\")\n",
    "avg = get_treatment_time(\"General Hospital\")\n",
    "wait = calculate_wait(queue, avg)\n",
    "print(f\"Result: {wait} minutes wait at General Hospital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "67edf530-a7d1-4146-bf80-27d6c1252a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_queries = [\n",
    "    \"How many people are waiting at City Emergency?\",\n",
    "    \"Which hospital is closest to me?\",\n",
    "    \"What's the average treatment time at Riverside Clinic?\",\n",
    "    \"If I go to University Hospital, how long will I wait?\",\n",
    "    \"Which ER has the shortest queue right now?\",\n",
    "    \"Is General Hospital or St. Mary Medical faster?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cf211a50-9592-4e74-8347-43172a048303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Agent v1 (Keyword Matching):\n",
      "==================================================\n",
      "üéØ Query: What's the wait at General Hospital?\n",
      "üí≠ Intent: Check wait time at General Hospital\n",
      "üìä Result: Wait at General Hospital: 300 minutes (5.0 hours)\n",
      "==================================================\n",
      "üéØ Query: Which hospital is the fastest to treat patients\n",
      "üí≠ Intent: Find fastest hospital\n",
      "üìä Result: Fastest: Riverside Clinic (60 minutes)\n",
      "==================================================\n",
      "üéØ Query: Which hospital has the shortest wait time\n",
      "üí≠ Intent: Find fastest hospital\n",
      "üìä Result: Fastest: Riverside Clinic (60 minutes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fastest: Riverside Clinic (60 minutes)'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "SECTION 3: BUILDING OUR FIRST AGENT\n",
    "Let's start with the simplest possible \"agent\" - keyword matching\n",
    "\"\"\"\n",
    "\n",
    "# VERSION 1: Rigid Keyword-Based Agent\n",
    "\n",
    "def er_agent_v1(query):\n",
    "    \"\"\"Our first attempt - simple keyword matching\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    print(f\"üéØ Query: {query}\")\n",
    "    \n",
    "    # Try to understand intent through keywords\n",
    "    if \"wait\" in query_lower and any(hosp in query_lower for hosp in ['general', 'mary', 'city', 'university', 'riverside']):\n",
    "        # Extract hospital name (very fragile!)\n",
    "        for hospital in list_hospitals():\n",
    "            if hospital.lower() in query_lower:\n",
    "                print(f\"üí≠ Intent: Check wait time at {hospital}\")\n",
    "                \n",
    "                # Execute the steps\n",
    "                queue = get_queue_length(hospital)\n",
    "                avg = get_treatment_time(hospital)\n",
    "                wait = calculate_wait(queue, avg)\n",
    "                \n",
    "                result = f\"Wait at {hospital}: {wait} minutes ({wait/60:.1f} hours)\"\n",
    "                print(f\"üìä Result: {result}\")\n",
    "                return result\n",
    "                \n",
    "    elif \"fastest\" in query_lower or \"shortest\" in query_lower:\n",
    "        print(f\"üí≠ Intent: Find fastest hospital\")\n",
    "        \n",
    "        # Find the best option\n",
    "        best_hospital = None\n",
    "        min_wait = float('inf')\n",
    "        \n",
    "        for hospital in list_hospitals():\n",
    "            queue = get_queue_length(hospital)\n",
    "            avg = get_treatment_time(hospital)\n",
    "            wait = calculate_wait(queue, avg)\n",
    "            if wait < min_wait:\n",
    "                min_wait = wait\n",
    "                best_hospital = hospital\n",
    "        \n",
    "        result = f\"Fastest: {best_hospital} ({min_wait} minutes)\"\n",
    "        print(f\"üìä Result: {result}\")\n",
    "        return result\n",
    "        \n",
    "    else:\n",
    "        print(f\"üí≠ Intent: Unknown\")\n",
    "        return \"‚ùå I don't understand that request\"\n",
    "\n",
    "# Test our first agent\n",
    "print(\"Testing Agent v1 (Keyword Matching):\")\n",
    "print(\"=\"*50)\n",
    "er_agent_v1(\"What's the wait at General Hospital?\")\n",
    "print(\"=\"*50)\n",
    "er_agent_v1(\"Which hospital is the fastest to treat patients\")\n",
    "print(\"=\"*50)\n",
    "er_agent_v1(\"Which hospital has the shortest wait time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c5bc8034-d402-4cd2-a963-3c7e05a5d7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üö® Let's test a few variations:\n",
      "==================================================\n",
      "üéØ Query: What's the wait at General Hospital?\n",
      "üí≠ Intent: Check wait time at General Hospital\n",
      "üìä Result: Wait at General Hospital: 300 minutes (5.0 hours)\n",
      "\n",
      "Query: 'What's the wait at General Hospital?'\n",
      "Result: Wait at General Hospital: 300 minutes (5.0 hours)...\n",
      "üéØ Query: How long at General Hospital?\n",
      "üí≠ Intent: Unknown\n",
      "\n",
      "Query: 'How long at General Hospital?'\n",
      "Result: ‚ùå I don't understand that request...\n",
      "üéØ Query: General Hospital waiting time?\n",
      "üí≠ Intent: Check wait time at General Hospital\n",
      "üìä Result: Wait at General Hospital: 300 minutes (5.0 hours)\n",
      "\n",
      "Query: 'General Hospital waiting time?'\n",
      "Result: Wait at General Hospital: 300 minutes (5.0 hours)...\n",
      "üéØ Query: Which ER is fastest?\n",
      "üí≠ Intent: Find fastest hospital\n",
      "üìä Result: Fastest: Riverside Clinic (60 minutes)\n",
      "\n",
      "Query: 'Which ER is fastest?'\n",
      "Result: Fastest: Riverside Clinic (60 minutes)...\n",
      "üéØ Query: Best hospital to visit when in a rush?\n",
      "üí≠ Intent: Unknown\n",
      "\n",
      "Query: 'Best hospital to visit when in a rush?'\n",
      "Result: ‚ùå I don't understand that request...\n",
      "üéØ Query: Quickest ER?\n",
      "üí≠ Intent: Unknown\n",
      "\n",
      "Query: 'Quickest ER?'\n",
      "Result: ‚ùå I don't understand that request...\n",
      "\n",
      "üí° Problem: Slight variations break everything!\n",
      "We need something that understands MEANING, not just keywords...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüö® Let's test a few variations:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_queries = [\n",
    "    \"What's the wait at General Hospital?\",     # ‚úÖ Works\n",
    "    \"How long at General Hospital?\",            # ‚ùå Fails - missing \"wait\"\n",
    "    \"General Hospital waiting time?\",           # ‚ùå Fails - \"waiting\" not \"wait\"\n",
    "    \"Which ER is fastest?\",                     # ‚úÖ Works\n",
    "    \"Best hospital to visit when in a rush?\",                  # ‚ùå Fails - no \"fastest\"\n",
    "    \"Quickest ER?\",                             # ‚ùå Fails - \"quickest\" not \"fastest\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    result = er_agent_v1(query)\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"Result: {result[:50]}...\")  # Truncate for readability\n",
    "    \n",
    "print(\"\\nüí° Problem: Slight variations break everything!\")\n",
    "print(\"We need something that understands MEANING, not just keywords...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "583af0a3-90c7-4230-b4fb-98063ccad219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LLM Understanding:\n",
      "==================================================\n",
      "Query: 'How long at General Hospital?'\n",
      "Intent: check_wait\n",
      "\n",
      "Query: 'Best hospital to visit when in a rush?'\n",
      "Intent: find_fastest\n",
      "\n",
      "Query: 'Quickest ER?'\n",
      "Intent: find_fastest\n",
      "\n",
      "‚úÖ LLM understands the MEANING, not just keywords!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VERSION 2: LLM-Powered Understanding\n",
    "What if we let an LLM understand what the user wants?\n",
    "\"\"\"\n",
    "\n",
    "def understand_er_query(query):\n",
    "    \"\"\"Use LLM to understand intent\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are helping with ER queries. Classify this query into one of these intents:\n",
    "    - check_wait: User wants to know wait time at a specific hospital\n",
    "    - find_fastest: User wants to find the hospital with shortest wait\n",
    "    - check_distance: User wants to know how far a hospital is\n",
    "    - unknown: Doesn't match any intent\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    Respond with just the intent name.\n",
    "    \"\"\"\n",
    "    \n",
    "    intent = generate(prompt).strip().lower()\n",
    "    return intent\n",
    "\n",
    "def extract_hospital_name(query):\n",
    "    \"\"\"Extract hospital name from query using LLM\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Extract the hospital name from this query. \n",
    "    Available hospitals: General Hospital, St. Mary Medical, City Emergency, University Hospital, Riverside Clinic\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    Respond with just the hospital name or \"none\" if not found.\n",
    "    \"\"\"\n",
    "    \n",
    "    return generate(prompt).strip()\n",
    "\n",
    "# Test the understanding\n",
    "print(\"Testing LLM Understanding:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_queries = [\n",
    "    \"How long at General Hospital?\",\n",
    "    \"Best hospital to visit when in a rush?\",\n",
    "    \"Quickest ER?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    intent = understand_er_query(query)\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Intent: {intent}\\n\")\n",
    "\n",
    "print(\"‚úÖ LLM understands the MEANING, not just keywords!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dfaa61-d614-47fe-aa99-85484b2bad22",
   "metadata": {},
   "source": [
    "**Now that we see how LLM can help in creating a better ER system, let's try to incorporate it to our simple agent.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0cbf8848-1817-4ac5-9b96-93813cfe95ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Agent v2 (LLM Understanding):\n",
      "==================================================\n",
      "üéØ Query: How long at General Hospital?\n",
      "üí≠ Intent: check_wait\n",
      "üìç Hospital: General Hospital\n",
      "üìä Result: Wait at General Hospital: 300 minutes (5.0 hours)\n",
      "\n",
      "üéØ Query: Best hospital to visit when in a rush?\n",
      "üí≠ Intent: find_fastest\n",
      "üìä Result: Fastest: Riverside Clinic (60 minutes wait)\n",
      "\n",
      "üéØ Query: Quickest ER?\n",
      "üí≠ Intent: find_fastest\n",
      "üìä Result: Fastest: Riverside Clinic (60 minutes wait)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fastest: Riverside Clinic (60 minutes wait)'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def er_agent_v2(query):\n",
    "    \"\"\"Agent with LLM-powered understanding\"\"\"\n",
    "    \n",
    "    print(f\"üéØ Query: {query}\")\n",
    "    \n",
    "    # Step 1: Understand intent using LLM\n",
    "    intent = understand_er_query(query)\n",
    "    print(f\"üí≠ Intent: {intent}\")\n",
    "    \n",
    "    # Step 2: Execute based on intent\n",
    "    if intent == \"check_wait\":\n",
    "        hospital = extract_hospital_name(query)\n",
    "        if hospital != \"none\":\n",
    "            print(f\"üìç Hospital: {hospital}\")\n",
    "            queue = get_queue_length(hospital)\n",
    "            avg = get_treatment_time(hospital)\n",
    "            wait = calculate_wait(queue, avg)\n",
    "            result = f\"Wait at {hospital}: {wait} minutes ({wait/60:.1f} hours)\"\n",
    "        else:\n",
    "            result = \"Please specify which hospital\"\n",
    "            \n",
    "    elif intent == \"find_fastest\":\n",
    "        best_hospital = None\n",
    "        min_wait = float('inf')\n",
    "        \n",
    "        for hospital in list_hospitals():\n",
    "            queue = get_queue_length(hospital)\n",
    "            avg = get_treatment_time(hospital)\n",
    "            wait = calculate_wait(queue, avg)\n",
    "            if wait < min_wait:\n",
    "                min_wait = wait\n",
    "                best_hospital = hospital\n",
    "        \n",
    "        result = f\"Fastest: {best_hospital} ({min_wait} minutes wait)\"\n",
    "        \n",
    "    else:\n",
    "        result = \"I couldn't understand that request\"\n",
    "    \n",
    "    print(f\"üìä Result: {result}\")\n",
    "    return result\n",
    "\n",
    "# Test the improved agent\n",
    "print(\"Testing Agent v2 (LLM Understanding):\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# These all work now!\n",
    "er_agent_v2(\"How long at General Hospital?\")\n",
    "print()\n",
    "er_agent_v2(\"Best hospital to visit when in a rush?\")\n",
    "print()\n",
    "er_agent_v2(\"Quickest ER?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fa5a30-93dd-4c0c-9e64-5afc51a9567e",
   "metadata": {},
   "source": [
    "Let's look at a slightly more complex query:\n",
    "\n",
    "**Query**: What's the wait at General Hospital and is it faster than St. Mary?\n",
    "\n",
    "This needs:\n",
    "1. Check wait at General Hospital\n",
    "2. Check wait at St. Mary Medical\n",
    "3. Compare them\n",
    "\n",
    "Let's see if our current agent with the LLM can handle this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "035e1740-647f-4e86-b9e3-b76999a00d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Query: What's the wait at General Hospital and is it faster than St. Mary\n",
      "üí≠ Intent: check_wait\n",
      "üìç Hospital: General Hospital\n",
      "üìä Result: Wait at General Hospital: 300 minutes (5.0 hours)\n",
      "Result: Wait at General Hospital: 300 minutes (5.0 hours)\n",
      "\n",
      "üí° We need to be able to dynamically PLAN and execute MULTIPLE steps...\n"
     ]
    }
   ],
   "source": [
    "complex_query = \"What's the wait at General Hospital and is it faster than St. Mary\"\n",
    "result = er_agent_v2(complex_query)\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "print(\"\\nüí° We need to be able to dynamically PLAN and execute MULTIPLE steps...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604572f-69b3-46e2-9f70-ab4318ffdc98",
   "metadata": {},
   "source": [
    "Now, based on our previous examples and last week's exercises, we've seen that a LLM can actually do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a8462116-2f78-449f-9c40-75233650de0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LLM Planning:\n",
      "==================================================\n",
      "\n",
      "Query: 'What's the wait at General Hospital?'\n",
      "Plan:\n",
      "```\n",
      "get_queue_length(\"General Hospital\")\n",
      "get_treatment_time(\"General Hospital\")\n",
      "calculate_wait(queue, time)\n",
      "```\n",
      "\n",
      "Query: 'Which hospital is fastest?'\n",
      "Plan:\n",
      "```plaintext\n",
      "list_hospitals()\n",
      "get_queue_length(hospital)\n",
      "get_treatment_time(hospital)\n",
      "get_distance(hospital)\n",
      "calculate_travel_time(distance)\n",
      "calculate_wait(queue, time)\n",
      "```\n",
      "\n",
      "Query: 'Compare wait times at General Hospital and St. Mary Medical'\n",
      "Plan:\n",
      "```\n",
      "list_hospitals()\n",
      "get_queue_length(\"General Hospital\")\n",
      "get_treatment_time(\"General Hospital\")\n",
      "get_queue_length(\"St. Mary Medical\")\n",
      "get_treatment_time(\"St. Mary Medical\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "def plan_er_query(query):\n",
    "    \"\"\"Let LLM plan which tools to use\"\"\"\n",
    "    \n",
    "    tools_description = \"\"\"\n",
    "    Available tools:\n",
    "    - get_queue_length(hospital) - Returns the current queue at a given hospital\n",
    "    - get_treatment_time(hospital) - Returns the avg minutes per patient\n",
    "    - calculate_wait(queue, time) - Returns the total wait time given the current queue length and the average treatment time\n",
    "    - get_distance(hospital) - Returns the distance to the hospital\n",
    "    - calculate_travel_time(distance) - Returns the travel time given the distance\n",
    "    - list_hospitals() - Returns a list of all nearby hospitals\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    {tools_description}\n",
    "    \n",
    "    User query: {query}\n",
    "    \n",
    "    What tool(s) should be called to answer this? \n",
    "    List the exact function calls needed, one per line.\n",
    "    \"\"\"\n",
    "    \n",
    "    plan = generate(prompt).strip()\n",
    "    return plan\n",
    "\n",
    "# Test the planning\n",
    "print(\"Testing LLM Planning:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "queries = [\n",
    "    \"What's the wait at General Hospital?\",\n",
    "    \"Which hospital is fastest?\",\n",
    "    \"Compare wait times at General Hospital and St. Mary Medical\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(\"Plan:\")\n",
    "    plan = plan_er_query(query)\n",
    "    print(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d53c5ef1-85eb-4d9f-8380-cf6441b57e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Agent v3 (LLM Chooses Tools):\n",
      "==================================================\n",
      "üéØ Query: How many people at General Hospital?\n",
      "üí≠ Planning: get_queue_length('General Hospital')\n",
      "‚ö° Executed: get_queue_length('General Hospital') ‚Üí 12\n",
      "\n",
      "üéØ Query: What's the average time at Riverside Clinic?\n",
      "üí≠ Planning: get_treatment_time('Riverside Clinic')\n",
      "‚ö° Executed: get_treatment_time('Riverside Clinic') ‚Üí 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Result: 20'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def er_agent_v3(query):\n",
    "    \"\"\"Agent where LLM decides which tools to use\"\"\"\n",
    "    \n",
    "    # Available tools\n",
    "    tools = {\n",
    "        \"get_queue_length\": get_queue_length,\n",
    "        \"get_treatment_time\": get_treatment_time,\n",
    "        \"calculate_wait\": calculate_wait,\n",
    "        \"get_distance\": get_distance,\n",
    "        \"calculate_travel_time\": calculate_travel_time,\n",
    "        \"list_hospitals\": list_hospitals\n",
    "    }\n",
    "    \n",
    "    tools_description = \"\"\"\n",
    "    Available tools:\n",
    "    - get_queue_length(hospital) - Returns the current queue at a given hospital\n",
    "    - get_treatment_time(hospital) - Returns the avg minutes per patient\n",
    "    - calculate_wait(queue, time) - Returns the total wait time given the current queue length and the average treatment time\n",
    "    - get_distance(hospital) - Returns the distance to the hospital\n",
    "    - calculate_travel_time(distance) - Returns the travel time given the distance\n",
    "    - list_hospitals() - Returns a list of all nearby hospitals\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üéØ Query: {query}\")\n",
    "    \n",
    "    # Think: What tool to use?\n",
    "    prompt = f\"\"\"\n",
    "    Here are some functions available to use:\n",
    "    - get_queue_length(hospital: str) - Returns the current queue length at a given hospital\n",
    "    - get_treatment_time(hospital: str) - Returns the average minutes per patient. Used to get the average treatment time per patient at a given hospital\n",
    "    - calculate_wait(queue_length: int, treatment_time: float) - Given the current queue length at a hospital and its average treatment time per patient, returns the total wait time expected\n",
    "    - get_distance(hospital: str) - Returns the distance to the hospital\n",
    "    - calculate_travel_time(distance: float) - Returns the travel time given the distance. Usually used when travel time needs to be considered when calculating total time (added to wait time)\n",
    "    - list_hospitals() - Returns a list of all nearby hospitals\n",
    "    \n",
    "    User query: {query}\n",
    "    \n",
    "    Respond with ONLY the function call needed (e.g., get_queue_length('General Hospital'))\n",
    "    If multiple calls needed, just give the first one.\n",
    "    \"\"\"\n",
    "    \n",
    "    tool_call = generate(prompt).strip()\n",
    "    print(f\"üí≠ Planning: {tool_call}\")\n",
    "    \n",
    "    # Act: Execute the tool\n",
    "    try:\n",
    "        result = eval(tool_call, tools)\n",
    "        print(f\"‚ö° Executed: {tool_call} ‚Üí {result}\")\n",
    "    except Exception as e:\n",
    "        result = f\"Error: {e}\"\n",
    "        print(f\"‚ùå Failed: {e}\")\n",
    "    \n",
    "    # For demonstration, just return the raw result\n",
    "    # (In reality, we'd interpret it better)\n",
    "    return f\"Result: {result}\"\n",
    "\n",
    "# Test it\n",
    "print(\"Testing Agent v3 (LLM Chooses Tools):\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "er_agent_v3(\"How many people at General Hospital?\")\n",
    "print()\n",
    "er_agent_v3(\"What's the average time at Riverside Clinic?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dadf2f-3fcb-454c-888e-1387e9f86895",
   "metadata": {},
   "source": [
    "Now let's look deeper into this query:\n",
    "\n",
    "**Query**: What's the wait at General Hospital?\n",
    "\n",
    "This actually needs THREE tools:\n",
    "1. get_queue_length('General Hospital') ‚Üí 12\n",
    "2. get_treatment_time('General Hospital') ‚Üí 25\n",
    "3. calculate_wait(12, 25) ‚Üí 300 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25b2034-6d04-41ea-98e3-d30b15231f52",
   "metadata": {},
   "source": [
    "<hr>\n",
    "üí°A LLM can identify which functions to call accurately, but to identify the correct arguments for the function calls, it sometimes needs the results of the previous calls.\n",
    "\n",
    "In the above example, the LLM thinks that this is what should be executed:\n",
    "1. get_queue_length('General Hospital') \n",
    "2. get_treatment_time('General Hospital')\n",
    "3. calculate_wait(queue_length, treatment_time)\n",
    "\n",
    "We can see that even though steps 1 and 2 that the LLM generated can be executed, step 3 can't because the LLM can't predict what the values are to pass to calculate_wait. It needs the output of the `get_queue_length` and the `get_treatment_time calls` to actually formulate the correct function call with the right parameters. \n",
    "\n",
    "**ü§î What if we let the agent call tools in a LOOP untils it's done?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3699f8ff-9dc3-482d-a263-376fc00b8c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Agent v4:\n",
      "==================================================\n",
      "üéØ QUERY: What's the wait at General Hospital?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìç Step 1:\n",
      "LLM Response: get_queue_length(\"General Hospital\")\n",
      "Execution Result: 12\n",
      "\n",
      "üìç Step 2:\n",
      "LLM Response: get_treatment_time(\"General Hospital\")\n",
      "Execution Result: 25\n",
      "\n",
      "üìç Step 3:\n",
      "LLM Response: calculate_wait(12, 25)\n",
      "Execution Result: 300\n",
      "\n",
      "üìç Step 4:\n",
      "LLM Response: DONE\n",
      "\n",
      "‚úÖ ANSWER: The wait at General Hospital is approximately 300 minutes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The wait at General Hospital is approximately 300 minutes.'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def er_agent_v4(query, max_steps=30):\n",
    "    tools = {\n",
    "        \"get_queue_length\": get_queue_length,\n",
    "        \"get_treatment_time\": get_treatment_time,\n",
    "        \"calculate_wait\": calculate_wait,\n",
    "        \"get_distance\": get_distance,\n",
    "        \"calculate_travel_time\": calculate_travel_time,\n",
    "        \"list_hospitals\": list_hospitals\n",
    "    }\n",
    "    \n",
    "    \n",
    "    print(f\"üéØ QUERY: {query}\")\n",
    "    print(\"‚îÄ\" * 40)\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        print(f\"\\nüìç Step {step + 1}:\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Query: {query}\n",
    "        \n",
    "        Previous steps: {history}\n",
    "        \n",
    "        Here are some tools that you can use:\n",
    "        - get_queue_length(hospital: str) - Returns the current queue length at a given hospital\n",
    "        - get_treatment_time(hospital: str) - Returns the average minutes per patient. Used to get the average treatment time per patient at a given hospital\n",
    "        - calculate_wait(queue_length: int, treatment_time: float) - Given the current queue length at a hospital and its average treatment time per patient, returns the total wait time expected\n",
    "        - get_distance(hospital: str) - Returns the distance to the hospital\n",
    "        - calculate_travel_time(distance: float) - Returns the travel time given the distance. Usually used when travel time needs to be considered when calculating total time (added to wait time)\n",
    "        - list_hospitals() - Returns a list of all nearby hospitals\n",
    "\n",
    "        What's the next step? If done, say \"DONE\".\n",
    "        Otherwise, give the exact function call. Respond with just the function call without any code blocks.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = generate(prompt).strip()\n",
    "        print(f\"LLM Response: {response}\")\n",
    "        \n",
    "        if \"DONE\" in response.upper():\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            result = eval(response, tools)\n",
    "            print(f\"Execution Result: {result}\")\n",
    "            history.append(f\"{response} ‚Üí {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            history.append(f\"{response} ‚Üí Error\")\n",
    "    \n",
    "    # Generate final answer once done\n",
    "    final_prompt = f\"\"\"\n",
    "    Question: {query}\n",
    "    Steps taken: {history}\n",
    "    \n",
    "    Give a brief, clear answer to the original question.\n",
    "    \"\"\"\n",
    "    \n",
    "    answer = generate(final_prompt).strip()\n",
    "    print(f\"\\n‚úÖ ANSWER: {answer}\")\n",
    "    return answer\n",
    "\n",
    "# Test the agent\n",
    "print(\"Testing Agent v4:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "er_agent_v4(\"What's the wait at General Hospital?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e3a44744-8aed-4df4-9e04-206c0072154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Let's test the previous variations (some of which failed):**\n",
      "==================================================\n",
      "üéØ QUERY: What's the wait at General Hospital?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìç Step 1:\n",
      "LLM Response: get_queue_length(\"General Hospital\")\n",
      "Execution Result: 12\n",
      "\n",
      "üìç Step 2:\n",
      "LLM Response: get_treatment_time(\"General Hospital\")\n",
      "Execution Result: 25\n",
      "\n",
      "üìç Step 3:\n",
      "LLM Response: calculate_wait(12, 25)\n",
      "Execution Result: 300\n",
      "\n",
      "üìç Step 4:\n",
      "LLM Response: DONE\n",
      "\n",
      "‚úÖ ANSWER: The wait at General Hospital is approximately 300 minutes.\n",
      "\n",
      "Query: 'What's the wait at General Hospital?'\n",
      "Result: The wait at General Hospital is approximately 300 minutes.\n",
      "==================================================\n",
      "üéØ QUERY: General Hospital waiting time?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìç Step 1:\n",
      "LLM Response: list_hospitals()\n",
      "Execution Result: ['General Hospital', 'St. Mary Medical', 'City Emergency', 'University Hospital', 'Riverside Clinic']\n",
      "\n",
      "üìç Step 2:\n",
      "LLM Response: get_queue_length('General Hospital')\n",
      "Execution Result: 12\n",
      "\n",
      "üìç Step 3:\n",
      "LLM Response: get_treatment_time('General Hospital')\n",
      "Execution Result: 25\n",
      "\n",
      "üìç Step 4:\n",
      "LLM Response: calculate_wait(12, 25)\n",
      "Execution Result: 300\n",
      "\n",
      "üìç Step 5:\n",
      "LLM Response: DONE\n",
      "\n",
      "‚úÖ ANSWER: The estimated waiting time at General Hospital is 300 minutes.\n",
      "\n",
      "Query: 'General Hospital waiting time?'\n",
      "Result: The estimated waiting time at General Hospital is 300 minutes.\n",
      "==================================================\n",
      "üéØ QUERY: Which ER is fastest?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìç Step 1:\n",
      "LLM Response: list_hospitals()\n",
      "Execution Result: ['General Hospital', 'St. Mary Medical', 'City Emergency', 'University Hospital', 'Riverside Clinic']\n",
      "\n",
      "üìç Step 2:\n",
      "LLM Response: get_queue_length('General Hospital')\n",
      "Execution Result: 12\n",
      "\n",
      "üìç Step 3:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 4:\n",
      "LLM Response: get_queue_length('City Emergency')\n",
      "Execution Result: 18\n",
      "\n",
      "üìç Step 5:\n",
      "LLM Response: get_treatment_time('General Hospital')\n",
      "Execution Result: 25\n",
      "\n",
      "üìç Step 6:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 7:\n",
      "LLM Response: get_treatment_time('St. Mary Medical')\n",
      "Execution Result: 45\n",
      "\n",
      "üìç Step 8:\n",
      "LLM Response: get_queue_length('City Emergency')\n",
      "Execution Result: 18\n",
      "\n",
      "üìç Step 9:\n",
      "LLM Response: calculate_wait(12, 25)\n",
      "Execution Result: 300\n",
      "\n",
      "üìç Step 10:\n",
      "LLM Response: get_queue_length('University Hospital')\n",
      "Execution Result: 8\n",
      "\n",
      "üìç Step 11:\n",
      "LLM Response: get_treatment_time('University Hospital')\n",
      "Execution Result: 40\n",
      "\n",
      "üìç Step 12:\n",
      "LLM Response: get_treatment_time('University Hospital')\n",
      "Execution Result: 40\n",
      "\n",
      "üìç Step 13:\n",
      "LLM Response: get_treatment_time('City Emergency')\n",
      "Execution Result: 35\n",
      "\n",
      "üìç Step 14:\n",
      "LLM Response: DONE\n",
      "\n",
      "‚úÖ ANSWER: The fastest ER is St. Mary Medical, with a total wait time of 300 minutes.\n",
      "\n",
      "Query: 'Which ER is fastest?'\n",
      "Result: The fastest ER is St. Mary Medical, with a total wait time of 300 minutes.\n",
      "==================================================\n",
      "üéØ QUERY: Best hospital to visit when in a rush?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìç Step 1:\n",
      "LLM Response: list_hospitals()\n",
      "Execution Result: ['General Hospital', 'St. Mary Medical', 'City Emergency', 'University Hospital', 'Riverside Clinic']\n",
      "\n",
      "üìç Step 2:\n",
      "LLM Response: get_queue_length('General Hospital')\n",
      "Execution Result: 12\n",
      "\n",
      "üìç Step 3:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 4:\n",
      "LLM Response: get_queue_length('City Emergency')\n",
      "Execution Result: 18\n",
      "\n",
      "üìç Step 5:\n",
      "LLM Response: get_queue_length('University Hospital')\n",
      "Execution Result: 8\n",
      "\n",
      "üìç Step 6:\n",
      "LLM Response: get_treatment_time('St. Mary Medical')\n",
      "Execution Result: 45\n",
      "\n",
      "üìç Step 7:\n",
      "LLM Response: get_treatment_time('General Hospital')\n",
      "Execution Result: 25\n",
      "\n",
      "üìç Step 8:\n",
      "LLM Response: calculate_wait(5, 45)\n",
      "Execution Result: 225\n",
      "\n",
      "üìç Step 9:\n",
      "LLM Response: get_queue_length('City Emergency')\n",
      "Execution Result: 18\n",
      "\n",
      "üìç Step 10:\n",
      "LLM Response: get_queue_length('University Hospital')\n",
      "Execution Result: 8\n",
      "\n",
      "üìç Step 11:\n",
      "LLM Response: get_queue_length('City Emergency')\n",
      "Execution Result: 18\n",
      "\n",
      "üìç Step 12:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 13:\n",
      "LLM Response: get_queue_length('University Hospital')\n",
      "Execution Result: 8\n",
      "\n",
      "üìç Step 14:\n",
      "LLM Response: get_queue_length('University Hospital')\n",
      "Execution Result: 8\n",
      "\n",
      "üìç Step 15:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 16:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 17:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 18:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 19:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 20:\n",
      "LLM Response: get_distance('St. Mary Medical')\n",
      "Execution Result: 4.0\n",
      "\n",
      "üìç Step 21:\n",
      "LLM Response: calculate_wait(5, 45)\n",
      "Execution Result: 225\n",
      "\n",
      "üìç Step 22:\n",
      "LLM Response: get_distance('St. Mary Medical')\n",
      "Execution Result: 4.0\n",
      "\n",
      "üìç Step 23:\n",
      "LLM Response: get_distance('General Hospital')\n",
      "Execution Result: 2.5\n",
      "\n",
      "üìç Step 24:\n",
      "LLM Response: calculate_wait(5, 45)\n",
      "Execution Result: 225\n",
      "\n",
      "üìç Step 25:\n",
      "LLM Response: calculate_travel_time(4.0)\n",
      "Execution Result: 8.0\n",
      "\n",
      "üìç Step 26:\n",
      "LLM Response: get_queue_length('City Emergency')\n",
      "Execution Result: 18\n",
      "\n",
      "üìç Step 27:\n",
      "LLM Response: get_queue_length('University Hospital')\n",
      "Execution Result: 8\n",
      "\n",
      "üìç Step 28:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 29:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 30:\n",
      "LLM Response: get_distance('General Hospital')\n",
      "Execution Result: 2.5\n",
      "\n",
      "‚úÖ ANSWER: The best hospital to visit when in a rush is **St. Mary Medical**, as it has the shortest queue length of 5. However, be aware that the total wait time, including treatment, would be 225 minutes.\n",
      "\n",
      "Query: 'Best hospital to visit when in a rush?'\n",
      "Result: The best hospital to visit when in a rush is **St. Mary Medical**, as it has the shortest queue length of 5. However, be aware that the total wait time, including treatment, would be 225 minutes.\n",
      "==================================================\n",
      "üéØ QUERY: Best hospital to visit when in a rush, accounting for wait times and travel, not just based on queue length?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìç Step 1:\n",
      "LLM Response: list_hospitals()\n",
      "Execution Result: ['General Hospital', 'St. Mary Medical', 'City Emergency', 'University Hospital', 'Riverside Clinic']\n",
      "\n",
      "üìç Step 2:\n",
      "LLM Response: get_queue_length('General Hospital')\n",
      "Execution Result: 12\n",
      "\n",
      "üìç Step 3:\n",
      "LLM Response: list_hospitals()\n",
      "Execution Result: ['General Hospital', 'St. Mary Medical', 'City Emergency', 'University Hospital', 'Riverside Clinic']\n",
      "\n",
      "üìç Step 4:\n",
      "LLM Response: get_treatment_time('General Hospital')\n",
      "Execution Result: 25\n",
      "\n",
      "üìç Step 5:\n",
      "LLM Response: get_distance('St. Mary Medical')\n",
      "Execution Result: 4.0\n",
      "\n",
      "üìç Step 6:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 7:\n",
      "LLM Response: get_distance('City Emergency')\n",
      "Execution Result: 1.2\n",
      "\n",
      "üìç Step 8:\n",
      "LLM Response: get_queue_length('City Emergency')\n",
      "Execution Result: 18\n",
      "\n",
      "üìç Step 9:\n",
      "LLM Response: get_distance('University Hospital')\n",
      "Execution Result: 6.0\n",
      "\n",
      "üìç Step 10:\n",
      "LLM Response: get_treatment_time('St. Mary Medical')\n",
      "Execution Result: 45\n",
      "\n",
      "üìç Step 11:\n",
      "LLM Response: get_distance('City Emergency')\n",
      "Execution Result: 1.2\n",
      "\n",
      "üìç Step 12:\n",
      "LLM Response: get_queue_length('City Emergency')\n",
      "Execution Result: 18\n",
      "\n",
      "üìç Step 13:\n",
      "LLM Response: get_distance('University Hospital')\n",
      "Execution Result: 6.0\n",
      "\n",
      "üìç Step 14:\n",
      "LLM Response: get_queue_length('City Emergency')\n",
      "Execution Result: 18\n",
      "\n",
      "üìç Step 15:\n",
      "LLM Response: get_distance('City Emergency')\n",
      "Execution Result: 1.2\n",
      "\n",
      "üìç Step 16:\n",
      "LLM Response: calculate_wait(get_queue_length('City Emergency'), get_treatment_time('City Emergency')) + calculate_travel_time(get_distance('City Emergency'))\n",
      "Execution Result: 632.4\n",
      "\n",
      "üìç Step 17:\n",
      "LLM Response: get_distance('General Hospital')\n",
      "Execution Result: 2.5\n",
      "\n",
      "üìç Step 18:\n",
      "LLM Response: get_treatment_time('City Emergency')\n",
      "Execution Result: 35\n",
      "\n",
      "üìç Step 19:\n",
      "LLM Response: get_distance('General Hospital')\n",
      "Execution Result: 2.5\n",
      "\n",
      "üìç Step 20:\n",
      "LLM Response: get_distance('General Hospital')\n",
      "Execution Result: 2.5\n",
      "\n",
      "üìç Step 21:\n",
      "LLM Response: get_distance('General Hospital')\n",
      "Execution Result: 2.5\n",
      "\n",
      "üìç Step 22:\n",
      "LLM Response: calculate_wait(get_queue_length('St. Mary Medical'), get_treatment_time('St. Mary Medical')) + calculate_travel_time(get_distance('St. Mary Medical'))\n",
      "Execution Result: 233.0\n",
      "\n",
      "üìç Step 23:\n",
      "LLM Response: get_distance('University Hospital')\n",
      "Execution Result: 6.0\n",
      "\n",
      "üìç Step 24:\n",
      "LLM Response: get_distance('University Hospital')\n",
      "Execution Result: 6.0\n",
      "\n",
      "üìç Step 25:\n",
      "LLM Response: get_distance('University Hospital')\n",
      "Execution Result: 6.0\n",
      "\n",
      "üìç Step 26:\n",
      "LLM Response: get_distance('University Hospital')\n",
      "Execution Result: 6.0\n",
      "\n",
      "üìç Step 27:\n",
      "LLM Response: get_distance('University Hospital')\n",
      "Execution Result: 6.0\n",
      "\n",
      "üìç Step 28:\n",
      "LLM Response: get_treatment_time('City Emergency')\n",
      "Execution Result: 35\n",
      "\n",
      "üìç Step 29:\n",
      "LLM Response: get_distance('General Hospital')\n",
      "Execution Result: 2.5\n",
      "\n",
      "üìç Step 30:\n",
      "LLM Response: get_distance('General Hospital')\n",
      "Execution Result: 2.5\n",
      "\n",
      "‚úÖ ANSWER: The best hospital to visit when in a rush is **St. Mary Medical**. It has the shortest calculated wait time of 233.0 minutes, including treatment and travel time, compared to the other hospitals.\n",
      "\n",
      "Query: 'Best hospital to visit when in a rush, accounting for wait times and travel, not just based on queue length?'\n",
      "Result: The best hospital to visit when in a rush is **St. Mary Medical**. It has the shortest calculated wait time of 233.0 minutes, including treatment and travel time, compared to the other hospitals.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLet's test the previous variations (some of which failed):\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_queries = [\n",
    "    \"What's the wait at General Hospital?\",\n",
    "    \"General Hospital waiting time?\",\n",
    "    \"Which ER is fastest?\",\n",
    "    \"Best hospital to visit when in a rush?\",\n",
    "    \"Best hospital to visit when in a rush, accounting for wait times and travel, not just based on queue length?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    result = er_agent_v4(query)\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"Result: {result}\")\n",
    "    print(\"=\" * 50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "42a878e3-ac43-4eaf-b400-da12732b6d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ QUERY: Which is faster: General Hospital or St. Mary Medical?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìç Step 1:\n",
      "LLM Response: get_queue_length(\"General Hospital\")\n",
      "Execution Result: 12\n",
      "\n",
      "üìç Step 2:\n",
      "LLM Response: get_queue_length(\"St. Mary Medical\")\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 3:\n",
      "LLM Response: get_treatment_time(\"General Hospital\")\n",
      "Execution Result: 25\n",
      "\n",
      "üìç Step 4:\n",
      "LLM Response: calculate_wait(12, 25)\n",
      "Execution Result: 300\n",
      "\n",
      "üìç Step 5:\n",
      "LLM Response: get_treatment_time(\"St. Mary Medical\")\n",
      "Execution Result: 45\n",
      "\n",
      "‚úÖ ANSWER: St. Mary Medical is faster. It has a shorter queue (5) and a treatment time of 45 minutes, while General Hospital has a queue of 12 and a treatment time of 25 minutes, resulting in a longer wait time of 300 minutes.\n",
      "\n",
      "==================================================\n",
      "üéØ QUERY: Find the hospital with the shortest wait time\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìç Step 1:\n",
      "LLM Response: list_hospitals()\n",
      "Execution Result: ['General Hospital', 'St. Mary Medical', 'City Emergency', 'University Hospital', 'Riverside Clinic']\n",
      "\n",
      "üìç Step 2:\n",
      "LLM Response: get_queue_length('General Hospital')\n",
      "Execution Result: 12\n",
      "\n",
      "üìç Step 3:\n",
      "LLM Response: get_queue_length('St. Mary Medical')\n",
      "Execution Result: 5\n",
      "\n",
      "üìç Step 4:\n",
      "LLM Response: get_queue_length('City Emergency')\n",
      "Execution Result: 18\n",
      "\n",
      "üìç Step 5:\n",
      "LLM Response: get_queue_length('University Hospital')\n",
      "Execution Result: 8\n",
      "\n",
      "‚úÖ ANSWER: The hospital with the shortest wait time is St. Mary Medical, with a queue length of 5.\n",
      "\n",
      "==================================================\n",
      "üéØ QUERY: If I go to City Emergency, how long including travel time?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìç Step 1:\n",
      "LLM Response: get_distance(\"City Emergency\")\n",
      "Execution Result: 1.2\n",
      "\n",
      "üìç Step 2:\n",
      "LLM Response: calculate_travel_time(1.2)\n",
      "Execution Result: 2.4\n",
      "\n",
      "üìç Step 3:\n",
      "LLM Response: get_queue_length(\"City Emergency\")\n",
      "Execution Result: 18\n",
      "\n",
      "üìç Step 4:\n",
      "LLM Response: get_treatment_time(\"City Emergency\")\n",
      "Execution Result: 35\n",
      "\n",
      "üìç Step 5:\n",
      "LLM Response: calculate_wait(18, 35)\n",
      "Execution Result: 630\n",
      "\n",
      "‚úÖ ANSWER: The total time, including travel, is approximately 633.4 minutes (or about 10.6 hours).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The total time, including travel, is approximately 633.4 minutes (or about 10.6 hours).'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er_agent_v4(\"Which is faster: General Hospital or St. Mary Medical?\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "er_agent_v4(\"Find the hospital with the shortest wait time\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "er_agent_v4(\"If I go to City Emergency, how long including travel time?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23720b3-4aaf-4bdb-ae84-193a67e39390",
   "metadata": {},
   "source": [
    "#### **EVOLUTION OF OUR AGENT**\n",
    "========================\n",
    "\n",
    "- **Version 1: Keyword Matching**:\n",
    "\n",
    "  ‚ùå Breaks with slight variations\n",
    "  \n",
    "  ‚ùå Can't understand meaning\n",
    "  \n",
    "- **Version 2: LLM Understanding**\n",
    "\n",
    "  ‚úÖ Understands meaning\n",
    "  \n",
    "  ‚ùå Still follows rigid patterns\n",
    "  \n",
    "- **Version 3: LLM Chooses Tools**\n",
    "\n",
    "  ‚úÖ Flexible tool selection\n",
    "  \n",
    "  ‚ùå Only one tool at a time (as subsequent tool calls may depend on previous call results)\n",
    "  \n",
    "- **Version 4: Executing steps in loop**\n",
    "\n",
    "  ‚úÖ Multiple steps\n",
    "  \n",
    "  ‚úÖ Can execute until a goal is met\n",
    "  \n",
    "  ‚úÖ No hardcoded pipelines!\n",
    "\n",
    "#### **PSEUDOCODE FOR THE AGENT LOOP:**\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "<pre>\n",
    "done = False\n",
    "while not done:\n",
    "    thought = think(query, context)     # What to do?\n",
    "    action = execute(thought)           # Do it\n",
    "    observation = observe(action)       # What happened?\n",
    "    if observation.is_done():\n",
    "        done = True                     # Stop if done\n",
    "    context.update(observation)         # Remember it if needed\n",
    "answer = finalize(context)\n",
    "return answer\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ac937-35dd-4aea-97c0-628d02d0791a",
   "metadata": {},
   "source": [
    "**What we just built in v4 has a name in AI research: ReAct (Reasoning and Acting)**\n",
    "\n",
    "It was introduced in this [paper](https://arxiv.org/abs/2210.03629)\n",
    "\n",
    "It uses something call ReAct prompting to allow a LLM to reason and act until a given goal is met.\n",
    "[ReAct Prompting Guide here](https://www.promptingguide.ai/techniques/react)\n",
    "\n",
    "<pre>\n",
    "The ReAct Loop:\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ              User Query                  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              ‚ñº\n",
    "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        ‚îÇ   THOUGHT   ‚îÇ ‚Üê \"What needs to be done?\"\n",
    "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              ‚ñº\n",
    "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        ‚îÇ   ACTION    ‚îÇ ‚Üê \"Execute the tool/function\"\n",
    "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              ‚ñº\n",
    "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        ‚îÇ OBSERVATION ‚îÇ ‚Üê \"What does the result mean?\"\n",
    "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              ‚ñº\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ Task Complete?    ‚îÇ\n",
    "    ‚îÇ No ‚Üí Loop back    ‚îÇ\n",
    "    ‚îÇ Yes ‚Üí Return      ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81bda72-5d3d-4c9d-a919-0af11206a95c",
   "metadata": {},
   "source": [
    "We've been using the term \"Agent\" for a while in this workshop. Let's go a bit deeper into exactly what that means.\n",
    "\n",
    "**[This](https://www.anthropic.com/engineering/building-effective-agents)** blog post by Anthropic explains the concept of \"Agents\" really well. So whenever we say \"agent\" in our project, for all intents and purposes we are thinking of the definition by Anthropic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5884cb2-81e9-4945-ac1b-8d520d538a66",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa8127c-1c2f-4404-87da-ea13d8de464d",
   "metadata": {},
   "source": [
    "## Building Our AI-Powered Analytics Assistant\n",
    "\n",
    "Now that we understand how agents work, let's briefly design our actual project.\n",
    "\n",
    "### What Users Want\n",
    "\n",
    "Imagine a user with a sales dataset like this:\n",
    "\n",
    "```\n",
    "date       | product  | category    | price | quantity | region\n",
    "-----------|----------|-------------|-------|----------|--------\n",
    "2024-01-01 | Laptop   | Electronics | 1200  | 2        | North\n",
    "2024-01-02 | Mouse    | Accessories | 25    | 10       | South\n",
    "2024-01-03 | Keyboard | Accessories | 75    | 5        | North\n",
    "2024-01-04 | Monitor  | Electronics | 300   | 3        | East\n",
    "2024-01-05 | Laptop   | Electronics | 1200  | 1        | South\n",
    "...\n",
    "```\n",
    "\n",
    "They'll ask things like:\n",
    "- \"Show me the data\"\n",
    "- \"Filter for sales above $1000\"\n",
    "- \"What's the average price by category?\"\n",
    "- \"Plot sales over time\"\n",
    "- \"Which region has the fastest growing sales?\"\n",
    "\n",
    "### From Queries to Tools\n",
    "\n",
    "Looking at these queries, we see patterns:\n",
    "- **Everything needs data loaded** ‚Üí `load_csv()`\n",
    "- **Users want to see data** ‚Üí `show_data()`, `show_info()`\n",
    "- **Lots of filtering** ‚Üí `filter_rows()`\n",
    "- **Aggregations everywhere** ‚Üí `group_and_aggregate()`\n",
    "- **Visual understanding** ‚Üí `create_plot()`\n",
    "\n",
    "### Tool Design Philosophy\n",
    "\n",
    "Instead of one mega-tool or overly specific tools, we usually want **composable operations** (but does depend on the use case):\n",
    "\n",
    "```python\n",
    "# ‚ùå Too broad\n",
    "def analyze_data(operation, **params)\n",
    "\n",
    "# ‚ùå Too specific\n",
    "def show_sales_by_region()\n",
    "\n",
    "# ‚úÖ Just right - composable!\n",
    "def filter_rows(condition)\n",
    "def group_and_aggregate(group_by, column, operation)\n",
    "```\n",
    "\n",
    "Each tool does ONE thing. The LLM combines them intelligently to answer complex queries.\n",
    "\n",
    "### Our Starting Toolset\n",
    "\n",
    "We'll keep it simple and start with these capabilities:\n",
    "\n",
    "```\n",
    "load_csv(filepath)\n",
    "show_info()\n",
    "show_data(n_rows)\n",
    "filter_rows(condition)\n",
    "group_and_aggregate(group_by, column, operation)\n",
    "calculate_statistics(column, stat_type)\n",
    "create_plot(plot_type, **kwargs)\n",
    "... and a few more\n",
    "```\n",
    "\n",
    "### Simulation\n",
    "\n",
    "**Query**: \"What's the average price by category?\"\n",
    "\n",
    "**Agent breaks it down**:\n",
    "1. Group by category\n",
    "2. Calculate mean of price\n",
    "3. Return formatted results\n",
    "\n",
    "Just like our ER agent, but now with pandas operations instead of ER queries!\n",
    "\n",
    "### Before Next Week\n",
    "\n",
    "Think about:\n",
    "1. What 3-5 queries would you ask YOUR data?\n",
    "2. Think about what tools make sense for your data and domain\n",
    "3. Think about the granularity of the tools\n",
    "\n",
    "In the next workshop, we'll build one version of the assistant with a dataset of my choice together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba117e3-c3c2-4cad-811c-5d38175312aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
