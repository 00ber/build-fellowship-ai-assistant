{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 3: Building AI Agents -- Foundations\n",
    "\n",
    "Last week we explored how LLMs work and how to guide them with prompts and structured extraction. Today we push further: we discover what LLMs *cannot* do, what they *can* do surprisingly well, and how combining those abilities creates something powerful -- an AI agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "from utils.display import output_box, llm_response, separator\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "\n",
    "def generate(prompt, temperature=0):\n",
    "    \"\"\"Generate a response from the LLM. Same helper from Workshop 2.\"\"\"\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: What LLMs Can and Cannot Do\n",
    "\n",
    "Last week we learned how LLMs work -- predicting the next token -- and how to guide them with prompts and structured extraction. Today we'll push further: what happens when we need LLMs to DO things in the real world?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can the LLM do math?\n",
    "response = generate(\"What is 1,847 x 293? Give me just the number.\")\n",
    "\n",
    "llm_response(response, label=\"LLM's Answer\")\n",
    "print(f\"Actual answer: {1847 * 293:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM attempted the math but may be wrong. It generates text that *looks like* math -- predicting plausible tokens -- but it never actually runs a multiplication algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can the LLM check the current time?\n",
    "response = generate(\"What is the exact current time right now?\")\n",
    "\n",
    "llm_response(response, label=\"LLM on Current Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can the LLM check today's weather?\n",
    "response = generate(\"What is the weather like in New York City right now?\")\n",
    "\n",
    "llm_response(response, label=\"LLM on Live Weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can the LLM read a file on our computer?\n",
    "response = generate(\"List all the files in my current directory.\")\n",
    "\n",
    "llm_response(response, label=\"LLM on Local Files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight:** LLMs can only generate text. They cannot perform calculations, access files, check the time, or fetch live data. Everything they produce is a prediction of what text should come next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: But LLMs Can Plan\n",
    "\n",
    "We just saw that LLMs cannot *do* things. But notice something interesting -- when asked about files, the LLM described exactly *how* to list files. Let's explore this ability further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can the LLM plan how to find a restaurant's wait time?\n",
    "response = generate(\n",
    "    \"If I wanted to know the wait time at a restaurant, \"\n",
    "    \"what steps would I need to take?\"\n",
    ")\n",
    "\n",
    "llm_response(response, label=\"LLM's Plan for Wait Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can the LLM plan how to find the cheapest restaurant?\n",
    "response = generate(\n",
    "    \"If I wanted to find the cheapest restaurant nearby, \"\n",
    "    \"what information would I need to gather?\"\n",
    ")\n",
    "\n",
    "llm_response(response, label=\"LLM's Plan for Cheapest Restaurant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_box(\n",
    "    \"LLMs are excellent at understanding questions and describing what needs \"\n",
    "    \"to be done. What if instead of asking LLMs to DO things, we ask them to \"\n",
    "    \"PLAN what needs to be done -- and then a system executes the plan?\",\n",
    "    label=\"KEY INSIGHT\",\n",
    "    style=\"warning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: From Text to Data (W2 Refresher)\n",
    "\n",
    "Our scenario today: helping people find restaurants. We have some restaurant info, but it's buried in messy text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstructured restaurant descriptions (first 3)\n",
    "RESTAURANT_DESCRIPTIONS = {\n",
    "    \"Olive Garden\": (\n",
    "        \"A family-friendly Italian chain known for their unlimited \"\n",
    "        \"breadsticks and pasta. Typical dinner runs $15-25 per person. \"\n",
    "        \"Vegetarian options available including eggplant parm and \"\n",
    "        \"pasta primavera. Located on Main Street, about 5 minutes \"\n",
    "        \"from downtown. Open until 10 PM on weekdays.\"\n",
    "    ),\n",
    "    \"Sushi Palace\": (\n",
    "        \"An upscale Japanese restaurant with an extensive omakase \"\n",
    "        \"menu. Expect to spend $35-60 per person for dinner. Limited \"\n",
    "        \"vegetarian options, mostly edamame and veggie rolls. Tucked \"\n",
    "        \"away in the arts district. Closes at 11 PM most nights.\"\n",
    "    ),\n",
    "    \"Burger Barn\": (\n",
    "        \"A no-frills burger joint with the best smash burgers in town. \"\n",
    "        \"Meals run $8-15 per person. They have a black bean burger \"\n",
    "        \"for vegetarians. Right next to the highway exit, very easy \"\n",
    "        \"to find. Kitchen closes at 9 PM sharp.\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstructured restaurant descriptions (remaining 3)\n",
    "RESTAURANT_DESCRIPTIONS.update({\n",
    "    \"Taj Mahal\": (\n",
    "        \"Authentic Indian cuisine with a wood-fired tandoor oven. \"\n",
    "        \"Dinner is typically $18-30 per person. Excellent vegetarian \"\n",
    "        \"selection with paneer dishes, dal, and veggie biryani. \"\n",
    "        \"Located in the university quarter. Open until 10:30 PM.\"\n",
    "    ),\n",
    "    \"Dragon Wok\": (\n",
    "        \"A popular Chinese takeout spot with generous portions. Most \"\n",
    "        \"dishes are $10-18 per person. A few vegetarian stir-fry \"\n",
    "        \"options available. Situated on the east side near the park. \"\n",
    "        \"Open until 9:30 PM, later on weekends.\"\n",
    "    ),\n",
    "    \"La Piazza\": (\n",
    "        \"Fine dining Italian with handmade pasta and an award-winning \"\n",
    "        \"wine list. Plan on $45-80 per person for a full dinner. \"\n",
    "        \"Vegetarian tasting menu available on request. Located in \"\n",
    "        \"the waterfront district with beautiful views. Closes at \"\n",
    "        \"11 PM, reservations recommended.\"\n",
    "    ),\n",
    "})\n",
    "\n",
    "# Show one example\n",
    "print(\"Olive Garden description:\")\n",
    "print(RESTAURANT_DESCRIPTIONS[\"Olive Garden\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pydantic model to extract structured info\n",
    "# Same structured extraction pattern from Workshop 2\n",
    "\n",
    "class RestaurantInfo(BaseModel):\n",
    "    price_per_person_low: int\n",
    "    price_per_person_high: int\n",
    "    has_vegetarian: bool\n",
    "    closing_time: str\n",
    "    special_notes: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract structured data from one description\n",
    "completion = openai_client.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract restaurant information from the description.\"},\n",
    "        {\"role\": \"user\", \"content\": RESTAURANT_DESCRIPTIONS[\"Olive Garden\"]}\n",
    "    ],\n",
    "    response_format=RestaurantInfo,\n",
    ")\n",
    "\n",
    "info = completion.choices[0].message.parsed\n",
    "\n",
    "print(f\"Price range: ${info.price_per_person_low}-${info.price_per_person_high}\")\n",
    "print(f\"Vegetarian options: {info.has_vegetarian}\")\n",
    "print(f\"Closing time: {info.closing_time}\")\n",
    "print(f\"Notes: {info.special_notes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight:** This is the same structured extraction from last week -- now used as a building block. We can turn messy text into clean data that tools can work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: From Planning to Execution\n",
    "\n",
    "We know LLMs can plan and we know how to structure data. Now let's see if an LLM can tell a system which function to call -- and the system can actually execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restaurant structured data -- used by agent tools\n",
    "RESTAURANTS = {\n",
    "    \"Olive Garden\": {\"cuisine\": \"Italian\", \"price_range\": \"$$\", \"rating\": 4.2, \"distance_miles\": 2.5},\n",
    "    \"Sushi Palace\": {\"cuisine\": \"Japanese\", \"price_range\": \"$$$\", \"rating\": 4.7, \"distance_miles\": 5.0},\n",
    "    \"Burger Barn\": {\"cuisine\": \"American\", \"price_range\": \"$\", \"rating\": 3.8, \"distance_miles\": 1.0},\n",
    "    \"Taj Mahal\": {\"cuisine\": \"Indian\", \"price_range\": \"$$\", \"rating\": 4.5, \"distance_miles\": 3.2},\n",
    "    \"Dragon Wok\": {\"cuisine\": \"Chinese\", \"price_range\": \"$\", \"rating\": 4.0, \"distance_miles\": 4.5},\n",
    "    \"La Piazza\": {\"cuisine\": \"Italian\", \"price_range\": \"$$$\", \"rating\": 4.8, \"distance_miles\": 6.0},\n",
    "}\n",
    "\n",
    "# Simulated real-time wait times (minutes)\n",
    "WAIT_TIMES = {\n",
    "    \"Olive Garden\": 25,\n",
    "    \"Sushi Palace\": 45,\n",
    "    \"Burger Barn\": 5,\n",
    "    \"Taj Mahal\": 15,\n",
    "    \"Dragon Wok\": 30,\n",
    "    \"La Piazza\": 60,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple tool functions\n",
    "\n",
    "def get_wait_time(restaurant):\n",
    "    \"\"\"Get current wait time in minutes at a restaurant.\"\"\"\n",
    "    for name, wait in WAIT_TIMES.items():\n",
    "        if name.lower() == restaurant.lower():\n",
    "            return wait\n",
    "    available = \", \".join(WAIT_TIMES.keys())\n",
    "    return f\"Restaurant '{restaurant}' not found. Available: {available}\"\n",
    "\n",
    "\n",
    "def get_rating(restaurant):\n",
    "    \"\"\"Get the rating (1-5 stars) for a restaurant.\"\"\"\n",
    "    for name, info in RESTAURANTS.items():\n",
    "        if name.lower() == restaurant.lower():\n",
    "            return info[\"rating\"]\n",
    "    available = \", \".join(RESTAURANTS.keys())\n",
    "    return f\"Restaurant '{restaurant}' not found. Available: {available}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the tools\n",
    "print(f\"Wait time at Olive Garden: {get_wait_time('Olive Garden')} minutes\")\n",
    "print(f\"Rating of Sushi Palace: {get_rating('Sushi Palace')} stars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM to generate a function call\n",
    "prompt = (\n",
    "    \"Given these available functions:\\n\"\n",
    "    \"- get_wait_time(restaurant) - Get current wait time in minutes\\n\"\n",
    "    \"- get_rating(restaurant) - Get rating (1-5 stars)\\n\\n\"\n",
    "    \"What function call would answer: \"\n",
    "    \"'How long is the wait at Olive Garden?'\\n\\n\"\n",
    "    \"Respond with ONLY the function call, nothing else.\"\n",
    ")\n",
    "\n",
    "function_call_text = generate(prompt)\n",
    "\n",
    "llm_response(function_call_text, label=\"LLM Generated Function Call\")\n",
    "print(f\"Type: {type(function_call_text).__name__} -- still just text!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the LLM's function call\n",
    "tools_dict = {\n",
    "    \"get_wait_time\": get_wait_time,\n",
    "    \"get_rating\": get_rating,\n",
    "}\n",
    "\n",
    "# Strip any markdown code fences the LLM may have added\n",
    "clean_call = function_call_text.strip()\n",
    "if clean_call.startswith(\"```\"):\n",
    "    clean_call = clean_call.split(\"\\n\")[1]\n",
    "    if clean_call.endswith(\"```\"):\n",
    "        clean_call = clean_call[:-3]\n",
    "\n",
    "result = eval(clean_call, {\"__builtins__\": {}}, tools_dict)\n",
    "\n",
    "print(f\"Function call: {clean_call}\")\n",
    "print(f\"Result: {result} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete flow: user question -> LLM plans -> system executes\n",
    "user_question = \"What's the rating of Sushi Palace?\"\n",
    "\n",
    "separator(\"Step 1: User asks a question\")\n",
    "print(f\"User: {user_question}\")\n",
    "\n",
    "separator(\"Step 2: LLM decides which function to call\")\n",
    "plan_prompt = (\n",
    "    \"Given these available functions:\\n\"\n",
    "    \"- get_wait_time(restaurant) - Get current wait time in minutes\\n\"\n",
    "    \"- get_rating(restaurant) - Get rating (1-5 stars)\\n\\n\"\n",
    "    f\"What function call would answer: '{user_question}'\\n\\n\"\n",
    "    \"Respond with ONLY the function call, nothing else.\"\n",
    ")\n",
    "planned_call = generate(plan_prompt)\n",
    "print(f\"LLM says: {planned_call}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the planned call and show the result\n",
    "separator(\"Step 3: System executes the function\")\n",
    "clean_call = planned_call.strip()\n",
    "if clean_call.startswith(\"```\"):\n",
    "    clean_call = clean_call.split(\"\\n\")[1]\n",
    "    if clean_call.endswith(\"```\"):\n",
    "        clean_call = clean_call[:-3]\n",
    "result = eval(clean_call, {\"__builtins__\": {}}, tools_dict)\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "separator(\"Step 4: Result returned to user\")\n",
    "output_box(\n",
    "    f\"Question: {user_question}\\n\"\n",
    "    f\"Answer: {result}\",\n",
    "    label=\"Final Answer\",\n",
    "    style=\"success\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight:** The LLM never executed anything itself. It generated a function call as text, and our system ran it. This pattern -- LLM plans, system executes -- is the core idea behind AI agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We Discovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_box(\n",
    "    \"1. User asks a question\\n\"\n",
    "    \"2. LLM decides which function to call\\n\"\n",
    "    \"3. System executes the function\\n\"\n",
    "    \"4. Result comes back to the user\\n\\n\"\n",
    "    \"This is the foundation of how agents work.\",\n",
    "    label=\"What We Discovered\",\n",
    "    style=\"success\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
