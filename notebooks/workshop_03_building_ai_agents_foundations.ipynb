{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 3: Building AI Agents -- Foundations\n",
    "\n",
    "Last week we explored how LLMs work and how to guide them with prompts and structured extraction. Today we push further -- we'll code our way up to AI agents and discover what makes them work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "from utils.display import output_box, llm_response, separator\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "\n",
    "def generate(prompt, temperature=0):\n",
    "    \"\"\"Generate a response from the LLM. Same helper from Workshop 2.\"\"\"\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Let's Test the LLM\n",
    "\n",
    "Last week we learned how LLMs work and how to guide them with prompts. Today let's push further -- what happens when we ask an LLM to do something beyond generating text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can the LLM do math?\n",
    "response = generate(\"What is 1,847 x 293? Give me just the number.\")\n",
    "\n",
    "llm_response(response, label=\"LLM's Answer\")\n",
    "print(f\"Actual answer: {1847 * 293:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting -- the LLM gave us a number, but is it right? It generates text that *looks like* math -- predicting plausible tokens -- but it never actually runs a multiplication algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can the LLM check the current time?\n",
    "response = generate(\"What is the exact current time right now?\")\n",
    "\n",
    "llm_response(response, label=\"LLM on Current Time\")",
    "\n",
    "# Can the LLM check today's weather?\n",
    "response = generate(\"What is the weather like in New York City right now?\")\n",
    "\n",
    "llm_response(response, label=\"LLM on Live Weather\")",
    "\n",
    "# Can the LLM read a file on our computer?\n",
    "response = generate(\"List all the files in my current directory.\")\n",
    "\n",
    "llm_response(response, label=\"LLM on Local Files\")",
    "\n",
    "# Can the LLM check today's weather?\n",
    "response = generate(\"What is the weather like in New York City right now?\")\n",
    "\n",
    "llm_response(response, label=\"LLM on Live Weather\")",
    "\n",
    "# Can the LLM read a file on our computer?\n",
    "response = generate(\"List all the files in my current directory.\")\n",
    "\n",
    "llm_response(response, label=\"LLM on Local Files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight:** Did you notice the pattern? In every case -- math, time, files, weather -- the LLM produced text that *looks like* an answer but never actually performed the action. LLMs can only generate text. They cannot perform calculations, access files, check the time, or fetch live data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Wait -- Something Interesting Happened\n",
    "\n",
    "We just saw that LLMs cannot *do* things. But look back at those responses -- when asked about files, the LLM described exactly *how* to list files. When asked about time, it explained *how* to check. Let's explore this ability further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can the LLM plan how to find a restaurant's wait time?\n",
    "response = generate(\n",
    "    \"If I wanted to know the wait time at a restaurant, \"\n",
    "    \"what steps would I need to take?\"\n",
    ")\n",
    "\n",
    "llm_response(response, label=\"LLM's Plan for Wait Time\")",
    "\n",
    "# Can the LLM plan how to find the cheapest restaurant?\n",
    "response = generate(\n",
    "    \"If I wanted to find the cheapest restaurant nearby, \"\n",
    "    \"what information would I need to gather?\"\n",
    ")\n",
    "\n",
    "llm_response(response, label=\"LLM's Plan for Cheapest Restaurant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_box(\n",
    "    \"What if instead of asking LLMs to DO things, we ask them to \"\n",
    "    \"PLAN what needs to be done -- and then a system executes the plan?\",\n",
    "    label=\"THE KEY QUESTION\",\n",
    "    style=\"warning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: From Text to Data (W2 Refresher)\n",
    "\n",
    "To explore this idea, we need data to work with. Our scenario today: helping people find restaurants. We have some restaurant info, but it's buried in messy text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstructured restaurant descriptions (first 3)\n",
    "RESTAURANT_DESCRIPTIONS = {\n",
    "    \"Olive Garden\": (\n",
    "        \"A family-friendly Italian chain known for their unlimited \"\n",
    "        \"breadsticks and pasta. Typical dinner runs $15-25 per person. \"\n",
    "        \"Vegetarian options available including eggplant parm and \"\n",
    "        \"pasta primavera. Located on Main Street, about 5 minutes \"\n",
    "        \"from downtown. Open until 10 PM on weekdays.\"\n",
    "    ),\n",
    "    \"Sushi Palace\": (\n",
    "        \"An upscale Japanese restaurant with an extensive omakase \"\n",
    "        \"menu. Expect to spend $35-60 per person for dinner. Limited \"\n",
    "        \"vegetarian options, mostly edamame and veggie rolls. Tucked \"\n",
    "        \"away in the arts district. Closes at 11 PM most nights.\"\n",
    "    ),\n",
    "    \"Burger Barn\": (\n",
    "        \"A no-frills American burger joint with the best smash burgers in town. \"\n",
    "        \"Meals run $8-15 per person. They have a black bean burger \"\n",
    "        \"for vegetarians. Right next to the highway exit, very easy \"\n",
    "        \"to find. Kitchen closes at 9 PM sharp.\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstructured restaurant descriptions (remaining 3)\n",
    "RESTAURANT_DESCRIPTIONS.update({\n",
    "    \"Taj Mahal\": (\n",
    "        \"Authentic Indian cuisine with a wood-fired tandoor oven. \"\n",
    "        \"Dinner is typically $18-30 per person. Excellent vegetarian \"\n",
    "        \"selection with paneer dishes, dal, and veggie biryani. \"\n",
    "        \"Located in the university quarter. Open until 10:30 PM.\"\n",
    "    ),\n",
    "    \"Dragon Wok\": (\n",
    "        \"A popular Chinese takeout spot with generous portions. Most \"\n",
    "        \"dishes are $10-18 per person. A few vegetarian stir-fry \"\n",
    "        \"options available. Situated on the east side near the park. \"\n",
    "        \"Open until 9:30 PM, later on weekends.\"\n",
    "    ),\n",
    "    \"La Piazza\": (\n",
    "        \"Fine dining Italian with handmade pasta and an award-winning \"\n",
    "        \"wine list. Plan on $45-80 per person for a full dinner. \"\n",
    "        \"Vegetarian tasting menu available on request. Located in \"\n",
    "        \"the waterfront district with beautiful views. Closes at \"\n",
    "        \"11 PM, reservations recommended.\"\n",
    "    ),\n",
    "})\n",
    "\n",
    "# Show one example\n",
    "print(\"Olive Garden description:\")\n",
    "print(RESTAURANT_DESCRIPTIONS[\"Olive Garden\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pydantic model to extract structured info\n",
    "# Same structured extraction pattern from Workshop 2\n",
    "\n",
    "class RestaurantInfo(BaseModel):\n",
    "    cuisine: str\n",
    "    price_per_person_low: int\n",
    "    price_per_person_high: int\n",
    "    has_vegetarian: bool\n",
    "    closing_time: str\n",
    "    notes: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract structured data from one description\n",
    "completion = openai_client.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract restaurant information from the description.\"},\n",
    "        {\"role\": \"user\", \"content\": RESTAURANT_DESCRIPTIONS[\"Olive Garden\"]}\n",
    "    ],\n",
    "    response_format=RestaurantInfo,\n",
    ")\n",
    "\n",
    "info = completion.choices[0].message.parsed\n",
    "\n",
    "print(f\"Cuisine: {info.cuisine}\")\n",
    "print(f\"Price range: ${info.price_per_person_low}-${info.price_per_person_high}\")\n",
    "print(f\"Vegetarian options: {info.has_vegetarian}\")\n",
    "print(f\"Closing time: {info.closing_time}\")\n",
    "print(f\"Notes: {info.notes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract from ALL restaurant descriptions\n",
    "extracted = {}\n",
    "for name, description in RESTAURANT_DESCRIPTIONS.items():\n",
    "    completion = openai_client.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract restaurant information from the description.\"},\n",
    "            {\"role\": \"user\", \"content\": description}\n",
    "        ],\n",
    "        response_format=RestaurantInfo,\n",
    "    )\n",
    "    extracted[name] = completion.choices[0].message.parsed\n",
    "    print(f\"{name}: {extracted[name].cuisine}, ${extracted[name].price_per_person_low}-${extracted[name].price_per_person_high}\")\n",
    "\n",
    "print(f\"\\nExtracted structured data from {len(extracted)} restaurants.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight:** This is the same structured extraction from last week -- now used as a building block. We can turn messy text into clean data that tools can work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Can the LLM Actually Use a Tool?\n",
    "\n",
    "We know LLMs can describe what needs to be done and we know how to structure data. Now let's test something: can an LLM tell a system which function to call -- and can the system actually execute it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build restaurant data from extraction results + other data sources\n",
    "RESTAURANTS = {}\n",
    "for name, info in extracted.items():\n",
    "    RESTAURANTS[name] = {\n",
    "        \"cuisine\": info.cuisine,\n",
    "        \"price_per_person_low\": info.price_per_person_low,\n",
    "        \"price_per_person_high\": info.price_per_person_high,\n",
    "        \"has_vegetarian\": info.has_vegetarian,\n",
    "        \"closing_time\": info.closing_time,\n",
    "        \"notes\": info.notes,\n",
    "    }\n",
    "\n",
    "# Ratings from review aggregator (separate data source)\n",
    "RATINGS = {\n",
    "    \"Olive Garden\": 4.2, \"Sushi Palace\": 4.7, \"Burger Barn\": 3.8,\n",
    "    \"Taj Mahal\": 4.5, \"Dragon Wok\": 4.0, \"La Piazza\": 4.8,\n",
    "}\n",
    "\n",
    "# Distance depends on the user's location (not a restaurant property)\n",
    "DISTANCES = {\n",
    "    \"Olive Garden\": 2.5, \"Sushi Palace\": 5.0, \"Burger Barn\": 1.0,\n",
    "    \"Taj Mahal\": 3.2, \"Dragon Wok\": 4.5, \"La Piazza\": 6.0,\n",
    "}\n",
    "\n",
    "for name in RESTAURANTS:\n",
    "    RESTAURANTS[name][\"rating\"] = RATINGS[name]\n",
    "    RESTAURANTS[name][\"distance_miles\"] = DISTANCES[name]\n",
    "\n",
    "# Simulated real-time wait times (changes every minute in theory)\n",
    "WAIT_TIMES = {\n",
    "    \"Olive Garden\": 25, \"Sushi Palace\": 45, \"Burger Barn\": 5,\n",
    "    \"Taj Mahal\": 15, \"Dragon Wok\": 30, \"La Piazza\": 60,\n",
    "}\n",
    "\n",
    "# Show what our tools will work with\n",
    "print(\"Restaurant data (extraction + live sources):\\n\")\n",
    "for name, data in RESTAURANTS.items():\n",
    "    print(f\"  {name}:\")\n",
    "    print(f\"    Cuisine: {data['cuisine']}\")\n",
    "    print(f\"    Price: ${data['price_per_person_low']}-${data['price_per_person_high']}/person\")\n",
    "    print(f\"    Vegetarian: {'Yes' if data['has_vegetarian'] else 'No'}\")\n",
    "    print(f\"    Rating: {data['rating']} stars, {data['distance_miles']} mi away\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple tool functions\n",
    "\n",
    "def get_wait_time(restaurant):\n",
    "    \"\"\"Get current wait time in minutes at a restaurant.\"\"\"\n",
    "    for name, wait in WAIT_TIMES.items():\n",
    "        if name.lower() == restaurant.lower():\n",
    "            return wait\n",
    "    available = \", \".join(WAIT_TIMES.keys())\n",
    "    return f\"Restaurant '{restaurant}' not found. Available: {available}\"\n",
    "\n",
    "\n",
    "def get_rating(restaurant):\n",
    "    \"\"\"Get the rating (1-5 stars) for a restaurant.\"\"\"\n",
    "    for name, info in RESTAURANTS.items():\n",
    "        if name.lower() == restaurant.lower():\n",
    "            return info[\"rating\"]\n",
    "    available = \", \".join(RESTAURANTS.keys())\n",
    "    return f\"Restaurant '{restaurant}' not found. Available: {available}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the tools\n",
    "print(f\"Wait time at Olive Garden: {get_wait_time('Olive Garden')} minutes\")\n",
    "print(f\"Rating of Sushi Palace: {get_rating('Sushi Palace')} stars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM to generate a function call\n",
    "prompt = (\n",
    "    \"Given these available functions:\\n\"\n",
    "    \"- get_wait_time(restaurant) - Get current wait time in minutes\\n\"\n",
    "    \"- get_rating(restaurant) - Get rating (1-5 stars)\\n\\n\"\n",
    "    \"What function call would answer: \"\n",
    "    \"'How long is the wait at Olive Garden?'\\n\\n\"\n",
    "    \"Respond with ONLY the function call, nothing else.\"\n",
    ")\n",
    "\n",
    "function_call_text = generate(prompt)\n",
    "\n",
    "llm_response(function_call_text, label=\"LLM Generated Function Call\")\n",
    "print(f\"Type: {type(function_call_text).__name__} -- still just text!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the LLM's function call\n",
    "tools_dict = {\n",
    "    \"get_wait_time\": get_wait_time,\n",
    "    \"get_rating\": get_rating,\n",
    "}\n",
    "\n",
    "# Strip any markdown code fences the LLM may have added\n",
    "clean_call = function_call_text.strip()\n",
    "if clean_call.startswith(\"```\"):\n",
    "    clean_call = clean_call.split(\"\\n\")[1]\n",
    "    if clean_call.endswith(\"```\"):\n",
    "        clean_call = clean_call[:-3]\n",
    "\n",
    "result = eval(clean_call, {\"__builtins__\": {}}, tools_dict)\n",
    "\n",
    "print(f\"Function call: {clean_call}\")\n",
    "print(f\"Result: {result} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete flow: user question -> LLM plans -> system executes\n",
    "user_question = \"What's the rating of Sushi Palace?\"\n",
    "\n",
    "separator(\"Step 1: User asks a question\")\n",
    "print(f\"User: {user_question}\")\n",
    "\n",
    "separator(\"Step 2: LLM decides which function to call\")\n",
    "plan_prompt = (\n",
    "    \"Given these available functions:\\n\"\n",
    "    \"- get_wait_time(restaurant) - Get current wait time in minutes\\n\"\n",
    "    \"- get_rating(restaurant) - Get rating (1-5 stars)\\n\\n\"\n",
    "    f\"What function call would answer: '{user_question}'\\n\\n\"\n",
    "    \"Respond with ONLY the function call, nothing else.\"\n",
    ")\n",
    "planned_call = generate(plan_prompt)\n",
    "print(f\"LLM says: {planned_call}\")",
    "\n",
    "# Execute the planned call and show the result\n",
    "separator(\"Step 3: System executes the function\")\n",
    "clean_call = planned_call.strip()\n",
    "if clean_call.startswith(\"```\"):\n",
    "    clean_call = clean_call.split(\"\\n\")[1]\n",
    "    if clean_call.endswith(\"```\"):\n",
    "        clean_call = clean_call[:-3]\n",
    "result = eval(clean_call, {\"__builtins__\": {}}, tools_dict)\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "separator(\"Step 4: Result returned to user\")\n",
    "output_box(\n",
    "    f\"Question: {user_question}\\n\"\n",
    "    f\"Answer: {result}\",\n",
    "    label=\"Final Answer\",\n",
    "    style=\"success\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight:** Did you notice what just happened? The LLM never executed anything itself -- it generated a function call as text, and our system ran it. This pattern -- LLM plans, system executes -- is the core idea behind AI agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_box(\n",
    "    \"1. User asks a question\\n\"\n",
    "    \"2. LLM decides which function to call\\n\"\n",
    "    \"3. System executes the function\\n\"\n",
    "    \"4. Result comes back to the user\\n\\n\"\n",
    "    \"This is the foundation of how agents work.\",\n",
    "    label=\"What We Discovered\",\n",
    "    style=\"success\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Restaurant Finder -- Building Our Scenario\n",
    "\n",
    "Now let's build something real to test our idea. Imagine a restaurant finder that can answer questions like \"What's the shortest wait near me?\" or \"Best-rated Italian place?\" First, we need tools the agent can call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All 7 tool functions for our Restaurant Finder agent\n",
    "\n",
    "def get_wait_time(restaurant):\n",
    "    \"\"\"Get current wait time in minutes at a restaurant.\"\"\"\n",
    "    for name, wait in WAIT_TIMES.items():\n",
    "        if name.lower() == restaurant.lower():\n",
    "            return wait\n",
    "    available = \", \".join(WAIT_TIMES.keys())\n",
    "    return f\"Restaurant '{restaurant}' not found. Available: {available}\"\n",
    "\n",
    "\n",
    "def get_rating(restaurant):\n",
    "    \"\"\"Get the rating (1-5 stars) for a restaurant.\"\"\"\n",
    "    for name, info in RESTAURANTS.items():\n",
    "        if name.lower() == restaurant.lower():\n",
    "            return info[\"rating\"]\n",
    "    available = \", \".join(RESTAURANTS.keys())\n",
    "    return f\"Restaurant '{restaurant}' not found. Available: {available}\"\n",
    "\n",
    "\n",
    "def get_distance(restaurant):\n",
    "    \"\"\"Get distance in miles to the restaurant.\"\"\"\n",
    "    for name, info in RESTAURANTS.items():\n",
    "        if name.lower() == restaurant.lower():\n",
    "            return info[\"distance_miles\"]\n",
    "    available = \", \".join(RESTAURANTS.keys())\n",
    "    return f\"Restaurant '{restaurant}' not found. Available: {available}\"\n",
    "\n",
    "\n",
    "def get_cuisine(restaurant):\n",
    "    \"\"\"Get the cuisine type of a restaurant.\"\"\"\n",
    "    for name, info in RESTAURANTS.items():\n",
    "        if name.lower() == restaurant.lower():\n",
    "            return info[\"cuisine\"]\n",
    "    available = \", \".join(RESTAURANTS.keys())\n",
    "    return f\"Restaurant '{restaurant}' not found. Available: {available}\"\n",
    "\n",
    "\n",
    "def get_price_range(restaurant):\n",
    "    \"\"\"Get the price range ($, $$, $$$) of a restaurant.\"\"\"\n",
    "    for name, info in RESTAURANTS.items():\n",
    "        if name.lower() == restaurant.lower():\n",
    "            return info[\"price_range\"]\n",
    "    available = \", \".join(RESTAURANTS.keys())\n",
    "    return f\"Restaurant '{restaurant}' not found. Available: {available}\"\n",
    "\n",
    "\n",
    "def calculate_travel_time(distance):\n",
    "    \"\"\"Calculate travel time in minutes. Assumes 2 minutes per mile.\"\"\"\n",
    "    return round(distance * 2, 1)\n",
    "\n",
    "\n",
    "def list_restaurants():\n",
    "    \"\"\"Get a list of all nearby restaurants.\"\"\"\n",
    "    return list(RESTAURANTS.keys())\n",
    "\n",
    "\n",
    "print(\"All 7 tool functions defined:\")\n",
    "print(\"  get_wait_time(restaurant)      - Wait time in minutes\")\n",
    "print(\"  get_rating(restaurant)          - Rating (1-5 stars)\")\n",
    "print(\"  get_distance(restaurant)        - Distance in miles\")\n",
    "print(\"  get_cuisine(restaurant)         - Cuisine type\")\n",
    "print(\"  get_price_range(restaurant)     - Price range ($, $$, $$$)\")\n",
    "print(\"  calculate_travel_time(distance) - Travel time in minutes\")\n",
    "print(\"  list_restaurants()              - All restaurant names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test individual tools\n",
    "print(f\"Wait time at Olive Garden: {get_wait_time('Olive Garden')} minutes\")\n",
    "print(f\"Rating of Sushi Palace: {get_rating('Sushi Palace')} stars\")\n",
    "print(f\"Distance to Burger Barn: {get_distance('Burger Barn')} miles\")",
    "\n",
    "# Test list_restaurants and calculate_travel_time\n",
    "print(\"All restaurants:\")\n",
    "for r in list_restaurants():\n",
    "    print(f\"  - {r}\")\n",
    "\n",
    "print(f\"\\nTravel time for 3.2 miles: {calculate_travel_time(3.2)} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual walkthrough: \"What's the wait at Olive Garden?\"\n",
    "# This is a simple single-tool query\n",
    "\n",
    "separator(\"Manual Walkthrough: Simple Query\")\n",
    "print(\"Question: What's the wait at Olive Garden?\")\n",
    "print(\"\\nTo answer this, we just need one tool call -- straightforward.\")\n",
    "print(f\"\\nStep 1: Call get_wait_time('Olive Garden')\")\n",
    "\n",
    "wait = get_wait_time(\"Olive Garden\")\n",
    "print(f\"Result: {wait} minutes\")\n",
    "\n",
    "print(f\"\\nAnswer: The wait at Olive Garden is {wait} minutes.\")\n",
    "print(\"\\nThat was easy -- one question, one tool call, done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual walkthrough: \"What's the cheapest restaurant within 10 minutes?\"\n",
    "\n",
    "separator(\"Manual Walkthrough: Complex Query\")\n",
    "print(\"Question: What's the cheapest restaurant within 10 minutes?\")\n",
    "\n",
    "separator(\"Step 1: Get all restaurants\")\n",
    "all_restaurants = list_restaurants()\n",
    "print(f\"Restaurants: {all_restaurants}\")\n",
    "\n",
    "separator(\"Step 2: Check distance for each\")\n",
    "for r in all_restaurants:\n",
    "    d = get_distance(r)\n",
    "    print(f\"  {r}: {d} miles\")\n",
    "\n",
    "separator(\"Step 3: Calculate travel times and filter\")\n",
    "within_10 = []\n",
    "for r in all_restaurants:\n",
    "    d = get_distance(r)\n",
    "    t = calculate_travel_time(d)\n",
    "    status = \"YES\" if t <= 10 else \"no\"\n",
    "    print(f\"  {r}: {t} min -- {status}\")\n",
    "    if t <= 10:\n",
    "        within_10.append(r)\n",
    "\n",
    "separator(\"Step 4: Compare prices of nearby restaurants\")\n",
    "for r in within_10:\n",
    "    p = get_price_range(r)\n",
    "    print(f\"  {r}: {p}\")\n",
    "\n",
    "print(\"\\nThat took 4 steps, and WE had to decide each one ourselves.\")\n",
    "print(\"Imagine doing this for every user question...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can the LLM plan how to answer the complex query?\n",
    "plan_prompt = (\n",
    "    \"Given these available tools:\\n\"\n",
    "    \"- get_wait_time(restaurant) - Get wait time in minutes\\n\"\n",
    "    \"- get_rating(restaurant) - Get rating (1-5 stars)\\n\"\n",
    "    \"- get_distance(restaurant) - Get distance in miles\\n\"\n",
    "    \"- get_cuisine(restaurant) - Get cuisine type\\n\"\n",
    "    \"- get_price_range(restaurant) - Get price range ($, $$, $$$)\\n\"\n",
    "    \"- calculate_travel_time(distance) - Get travel time in minutes\\n\"\n",
    "    \"- list_restaurants() - Get list of all restaurants\\n\\n\"\n",
    "    \"How would you answer: \\'What is the cheapest restaurant within \"\n",
    "    \"10 minutes?\\'\\n\"\n",
    "    \"List the steps and which tool you would use at each step.\"\n",
    ")\n",
    "\n",
    "plan = generate(plan_prompt)\n",
    "llm_response(plan, label=\"LLM's Plan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Building the Agent\n",
    "\n",
    "Let's see if we can automate those manual steps. Our first attempt will be simple...\n",
    "\n",
    "### Agent v1: Keyword Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurant_agent_v1(query):\n",
    "    \"\"\"Agent v1: Uses keyword matching to pick a tool.\"\"\"\n",
    "    # Try to find a restaurant name in the query\n",
    "    restaurant = None\n",
    "    for name in RESTAURANTS:\n",
    "        if name.lower() in query.lower():\n",
    "            restaurant = name\n",
    "            break\n",
    "\n",
    "    if \"wait\" in query.lower():\n",
    "        return f\"Wait time at {restaurant}: {get_wait_time(restaurant)} minutes\"\n",
    "    elif \"rating\" in query.lower() or \"rated\" in query.lower():\n",
    "        return f\"Rating of {restaurant}: {get_rating(restaurant)} stars\"\n",
    "    elif \"distance\" in query.lower() or \"far\" in query.lower():\n",
    "        return f\"Distance to {restaurant}: {get_distance(restaurant)} miles\"\n",
    "    elif \"cuisine\" in query.lower() or \"type\" in query.lower():\n",
    "        return f\"Cuisine at {restaurant}: {get_cuisine(restaurant)}\"\n",
    "    elif \"price\" in query.lower() or \"cost\" in query.lower():\n",
    "        return f\"Price range at {restaurant}: {get_price_range(restaurant)}\"\n",
    "    else:\n",
    "        return \"Sorry, I don't understand that question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1 works for simple keyword matches\n",
    "result = restaurant_agent_v1(\"What's the wait at Olive Garden?\")\n",
    "output_box(result, label=\"v1 Success\", style=\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1 breaks on natural language variations\n",
    "result1 = restaurant_agent_v1(\n",
    "    \"How long will I have to stand in line at Olive Garden?\"\n",
    ")\n",
    "output_box(result1, label=\"v1 Failure: No 'wait' keyword\", style=\"error\")\n",
    "\n",
    "result2 = restaurant_agent_v1(\"Tell me about Sushi Palace\")\n",
    "output_box(result2, label=\"v1 Failure: No matching keyword\", style=\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight:** See the problem? The agent only understood exact keywords -- 'wait', 'rating', 'distance'. But users don't talk that way. We need something that *understands* the question, not just matches keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent v2: LLM Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def understand_query(query):\n",
    "    \"\"\"Ask the LLM to classify what type of information the user wants.\"\"\"\n",
    "    prompt = (\n",
    "        \"Classify this restaurant query into exactly one category:\\n\"\n",
    "        \"- wait_time\\n\"\n",
    "        \"- rating\\n\"\n",
    "        \"- distance\\n\"\n",
    "        \"- cuisine\\n\"\n",
    "        \"- price_range\\n\"\n",
    "        \"- travel_time\\n\\n\"\n",
    "        f\"Query: {query}\\n\\n\"\n",
    "        \"Respond with ONLY the category name, nothing else.\"\n",
    "    )\n",
    "    return generate(prompt)",
    "\n",
    "def extract_restaurant(query):\n",
    "    \"\"\"Ask the LLM to extract the restaurant name from the query.\"\"\"\n",
    "    prompt = (\n",
    "        f\"Extract the restaurant name from this query:\\n\"\n",
    "        f\"Query: {query}\\n\\n\"\n",
    "        f\"Available restaurants: {list_restaurants()}\\n\\n\"\n",
    "        \"Respond with ONLY the restaurant name, nothing else.\"\n",
    "    )\n",
    "    return generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurant_agent_v2(query):\n",
    "    \"\"\"Agent v2: Uses LLM to understand the query and extract info.\"\"\"\n",
    "    category = understand_query(query)\n",
    "    restaurant = extract_restaurant(query)\n",
    "\n",
    "    print(f\"LLM understood: category={category}, restaurant={restaurant}\")\n",
    "\n",
    "    tools = {\n",
    "        \"wait_time\": lambda r: f\"Wait: {get_wait_time(r)} minutes\",\n",
    "        \"rating\": lambda r: f\"Rating: {get_rating(r)} stars\",\n",
    "        \"distance\": lambda r: f\"Distance: {get_distance(r)} miles\",\n",
    "        \"cuisine\": lambda r: f\"Cuisine: {get_cuisine(r)}\",\n",
    "        \"price_range\": lambda r: f\"Price range: {get_price_range(r)}\",\n",
    "        \"travel_time\": lambda r: (\n",
    "            f\"Travel time: {calculate_travel_time(get_distance(r))} min\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    if category in tools:\n",
    "        return tools[category](restaurant)\n",
    "    return f\"Could not process query (category: {category})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 handles natural language -- previously failing queries now work!\n",
    "result = restaurant_agent_v2(\n",
    "    \"How long will I have to stand in line at Olive Garden?\"\n",
    ")\n",
    "output_box(result, label=\"v2 Success: Natural Language\", style=\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 fails on multi-step queries that need multiple tools\n",
    "result = restaurant_agent_v2(\n",
    "    \"What's the cheapest restaurant within 10 minutes?\"\n",
    ")\n",
    "output_box(result, label=\"v2 Failure: Multi-step Query\", style=\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight:** LLM understanding solved the language problem, but some questions need multiple steps. V2 can only make one tool call -- it can't chain information from one call into the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent v3: LLM Tool Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurant_agent_v3(query):\n",
    "    \"\"\"Agent v3: LLM picks the tool AND generates the function call.\"\"\"\n",
    "    prompt = (\n",
    "        \"Given these available functions:\\n\"\n",
    "        \"- get_wait_time(restaurant) - Get wait time in minutes\\n\"\n",
    "        \"- get_rating(restaurant) - Get rating (1-5 stars)\\n\"\n",
    "        \"- get_distance(restaurant) - Get distance in miles\\n\"\n",
    "        \"- get_cuisine(restaurant) - Get cuisine type\\n\"\n",
    "        \"- get_price_range(restaurant) - Get price ($, $$, $$$)\\n\"\n",
    "        \"- calculate_travel_time(distance) - Travel time (2 min/mile)\\n\"\n",
    "        \"- list_restaurants() - Get all restaurant names\\n\\n\"\n",
    "        f\"What function call answers: '{query}'\\n\\n\"\n",
    "        \"Respond with ONLY the function call, nothing else.\"\n",
    "    )\n",
    "    response = generate(prompt).strip()\n",
    "    if response.startswith(\"```\"):\n",
    "        response = response.split(\"\\n\")[1]\n",
    "        if response.endswith(\"```\"):\n",
    "            response = response[:-3]\n",
    "    tools_dict = {\n",
    "        \"get_wait_time\": get_wait_time, \"get_rating\": get_rating,\n",
    "        \"get_distance\": get_distance, \"get_cuisine\": get_cuisine,\n",
    "        \"get_price_range\": get_price_range,\n",
    "        \"calculate_travel_time\": calculate_travel_time,\n",
    "        \"list_restaurants\": list_restaurants,\n",
    "    }\n",
    "    print(f\"LLM generated: {response}\")\n",
    "    result = eval(response, {\"__builtins__\": {}}, tools_dict)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v3 works for any single-step query -- the LLM picks the right tool\n",
    "result1 = restaurant_agent_v3(\"How long is the wait at Taj Mahal?\")\n",
    "output_box(f\"Wait query: {result1}\", label=\"v3 Success\", style=\"success\")\n",
    "\n",
    "result2 = restaurant_agent_v3(\"What kind of food does Dragon Wok serve?\")\n",
    "output_box(f\"Cuisine query: {result2}\", label=\"v3 Success\", style=\"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V3 lets the LLM choose the tool -- powerful! But it still only makes ONE call. For our complex query (\"cheapest within 10 min?\"), we need the agent to call one tool, look at the result, decide what to do next, call another tool, and keep going until it has enough information.\n",
    "\n",
    "> **Key Insight:** Single-call agents can't solve multi-step problems. We need a loop: call a tool, observe the result, decide the next step, repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent v4: The Loop\n",
    "\n",
    "What if the agent could keep going? Instead of making ONE call, let it loop: think about what to do next, call a tool, look at the result, decide the next step. Keep going until the question is fully answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool descriptions for the agent prompt\n",
    "TOOL_DESCRIPTIONS = (\n",
    "    \"Available tools:\\n\"\n",
    "    \"- get_wait_time(restaurant) - Wait time in minutes\\n\"\n",
    "    \"- get_rating(restaurant) - Rating (1-5 stars)\\n\"\n",
    "    \"- get_distance(restaurant) - Distance in miles\\n\"\n",
    "    \"- get_cuisine(restaurant) - Cuisine type\\n\"\n",
    "    \"- get_price_range(restaurant) - Price ($, $$, $$$)\\n\"\n",
    "    \"- calculate_travel_time(distance) - Travel time\\n\"\n",
    "    \"- list_restaurants() - All restaurant names\"\n",
    ")\n",
    "\n",
    "def restaurant_agent_v4(query, max_steps=10):\n",
    "    \"\"\"Agent v4: ReAct loop -- reason, act, observe, repeat.\"\"\"\n",
    "    tools = {\n",
    "        \"get_wait_time\": get_wait_time, \"get_rating\": get_rating,\n",
    "        \"get_distance\": get_distance, \"get_cuisine\": get_cuisine,\n",
    "        \"get_price_range\": get_price_range,\n",
    "        \"calculate_travel_time\": calculate_travel_time,\n",
    "        \"list_restaurants\": list_restaurants,\n",
    "    }\n",
    "    history = []\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        prompt = (f\"Query: {query}\\n\\nPrevious steps: {history}\\n\\n\"\n",
    "                  f\"{TOOL_DESCRIPTIONS}\\n\\n\"\n",
    "                  \"If you have enough info to answer, respond: DONE: [answer]\\n\"\n",
    "                  \"Otherwise respond with ONLY the next function call.\")\n",
    "\n",
    "        # Show the full prompt at steps 3-5 to reveal growing context\n",
    "        if 2 <= step <= 4:\n",
    "            separator(f\"Full Prompt Sent to LLM (Step {step + 1})\")\n",
    "            print(prompt)\n",
    "            separator()\n",
    "            print(\"Notice: The prompt includes ALL previous results.\")\n",
    "            print(\"The agent re-reads everything each step.\\n\")\n",
    "        elif step > 4:\n",
    "            print(f\"Step {step + 1}: Prompt includes {len(history)} previous steps (not shown)\")\n",
    "\n",
    "        response = generate(prompt).strip()\n",
    "        if response.upper().startswith(\"DONE\"):\n",
    "            answer = response[5:].strip().lstrip(\":\").strip()\n",
    "            output_box(answer, label=\"Agent Answer\", style=\"success\")\n",
    "            return answer\n",
    "\n",
    "        # Clean markdown code fences if present\n",
    "        if response.startswith(\"```\"):\n",
    "            lines = response.split(\"\\n\")\n",
    "            response = lines[1] if len(lines) > 1 else response\n",
    "            if response.endswith(\"```\"): response = response[:-3]\n",
    "            response = response.strip()\n",
    "\n",
    "        try:\n",
    "            result = eval(response, {\"__builtins__\": {}}, tools)\n",
    "            print(f\"  Step {step + 1}: {response} -> {result}\")\n",
    "            history.append({\"step\": step + 1, \"call\": response, \"result\": str(result)})\n",
    "        except Exception as e:\n",
    "            print(f\"  Step {step + 1}: {response} -> Error: {e}\")\n",
    "            history.append({\"step\": step + 1, \"call\": response, \"result\": f\"Error: {e}\"})\n",
    "\n",
    "    output_box(\"Agent reached maximum steps without finishing.\", label=\"Warning\", style=\"warning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v4 test: simple query (should complete in 1-2 steps)\n",
    "separator(\"v4 Test: Simple Query\")\n",
    "restaurant_agent_v4(\"What's the wait at Olive Garden?\")\n",
    "\n",
    "# v4 test: complex query (requires multiple tools)\n",
    "# Watch the growing context at step 3+!\n",
    "separator(\"v4 Test: Complex Query\")\n",
    "restaurant_agent_v4(\"What's the cheapest restaurant within 10 minutes of me?\")\n",
    "\n",
    "# v4 test: very complex query (chains many tool calls)\n",
    "separator(\"v4 Test: Very Complex Query\")\n",
    "restaurant_agent_v4(\n",
    "    \"What's the best-rated Italian restaurant factoring in wait time and travel time?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Insight:** Did you notice how the prompt grows with each step? The agent re-reads its ENTIRE history every time it asks the LLM what to do next. Previous tool results become part of the next prompt -- that's how the agent \"knows\" what happened before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: The ReAct Pattern",
    "\n",
    "### The Agent Evolution\n",
    "\n",
    "**Agent v1 (Keyword Matching):** Hard-coded rules. Breaks on natural language variations.\n",
    "\n",
    "**Agent v2 (LLM Understanding):** LLM classifies the question. Single tool call only.\n",
    "\n",
    "**Agent v3 (LLM Tool Selection):** LLM picks the tool AND generates the call. Still single call.\n",
    "\n",
    "**Agent v4 (The Loop):** LLM plans, acts, observes, repeats. Handles any complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pattern Has a Name\n",
    "\n",
    "Think about what our v4 agent does each step:\n",
    "1. **Reason** about what information it needs\n",
    "2. **Act** by calling a tool\n",
    "3. **Observe** the result\n",
    "4. **Repeat** until the question is answered\n",
    "\n",
    "This loop we built -- Reason, Act, Observe, Repeat -- has a name in AI research: **ReAct** (Reasoning + Acting).\n",
    "\n",
    "Anthropic defines an agent as: *\"A system that uses an LLM to decide what actions to take and in what order.\"* That's exactly what our v4 agent does -- the LLM decides the next action, the system executes it, and the result informs the next decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_box(\n",
    "    \"An agent is just a loop: the LLM reasons about what to do, \"\n",
    "    \"the system executes the action, and the result feeds back into \"\n",
    "    \"the next reasoning step. Everything we built today -- from v1 \"\n",
    "    \"to v4 -- was the journey of discovering why this loop is necessary.\",\n",
    "    label=\"What We Built\",\n",
    "    style=\"warning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: What's Next",
    "\n",
    "Today we built agents with toy tools -- get_wait_time, get_rating, get_distance. These are fun, but they work with hardcoded data in Python dictionaries.\n",
    "\n",
    "What about real data? Real databases? Real APIs?\n",
    "\n",
    "Next workshop, we'll design tools that work with actual data -- and discover that tool DESIGN is where the real engineering challenge begins.",
    "\n",
    "### Coming Up: Workshop 4\n",
    "\n",
    "**Workshop 4: Tool Design for Agents** -- How to turn real-world data sources into tools an agent can use effectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}