{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e14f961f",
   "metadata": {},
   "source": [
    "# Workshop 3: Building AI Agents — Foundations\n",
    "\n",
    "**Last week we covered:**\n",
    "- How LLMs work at a high level\n",
    "- Prompt engineering techniques\n",
    "- Getting structured output from LLMs\n",
    "\n",
    "**Today we will:**\n",
    "- Discover the fundamental limits of LLMs\n",
    "- Learn how function calling bridges those limits\n",
    "- Build a restaurant finder agent — step by step — from keyword matching all the way to a full reasoning loop\n",
    "- Connect it to our real project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f4e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Setup & Imports ───────────────────────────────────────────\n",
    "from openai import OpenAI\n",
    "from utils.display import output_box, llm_response, separator, compare_table, heading\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def generate(prompt: str, temperature: float = 0) -> str:\n",
    "    \"\"\"Send a prompt to the LLM and return the text response.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt},\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0837b6",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 — The Gap: What LLMs Can and Cannot Do\n",
    "\n",
    "Let's start with a simple question. What is `1234 × 5678`?\n",
    "\n",
    "With Python we can get the answer immediately:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf0fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python says: 541,171\n"
     ]
    }
   ],
   "source": [
    "# Python does math with certainty\n",
    "print(f\"Python says: {1847 * 293:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ab41b5",
   "metadata": {},
   "source": [
    "Now let's ask the LLM the same thing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2b92320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">LLM's Answer</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">541051</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #FFFBEB; border-left: 4px solid #FEF3C7; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #A16207; margin-bottom: 4px;\">Comparison</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">LLM said:  541,051\n",
       "Correct:   541,171\n",
       "Off by:    120</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num1, num2 = 1847, 293\n",
    "\n",
    "response = generate(f\"What is {num1} * {num2}? Respond only with the number.\")\n",
    "llm_answer = int(response.replace(\",\", \"\").strip())\n",
    "correct    = num1 * num2\n",
    "\n",
    "llm_response(response, label=\"LLM's Answer\")\n",
    "output_box(\n",
    "    f\"LLM said:  {llm_answer:,}\\n\"\n",
    "    f\"Correct:   {correct:,}\\n\"\n",
    "    f\"Off by:    {abs(llm_answer - correct):,}\",\n",
    "    label=\"Comparison\",\n",
    "    style=\"warning\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e618e6c",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "\n",
    "LLMs are **language models** — they predict the most likely next token, not the correct answer. When the model sees `1847 × 293`, it guesses a number that *looks* like a 7-million-ish product because it has seen millions of similar examples. But it never runs the multiplication algorithm.\n",
    "\n",
    "Let's look at a few other examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6b7a197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Can the LLM list files on your computer?</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">LLM on file listing</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">I don't have the ability to access or interact with your file system or current directory. However, I can guide you on how to list files in your current directory using various methods depending on your operating system.\n",
       "\n",
       "### For Windows:\n",
       "1. Open Command Prompt.\n",
       "2. Type the following command and press Enter:\n",
       "   ```\n",
       "   dir\n",
       "   ```\n",
       "\n",
       "### For macOS or Linux:\n",
       "1. Open Terminal.\n",
       "2. Type the following command and press Enter:\n",
       "   ```\n",
       "   ls\n",
       "   ```\n",
       "\n",
       "If you want more detailed information, you can use:\n",
       "- For macOS/Linux:\n",
       "  ```\n",
       "  ls -l\n",
       "  ```\n",
       "- For Windows:\n",
       "  ```\n",
       "  dir /w\n",
       "  ```\n",
       "\n",
       "Let me know if you need further assistance!</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Does the LLM know the current time?</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">LLM on current time</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">I'm sorry, but I can't provide real-time information, including the current time. You can easily check the time on your device or through a search engine.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Can the LLM check today's weather?</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">LLM on weather</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">I'm sorry, but I can't provide real-time data such as current temperatures. I recommend checking a reliable weather website or app for the most up-to-date information on the temperature in Boston.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "separator(\"Can the LLM list files on your computer?\")\n",
    "llm_response(generate(\"List all the files in the current directory.\"), label=\"LLM on file listing\")\n",
    "\n",
    "separator(\"Does the LLM know the current time?\")\n",
    "llm_response(generate(\"What is the exact current time right now?\"), label=\"LLM on current time\")\n",
    "\n",
    "separator(\"Can the LLM check today's weather?\")\n",
    "llm_response(generate(\"What is the current temperature in Boston right now?\"), label=\"LLM on weather\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c372a6a",
   "metadata": {},
   "source": [
    "> **Key Insight:** In every case the LLM produced text that *looks like* an answer — but it never actually performed the action. LLMs can only generate text. They cannot run calculations, read files, check the time, or fetch live data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fcc6c5",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2 — But LLMs Can Plan\n",
    "\n",
    "We just saw that LLMs can't *do* things. But look closely at those responses. When asked about files, the LLM described *exactly* how to list them. When asked for the time, it told you the Python code that would get it.\n",
    "\n",
    "Let's make that explicit:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f54e7b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">How would you calculate 1847 × 293?</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">LLM describes math</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">To calculate \\( 1847 \\times 293 \\), you can use the standard multiplication method. Here’s a step-by-step breakdown:\n",
       "\n",
       "1. **Write the numbers vertically**:\n",
       "   ```\n",
       "       1847\n",
       "   ×     293\n",
       "   ```\n",
       "\n",
       "2. **Multiply the bottom number by each digit of the top number, starting from the rightmost digit**:\n",
       "\n",
       "   - **Multiply by 3 (the units place of 293)**:\n",
       "     \\[\n",
       "     1847 \\times 3 = 5541\n",
       "     \\]\n",
       "     Write this down:\n",
       "     ```\n",
       "         5541\n",
       "     ```\n",
       "\n",
       "   - **Multiply by 9 (the tens place of 293)**:\n",
       "     \\[\n",
       "     1847 \\times 9 = 16623\n",
       "     \\]\n",
       "     Since this is in the tens place, we add a zero to the right:\n",
       "     ```\n",
       "        166230\n",
       "     ```\n",
       "\n",
       "   - **Multiply by 2 (the hundreds place of 293)**:\n",
       "     \\[\n",
       "     1847 \\times 2 = 3694\n",
       "     \\]\n",
       "     Since this is in the hundreds place, we add two zeros to the right:\n",
       "     ```\n",
       "       369400\n",
       "     ```\n",
       "\n",
       "3. **Now, add all the results together**:\n",
       "   ```\n",
       "         5541\n",
       "       166230\n",
       "      369400\n",
       "   ```\n",
       "\n",
       "   Align the numbers for addition:\n",
       "   ```\n",
       "         5541\n",
       "       166230\n",
       "      369400\n",
       "   ------------\n",
       "      541751\n",
       "   ```\n",
       "\n",
       "4. **Final result**:\n",
       "   \\[\n",
       "   1847 \\times 293 = 541751\n",
       "   \\]\n",
       "\n",
       "Thus, the product of \\( 1847 \\) and \\( 293 \\) is \\( 541751 \\).</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">How would you list files?</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">LLM describes file listing</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">You can use the `os` module or the `pathlib` module in Python to list all files in the current directory. Here are examples using both methods:\n",
       "\n",
       "### Using `os` module\n",
       "\n",
       "```python\n",
       "import os\n",
       "\n",
       "# List all files in the current directory\n",
       "files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
       "print(files)\n",
       "```\n",
       "\n",
       "### Using `pathlib` module\n",
       "\n",
       "```python\n",
       "from pathlib import Path\n",
       "\n",
       "# List all files in the current directory\n",
       "files = [f for f in Path('.').iterdir() if f.is_file()]\n",
       "print(files)\n",
       "```\n",
       "\n",
       "Both of these snippets will print a list of all files in the current directory. You can run either of these code snippets in your Python environment.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">How would you get the current time?</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">LLM describes time</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">To get the current time in Python, you can use the `datetime` module, which provides a variety of functions to work with dates and times. Here’s a simple example of how to get the current time:\n",
       "\n",
       "```python\n",
       "from datetime import datetime\n",
       "\n",
       "# Get the current time\n",
       "current_time = datetime.now()\n",
       "\n",
       "# Print the current time\n",
       "print(\"Current time:\", current_time.strftime(\"%H:%M:%S\"))\n",
       "```\n",
       "\n",
       "In this code:\n",
       "- We import the `datetime` class from the `datetime` module.\n",
       "- We use `datetime.now()` to get the current date and time.\n",
       "- We format the output to show only the time in hours, minutes, and seconds using `strftime(\"%H:%M:%S\")`.\n",
       "\n",
       "If you want to get the current time in a specific timezone, you can use the `pytz` library along with `datetime`. Here's an example:\n",
       "\n",
       "```python\n",
       "from datetime import datetime\n",
       "import pytz\n",
       "\n",
       "# Define the timezone\n",
       "timezone = pytz.timezone('America/New_York')\n",
       "\n",
       "# Get the current time in the specified timezone\n",
       "current_time = datetime.now(timezone)\n",
       "\n",
       "# Print the current time\n",
       "print(\"Current time in New York:\", current_time.strftime(\"%H:%M:%S\"))\n",
       "```\n",
       "\n",
       "Make sure to install the `pytz` library if you want to work with timezones:\n",
       "\n",
       "```bash\n",
       "pip install pytz\n",
       "```\n",
       "\n",
       "This will give you the current time in the specified timezone.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "separator(\"How would you calculate 1847 × 293?\")\n",
    "llm_response(generate(f\"How would you calculate {num1} * {num2}? Be specific.\"), label=\"LLM describes math\")\n",
    "\n",
    "separator(\"How would you list files?\")\n",
    "llm_response(generate(\"What Python code would list all files in the current directory?\"), label=\"LLM describes file listing\")\n",
    "\n",
    "separator(\"How would you get the current time?\")\n",
    "llm_response(generate(\"What Python code would get the current time?\"), label=\"LLM describes time\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f1606",
   "metadata": {},
   "source": [
    "> **Key Insight:** LLMs are *excellent* at understanding tasks and describing what needs to be done.\n",
    "\n",
    "> **The Big Idea:** What if instead of asking LLMs to **do** things, we ask them to tell us **what needs to be done** — and then *we* execute it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724cd70",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3 — Bridging the Gap: Function Calling\n",
    "\n",
    "The idea: give the LLM a set of functions it can choose from. Ask it to output which function to call (as text). Then we execute that function.\n",
    "\n",
    "Let's prove this with the simplest possible example — arithmetic:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae67f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #F0FDF4; border-left: 4px solid #DCFCE7; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #15803D; margin-bottom: 4px;\">Tools work ✓</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">add_ints(5, 3)      = 8\n",
       "multiply_ints(5, 3) = 15\n",
       "divide_ints(9, 3)   = 3.0</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Define simple arithmetic tools ────────────────────────────\n",
    "def add_ints(x: int, y: int) -> int:\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "def multiply_ints(x: int, y: int) -> int:\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "def divide_ints(x: int, y: int) -> float:\n",
    "    \"\"\"Divide two integers.\"\"\"\n",
    "    return x / y\n",
    "\n",
    "# Quick smoke-test\n",
    "output_box(\n",
    "    f\"add_ints(5, 3)      = {add_ints(5, 3)}\\n\"\n",
    "    f\"multiply_ints(5, 3) = {multiply_ints(5, 3)}\\n\"\n",
    "    f\"divide_ints(9, 3)   = {divide_ints(9, 3)}\",\n",
    "    label=\"Tools work ✓\",\n",
    "    style=\"success\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3ef3b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">LLM generates a function call (it's just text!)</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">multiply_ints(1847, 293)</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Ask the LLM which function to call ────────────────────────\n",
    "prompt = f\"\"\"You have access to these functions:\n",
    "- add_ints(x, y): Adds two integers\n",
    "- multiply_ints(x, y): Multiplies two integers\n",
    "- divide_ints(x, y): Divides two integers\n",
    "\n",
    "Respond with ONLY the function call needed to answer this query:\n",
    "\"What is the product of {num1} and {num2}?\"\n",
    "\"\"\"\n",
    "\n",
    "function_call = generate(prompt)\n",
    "llm_response(function_call, label=\"LLM generates a function call (it's just text!)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a11010f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #F0FDF4; border-left: 4px solid #DCFCE7; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #15803D; margin-bottom: 4px;\">Execution Result</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">Function call: multiply_ints(1847, 293)\n",
       "Result:        541,171\n",
       "Correct:       541,171</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── We execute it ─────────────────────────────────────────────\n",
    "tools = {\"add_ints\": add_ints, \"multiply_ints\": multiply_ints, \"divide_ints\": divide_ints}\n",
    "result = eval(function_call, tools)\n",
    "\n",
    "output_box(\n",
    "    f\"Function call: {function_call}\\n\"\n",
    "    f\"Result:        {result:,}\\n\"\n",
    "    f\"Correct:       {num1 * num2:,}\",\n",
    "    label=\"Execution Result\",\n",
    "    style=\"success\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41465614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Step 1 — User query</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">User</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">Multiply 1847 and 293</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Step 2 — LLM decides what to call</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">LLM Output (still just text)</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">multiply_ints(1847, 293)</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Step 3 — System executes</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">Execution</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">multiply_ints(1847, 293) → 541,171</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Step 4 — LLM formats the final answer</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">Final Response</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">The result of multiplying 1847 and 293 is 541,171.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Complete end-to-end flow ───────────────────────────────────\n",
    "user_query = f\"Multiply {num1} and {num2}\"\n",
    "\n",
    "separator(\"Step 1 — User query\")\n",
    "output_box(user_query, label=\"User\")\n",
    "\n",
    "separator(\"Step 2 — LLM decides what to call\")\n",
    "call = generate(f\"\"\"Functions: add_ints(x,y), multiply_ints(x,y), divide_ints(x,y)\n",
    "Query: {user_query}\n",
    "Respond with ONLY the exact function call.\"\"\")\n",
    "llm_response(call, label=\"LLM Output (still just text)\")\n",
    "\n",
    "separator(\"Step 3 — System executes\")\n",
    "result = eval(call, tools)\n",
    "output_box(f\"{call} → {result:,}\", label=\"Execution\")\n",
    "\n",
    "separator(\"Step 4 — LLM formats the final answer\")\n",
    "final = generate(f'The user asked: \"{user_query}\". The result is {result}. Respond naturally.')\n",
    "llm_response(final, label=\"Final Response\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f60b246",
   "metadata": {},
   "source": [
    "### What We Just Discovered\n",
    "\n",
    "1. **LLMs are text generators** — they output strings, nothing else\n",
    "2. **LLMs can't directly run things** — no calculations, files, or live data\n",
    "3. **LLMs understand tasks** — they know *what* needs to be done\n",
    "4. **Function calling bridges the gap** — LLM writes instructions → system executes → LLM sees result → responds\n",
    "\n",
    "**The pattern:**\n",
    "```\n",
    "User Query → LLM (thinks) → Function Call (text) → System Executes → Result → LLM Responds\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09ae2a0",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4 — A Real Scenario: Restaurant Finder\n",
    "\n",
    "The arithmetic example was clean but trivial. Real-world tasks are messier — and they often need **multiple steps** to answer one question.\n",
    "\n",
    "Let's build something more interesting: a restaurant finder that can answer questions like:\n",
    "- *\"What's the wait at Olive Garden?\"*\n",
    "- *\"Which restaurant has the best rating?\"*\n",
    "- *\"What's the best Italian place within 10 minutes of me?\"*\n",
    "\n",
    "An LLM alone cannot answer these — it doesn't know **current** wait times, live ratings, or your location. But if we give it the right tools, it can figure out exactly what to call.\n",
    "\n",
    "First, let's set up our data and tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56b73ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Restaurant data (simulated real-time) ─────────────────────\n",
    "# In a real system this would hit live APIs. Here we use hardcoded data.\n",
    "\n",
    "RESTAURANTS = {\n",
    "    \"Olive Garden\":  {\"wait\": 25, \"rating\": 3.8, \"distance\": 1.2, \"cuisine\": \"Italian\",  \"price\": \"$$\"},\n",
    "    \"Sushi Palace\":  {\"wait\": 10, \"rating\": 4.5, \"distance\": 2.0, \"cuisine\": \"Japanese\", \"price\": \"$$$\"},\n",
    "    \"Burger Barn\":   {\"wait\":  5, \"rating\": 3.5, \"distance\": 0.8, \"cuisine\": \"American\", \"price\": \"$\"},\n",
    "    \"Taj Mahal\":     {\"wait\": 15, \"rating\": 4.7, \"distance\": 3.5, \"cuisine\": \"Indian\",   \"price\": \"$$\"},\n",
    "    \"La Maison\":     {\"wait\": 40, \"rating\": 4.9, \"distance\": 4.2, \"cuisine\": \"French\",   \"price\": \"$$$\"},\n",
    "}\n",
    "\n",
    "# ── Tool functions ─────────────────────────────────────────────\n",
    "def list_restaurants() -> list[str]:\n",
    "    \"\"\"Return all available restaurant names.\"\"\"\n",
    "    return list(RESTAURANTS.keys())\n",
    "\n",
    "def get_wait_time(restaurant: str) -> int:\n",
    "    \"\"\"Get current wait time in minutes.\"\"\"\n",
    "    return RESTAURANTS.get(restaurant, {}).get(\"wait\", -1)\n",
    "\n",
    "def get_rating(restaurant: str) -> float:\n",
    "    \"\"\"Get star rating (1–5).\"\"\"\n",
    "    return RESTAURANTS.get(restaurant, {}).get(\"rating\", -1)\n",
    "\n",
    "def get_distance(restaurant: str) -> float:\n",
    "    \"\"\"Get distance in miles from current location.\"\"\"\n",
    "    return RESTAURANTS.get(restaurant, {}).get(\"distance\", -1)\n",
    "\n",
    "def get_cuisine(restaurant: str) -> str:\n",
    "    \"\"\"Get cuisine type.\"\"\"\n",
    "    return RESTAURANTS.get(restaurant, {}).get(\"cuisine\", \"Unknown\")\n",
    "\n",
    "def get_price_range(restaurant: str) -> str:\n",
    "    \"\"\"Get price range: $, $$, or $$$.\"\"\"\n",
    "    return RESTAURANTS.get(restaurant, {}).get(\"price\", \"?\")\n",
    "\n",
    "def calculate_total_time(wait: int, distance: float, speed_mph: float = 30.0) -> float:\n",
    "    \"\"\"Calculate total time = wait time + travel time (distance / speed * 60 min).\"\"\"\n",
    "    travel_minutes = (distance / speed_mph) * 60\n",
    "    return round(wait + travel_minutes, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c31c9f6",
   "metadata": {},
   "source": [
    "**Our tools at a glance:**\n",
    "\n",
    "| Function | What it does |\n",
    "|---|---|\n",
    "| `list_restaurants()` | All restaurant names |\n",
    "| `get_wait_time(restaurant)` | Current wait in minutes |\n",
    "| `get_rating(restaurant)` | Star rating 1–5 |\n",
    "| `get_distance(restaurant)` | Miles from your location |\n",
    "| `get_cuisine(restaurant)` | Cuisine type |\n",
    "| `get_price_range(restaurant)` | `$, $$, or $$$`|\n",
    "| `calculate_total_time(wait, distance)` | Wait + travel time combined |\n",
    "\n",
    "Let's verify they all work:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f87bc38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table style=\"width: 100%; border-collapse: collapse; border: 1px solid #E5E7EB; border-radius: 6px; overflow: hidden; margin: 8px 0;\">\n",
       "        <thead><tr style=\"background: #F3F4F6; border-bottom: 2px solid #D1D5DB;\"><th style=\"padding: 10px 14px; text-align: left; font-weight: 600; color: #374151;\">Function Call</th><th style=\"padding: 10px 14px; text-align: left; font-weight: 600; color: #374151;\">Result</th></tr></thead>\n",
       "        <tbody><tr style=\"background: #F9FAFB; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">list_restaurants()</td><td style=\"padding: 10px 14px; color: #4B5563;\">['Olive Garden', 'Sushi Palace', 'Burger Barn', 'Taj Mahal', 'La Maison']</td></tr><tr style=\"background: #FFFFFF; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">get_wait_time('Olive Garden')</td><td style=\"padding: 10px 14px; color: #4B5563;\">25 min</td></tr><tr style=\"background: #F9FAFB; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">get_rating('Sushi Palace')</td><td style=\"padding: 10px 14px; color: #4B5563;\">4.5 ★</td></tr><tr style=\"background: #FFFFFF; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">get_distance('Burger Barn')</td><td style=\"padding: 10px 14px; color: #4B5563;\">0.8 miles</td></tr><tr style=\"background: #F9FAFB; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">get_cuisine('Taj Mahal')</td><td style=\"padding: 10px 14px; color: #4B5563;\">Indian</td></tr><tr style=\"background: #FFFFFF; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">get_price_range('La Maison')</td><td style=\"padding: 10px 14px; color: #4B5563;\">$$$</td></tr><tr style=\"background: #F9FAFB; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">calculate_total_time(25, 1.2)</td><td style=\"padding: 10px 14px; color: #4B5563;\">27.4 min</td></tr></tbody>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_table(\n",
    "    rows=[\n",
    "        (\"list_restaurants()\",               str(list_restaurants())),\n",
    "        (\"get_wait_time('Olive Garden')\",     f\"{get_wait_time('Olive Garden')} min\"),\n",
    "        (\"get_rating('Sushi Palace')\",        f\"{get_rating('Sushi Palace')} ★\"),\n",
    "        (\"get_distance('Burger Barn')\",       f\"{get_distance('Burger Barn')} miles\"),\n",
    "        (\"get_cuisine('Taj Mahal')\",          get_cuisine(\"Taj Mahal\")),\n",
    "        (\"get_price_range('La Maison')\",      get_price_range(\"La Maison\")),\n",
    "        (\"calculate_total_time(25, 1.2)\",     f\"{calculate_total_time(25, 1.2)} min\"),\n",
    "    ],\n",
    "    headers=(\"Function Call\", \"Result\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec464a60",
   "metadata": {},
   "source": [
    "---\n",
    "### Manual Walkthroughs — Building Intuition\n",
    "\n",
    "Before we write any agent code, let's manually think through three queries of increasing complexity. This is important — the friction you feel doing this by hand is *exactly* what the agent will solve.\n",
    "\n",
    "---\n",
    "#### Query 1 — Simple: *\"What's the wait at Olive Garden?\"*\n",
    "\n",
    "To answer this, we need exactly one tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd9d14b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #F0FDF4; border-left: 4px solid #DCFCE7; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #15803D; margin-bottom: 4px;\">Query 1: What's the wait at Olive Garden?</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">get_wait_time('Olive Garden') → 25 minutes</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "restaurant = \"Olive Garden\"\n",
    "\n",
    "wait = get_wait_time(restaurant)\n",
    "\n",
    "output_box(\n",
    "    f\"get_wait_time('{restaurant}') → {wait} minutes\",\n",
    "    label=\"Query 1: What's the wait at Olive Garden?\",\n",
    "    style=\"success\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa6c4f",
   "metadata": {},
   "source": [
    "---\n",
    "#### Query 2 — Medium: *\"Which restaurant has the shortest wait right now?\"*\n",
    "\n",
    "Now we need to check **every** restaurant, calculate each wait, and find the minimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c91faa4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Query 2: Which restaurant has the shortest wait?</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Olive Garden       → 25 min wait\n",
      "  Sushi Palace       → 10 min wait\n",
      "  Burger Barn        → 5 min wait\n",
      "  Taj Mahal          → 15 min wait\n",
      "  La Maison          → 40 min wait\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #F0FDF4; border-left: 4px solid #DCFCE7; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #15803D; margin-bottom: 4px;\">Result</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">Winner: Burger Barn (5 min wait)</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "separator(\"Query 2: Which restaurant has the shortest wait?\")\n",
    "\n",
    "results = []\n",
    "for name in list_restaurants():\n",
    "    wait = get_wait_time(name)\n",
    "    results.append((name, wait))\n",
    "    print(f\"  {name:<18} → {wait} min wait\")\n",
    "\n",
    "best_name, best_wait = min(results, key=lambda x: x[1])\n",
    "\n",
    "output_box(\n",
    "    f\"Winner: {best_name} ({best_wait} min wait)\",\n",
    "    label=\"Result\",\n",
    "    style=\"success\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f348397",
   "metadata": {},
   "source": [
    "---\n",
    "#### Query 3 — Complex: *\"What's the best Italian place within 10 minutes of me?\"*\n",
    "\n",
    "This needs multiple filters across multiple tools, in order:\n",
    "1. Get each restaurant's cuisine — keep only Italian ones\n",
    "2. For each Italian restaurant, calculate total time (wait + travel)\n",
    "3. Filter to those with total time ≤ 10 minutes\n",
    "4. Rank by rating among the ones that remain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba2eed3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Query 3: Best Italian place within 10 minutes?</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Olive Garden: cuisine=Italian, wait=25m, dist=1.2mi, total=27.4m, rating=3.8★\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #FFFBEB; border-left: 4px solid #FEF3C7; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        \n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">No Italian restaurants within 10 minutes.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "separator(\"Query 3: Best Italian place within 10 minutes?\")\n",
    "\n",
    "MAX_TOTAL_MINUTES = 10\n",
    "candidates = []\n",
    "\n",
    "for name in list_restaurants():\n",
    "    cuisine = get_cuisine(name)\n",
    "    if cuisine != \"Italian\":\n",
    "        continue\n",
    "\n",
    "    wait     = get_wait_time(name)\n",
    "    distance = get_distance(name)\n",
    "    total    = calculate_total_time(wait, distance)\n",
    "    rating   = get_rating(name)\n",
    "\n",
    "    print(f\"  {name}: cuisine={cuisine}, wait={wait}m, dist={distance}mi, total={total}m, rating={rating}★\")\n",
    "\n",
    "    if total <= MAX_TOTAL_MINUTES:\n",
    "        candidates.append((name, total, rating))\n",
    "\n",
    "if candidates:\n",
    "    best = max(candidates, key=lambda x: x[2])\n",
    "    output_box(\n",
    "        f\"Winner: {best[0]}\\nTotal time: {best[1]} min  |  Rating: {best[2]} ★\",\n",
    "        label=\"Result\",\n",
    "        style=\"success\",\n",
    "    )\n",
    "else:\n",
    "    output_box(\"No Italian restaurants within 10 minutes.\", style=\"warning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e9a36",
   "metadata": {},
   "source": [
    "That took a lot of hardcoded steps — and we wrote those steps ourselves. What if we had 50 different query types? We'd need 50 different blocks of code.\n",
    "\n",
    "Let's see we can use a LLM to help instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b68f33e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Query: \"What's the wait at Olive Garden?\"</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">LLM's Plan</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">1. get_wait_time(\"Olive Garden\")</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Query: \"Which restaurant has the shortest wait?\"</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">LLM's Plan</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">1. list_restaurants()\n",
       "2. get_wait_time(restaurant)</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Query: \"What's the best Italian place within 10 minutes?\"</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">LLM's Plan</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">1. list_restaurants()\n",
       "2. get_cuisine(restaurant)\n",
       "3. get_distance(restaurant)\n",
       "4. get_wait_time(restaurant)\n",
       "5. calculate_total_time(wait, distance)\n",
       "6. get_rating(restaurant)</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOOL_DESCRIPTIONS = \"\"\"\n",
    "Available tools:\n",
    "- list_restaurants() — returns all restaurant names\n",
    "- get_wait_time(restaurant) — current wait in minutes\n",
    "- get_rating(restaurant) — star rating (1–5)\n",
    "- get_distance(restaurant) — miles from your location\n",
    "- get_cuisine(restaurant) — cuisine type (e.g., Italian, Japanese)\n",
    "- get_price_range(restaurant) — price range ($, $$, $$$)\n",
    "- calculate_total_time(wait, distance) — wait + travel time combined\n",
    "\"\"\"\n",
    "\n",
    "test_queries = [\n",
    "    \"What's the wait at Olive Garden?\",\n",
    "    \"Which restaurant has the shortest wait?\",\n",
    "    \"What's the best Italian place within 10 minutes?\",\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    plan = generate(f\"\"\"\n",
    "{TOOL_DESCRIPTIONS}\n",
    "\n",
    "User query: {query}\n",
    "\n",
    "What tool calls are needed, in order? List them one per line.\n",
    "\"\"\")\n",
    "    separator(f'Query: \"{query}\"')\n",
    "    llm_response(plan, label=\"LLM's Plan\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca323ae",
   "metadata": {},
   "source": [
    "The LLM can plan the right steps. The question is: can we automate that planning and execution? Let's build toward that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366d981f",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5 — Building the Agent\n",
    "\n",
    "We'll build four versions, each fixing a flaw in the previous one.\n",
    "\n",
    "---\n",
    "### Agent v1 — Keyword Matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d31cb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurant_agent_v1(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Agent v1: Uses keyword matching to route queries.\n",
    "    Simple, but extremely fragile.\n",
    "    \"\"\"\n",
    "    q = query.lower()\n",
    "\n",
    "    # Find restaurant name (if any)\n",
    "    restaurant = next((r for r in list_restaurants() if r.lower() in q), None)\n",
    "\n",
    "    if \"wait\" in q and restaurant:\n",
    "        wait = get_wait_time(restaurant)\n",
    "        return f\"Wait at {restaurant}: {wait} minutes\"\n",
    "\n",
    "    elif \"rating\" in q and restaurant:\n",
    "        rating = get_rating(restaurant)\n",
    "        return f\"Rating of {restaurant}: {rating} ★\"\n",
    "\n",
    "    elif \"fastest\" in q or \"shortest wait\" in q:\n",
    "        results = [(r, get_wait_time(r)) for r in list_restaurants()]\n",
    "        best = min(results, key=lambda x: x[1])\n",
    "        return f\"Shortest wait: {best[0]} ({best[1]} min)\"\n",
    "\n",
    "    else:\n",
    "        return \"I don't understand that request.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9c73f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table style=\"width: 100%; border-collapse: collapse; border: 1px solid #E5E7EB; border-radius: 6px; overflow: hidden; margin: 8px 0;\">\n",
       "        <thead><tr style=\"background: #F3F4F6; border-bottom: 2px solid #D1D5DB;\"><th style=\"padding: 10px 14px; text-align: left; font-weight: 600; color: #374151;\">Query</th><th style=\"padding: 10px 14px; text-align: left; font-weight: 600; color: #374151;\">v1 Result</th></tr></thead>\n",
       "        <tbody><tr style=\"background: #F9FAFB; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">What's the wait at Olive Garden?</td><td style=\"padding: 10px 14px; color: #4B5563;\">Wait at Olive Garden: 25 minutes</td></tr><tr style=\"background: #FFFFFF; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">Sushi Palace rating?</td><td style=\"padding: 10px 14px; color: #4B5563;\">Rating of Sushi Palace: 4.5 ★</td></tr><tr style=\"background: #F9FAFB; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">Which has the shortest wait?</td><td style=\"padding: 10px 14px; color: #4B5563;\">Shortest wait: Burger Barn (5 min)</td></tr></tbody>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Things v1 gets right\n",
    "compare_table(\n",
    "    rows=[\n",
    "        (\"What's the wait at Olive Garden?\",    restaurant_agent_v1(\"What's the wait at Olive Garden?\")),\n",
    "        (\"Sushi Palace rating?\",                 restaurant_agent_v1(\"Sushi Palace rating?\")),\n",
    "        (\"Which has the shortest wait?\",         restaurant_agent_v1(\"Which has the shortest wait?\")),\n",
    "    ],\n",
    "    headers=(\"Query\", \"v1 Result\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2ae8482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table style=\"width: 100%; border-collapse: collapse; border: 1px solid #E5E7EB; border-radius: 6px; overflow: hidden; margin: 8px 0;\">\n",
       "        <thead><tr style=\"background: #F3F4F6; border-bottom: 2px solid #D1D5DB;\"><th style=\"padding: 10px 14px; text-align: left; font-weight: 600; color: #374151;\">Query</th><th style=\"padding: 10px 14px; text-align: left; font-weight: 600; color: #374151;\">v1 Result</th></tr></thead>\n",
       "        <tbody><tr style=\"background: #F9FAFB; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">How long will I wait at Olive Garden?</td><td style=\"padding: 10px 14px; color: #4B5563;\">Wait at Olive Garden: 25 minutes</td></tr><tr style=\"background: #FFFFFF; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">Is Sushi Palace well reviewed?</td><td style=\"padding: 10px 14px; color: #4B5563;\">I don't understand that request.</td></tr><tr style=\"background: #F9FAFB; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">Where can I get seated quickly?</td><td style=\"padding: 10px 14px; color: #4B5563;\">I don't understand that request.</td></tr></tbody>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Things v1 breaks on\n",
    "compare_table(\n",
    "    rows=[\n",
    "        (\"How long will I wait at Olive Garden?\",       restaurant_agent_v1(\"How long will I wait at Olive Garden?\")),\n",
    "        (\"Is Sushi Palace well reviewed?\",              restaurant_agent_v1(\"Is Sushi Palace well reviewed?\")),\n",
    "        (\"Where can I get seated quickly?\",             restaurant_agent_v1(\"Where can I get seated quickly?\")),\n",
    "    ],\n",
    "    headers=(\"Query\", \"v1 Result\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db53134",
   "metadata": {},
   "source": [
    "> **The problem:** v1 understands exact keywords — `\"wait\"`, `\"rating\"`, `\"fastest\"`. Real users don't talk that way. Slight rephrasing breaks everything.\n",
    "\n",
    "---\n",
    "### Agent v2 — LLM Understanding\n",
    "\n",
    "What if we let the LLM *classify* the query instead of matching keywords?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c714ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def understand_query(query: str) -> str:\n",
    "    \"\"\"Use the LLM to classify what kind of information the user wants.\"\"\"\n",
    "    return generate(\n",
    "        f\"\"\"Classify this restaurant query into one of these categories:\n",
    "- check_wait: user wants the wait time at a specific restaurant\n",
    "- check_rating: user wants the rating of a specific restaurant\n",
    "- find_shortest_wait: user wants the restaurant with the shortest wait\n",
    "- unknown: doesn't match any above\n",
    "\n",
    "Query: {query}\n",
    "Respond with the category name only.\"\"\",\n",
    "    )\n",
    "\n",
    "def extract_restaurant(query: str) -> str:\n",
    "    \"\"\"Extract the restaurant name from a query.\"\"\"\n",
    "    return generate(\n",
    "        f\"\"\"Available restaurants: {', '.join(list_restaurants())}\n",
    "\n",
    "Extract the restaurant name from this query, or respond 'none' if no specific restaurant is mentioned.\n",
    "Query: {query}\n",
    "Respond with just the restaurant name or 'none'.\"\"\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14c892f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurant_agent_v2(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Agent v2: LLM understands intent; system executes.\n",
    "    Handles natural language — but only one tool at a time.\n",
    "    \"\"\"\n",
    "    intent     = understand_query(query)\n",
    "    restaurant = extract_restaurant(query)\n",
    "\n",
    "    print(f\"  Intent: {intent}\")\n",
    "    print(f\"  Restaurant: {restaurant}\")\n",
    "\n",
    "    if intent == \"check_wait\" and restaurant != \"none\":\n",
    "        wait = get_wait_time(restaurant)\n",
    "        return f\"Wait at {restaurant}: {wait} minutes\"\n",
    "\n",
    "    elif intent == \"check_rating\" and restaurant != \"none\":\n",
    "        rating = get_rating(restaurant)\n",
    "        return f\"Rating of {restaurant}: {rating} ★\"\n",
    "\n",
    "    elif intent == \"find_shortest_wait\":\n",
    "        results = [(r, get_wait_time(r)) for r in list_restaurants()]\n",
    "        best = min(results, key=lambda x: x[1])\n",
    "        return f\"Shortest wait: {best[0]} ({best[1]} min)\"\n",
    "\n",
    "    else:\n",
    "        return \"I couldn't understand that request.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "013aa38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">Queries that v1 could not handle</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'How long will I wait at Olive Garden?'\n",
      "  Intent: check_wait\n",
      "  Restaurant: Olive Garden\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #F0FDF4; border-left: 4px solid #DCFCE7; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #15803D; margin-bottom: 4px;\">v2 Result</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">Wait at Olive Garden: 25 minutes</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'Is Sushi Palace well reviewed?'\n",
      "  Intent: check_rating\n",
      "  Restaurant: Sushi Palace\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #F0FDF4; border-left: 4px solid #DCFCE7; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #15803D; margin-bottom: 4px;\">v2 Result</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">Rating of Sushi Palace: 4.5 ★</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'Where can I get seated quickly?'\n",
      "  Intent: find_shortest_wait\n",
      "  Restaurant: none\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #F0FDF4; border-left: 4px solid #DCFCE7; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #15803D; margin-bottom: 4px;\">v2 Result</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">Shortest wait: Burger Barn (5 min)</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Queries that failed in v1 now work\n",
    "separator(\"Queries that v1 could not handle\")\n",
    "\n",
    "for query in [\n",
    "    \"How long will I wait at Olive Garden?\",\n",
    "    \"Is Sushi Palace well reviewed?\",\n",
    "    \"Where can I get seated quickly?\",\n",
    "]:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    result = restaurant_agent_v2(query)\n",
    "    output_box(result, label=\"v2 Result\", style=\"success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "533455a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center; margin: 16px 0;\"><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/><span style=\"padding: 0 12px; color: #6B7280; font-size: 13px;\">A query that requires multiple steps</span><hr style=\"flex: 1; border: none; border-top: 1px solid #D1D5DB;\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'What's the best Italian place within 10 minutes of me?'\n",
      "  Intent: unknown\n",
      "  Restaurant: Olive Garden\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #FEF2F2; border-left: 4px solid #FEE2E2; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #B91C1C; margin-bottom: 4px;\">v2 Result</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">I couldn't understand that request.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# But v2 fails on anything needing multiple tools\n",
    "separator(\"A query that requires multiple steps\")\n",
    "\n",
    "query = \"What's the best Italian place within 10 minutes of me?\"\n",
    "print(f\"Query: '{query}'\")\n",
    "result = restaurant_agent_v2(query)\n",
    "output_box(result, label=\"v2 Result\", style=\"error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd99e19",
   "metadata": {},
   "source": [
    "> **The problem:** v2 understands *language* but still follows rigid if/else branches. Answering \"best Italian within 10 minutes\" requires calling `get_cuisine`, `get_wait_time`, `get_distance`, and `calculate_total_time` — in a specific order. v2 can't do that.\n",
    "\n",
    "---\n",
    "### Agent v3 — LLM Picks the Tool\n",
    "\n",
    "What if we stop writing branches altogether and let the LLM decide *which function to call*?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62f7ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS_V3 = {\n",
    "    \"list_restaurants\": list_restaurants,\n",
    "    \"get_wait_time\": get_wait_time,\n",
    "    \"get_rating\": get_rating,\n",
    "    \"get_distance\": get_distance,\n",
    "    \"get_cuisine\": get_cuisine,\n",
    "    \"get_price_range\": get_price_range,\n",
    "    \"calculate_total_time\": calculate_total_time,\n",
    "}\n",
    "\n",
    "def restaurant_agent_v3(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Agent v3: LLM selects AND generates the function call; system executes.\n",
    "    Flexible — but still only one tool call per query.\n",
    "    \"\"\"\n",
    "    tool_call = generate(\n",
    "        f\"\"\"{TOOL_DESCRIPTIONS}\n",
    "User query: {query}\n",
    "\n",
    "Respond with ONLY a single function call (e.g., get_wait_time('Olive Garden')).\n",
    "If multiple calls are needed, give the first one only.\"\"\",\n",
    "    )\n",
    "\n",
    "    print(f\"  LLM chose: {tool_call}\")\n",
    "\n",
    "    # Strip markdown fences if the LLM adds them\n",
    "    clean = tool_call.strip().strip(\"`\").strip()\n",
    "\n",
    "    try:\n",
    "        result = eval(clean, TOOLS_V3)\n",
    "        return f\"{clean} → {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error executing '{clean}': {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64c4e0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LLM chose: get_wait_time('Olive Garden')\n",
      "  LLM chose: get_rating('Sushi Palace')\n",
      "  LLM chose: get_cuisine('Taj Mahal')\n",
      "  LLM chose: get_distance('Burger Barn')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <table style=\"width: 100%; border-collapse: collapse; border: 1px solid #E5E7EB; border-radius: 6px; overflow: hidden; margin: 8px 0;\">\n",
       "        <thead><tr style=\"background: #F3F4F6; border-bottom: 2px solid #D1D5DB;\"><th style=\"padding: 10px 14px; text-align: left; font-weight: 600; color: #374151;\">Query</th><th style=\"padding: 10px 14px; text-align: left; font-weight: 600; color: #374151;\">v3 Result</th></tr></thead>\n",
       "        <tbody><tr style=\"background: #F9FAFB; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">How long will I wait at Olive Garden?</td><td style=\"padding: 10px 14px; color: #4B5563;\">get_wait_time('Olive Garden') → 25</td></tr><tr style=\"background: #FFFFFF; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">Is Sushi Palace well reviewed?</td><td style=\"padding: 10px 14px; color: #4B5563;\">get_rating('Sushi Palace') → 4.5</td></tr><tr style=\"background: #F9FAFB; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">What kind of food does Taj Mahal serve?</td><td style=\"padding: 10px 14px; color: #4B5563;\">get_cuisine('Taj Mahal') → Indian</td></tr><tr style=\"background: #FFFFFF; border-bottom: 1px solid #E5E7EB;\"><td style=\"padding: 10px 14px; color: #4B5563;\">How far is Burger Barn?</td><td style=\"padding: 10px 14px; color: #4B5563;\">get_distance('Burger Barn') → 0.8</td></tr></tbody>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# v3 picks the right tool without any hardcoded branches\n",
    "compare_table(\n",
    "    rows=[\n",
    "        (q, restaurant_agent_v3(q)) for q in [\n",
    "            \"How long will I wait at Olive Garden?\",\n",
    "            \"Is Sushi Palace well reviewed?\",\n",
    "            \"What kind of food does Taj Mahal serve?\",\n",
    "            \"How far is Burger Barn?\",\n",
    "        ]\n",
    "    ],\n",
    "    headers=(\"Query\", \"v3 Result\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04617243",
   "metadata": {},
   "source": [
    "> **The remaining problem:** Consider answering *\"What's the wait at Olive Garden?\"* in full. The correct sequence is:\n",
    "> 1. `get_wait_time('Olive Garden')` → 25\n",
    "> 2. Use that result in a natural-language response\n",
    ">\n",
    "> That's manageable with one call. But *\"What's the best Italian place within 10 minutes?\"* needs 7+ calls — and each call's *arguments depend on the result of a previous call*. v3 can only make one.\n",
    "\n",
    "---\n",
    "### Agent v4 — The Loop\n",
    "\n",
    "The fix is simple: let the agent keep going. After each tool call, feed the result back to the LLM and ask \"what's next?\" Keep looping until it says it's done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a53ba0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurant_agent_v4(query: str, max_steps: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Agent v4: LLM reasons and acts in a loop until the query is answered.\n",
    "    This is the ReAct pattern.\n",
    "    \"\"\"\n",
    "    print(f\"Query: {query}\")\n",
    "    separator()\n",
    "\n",
    "    history = []  # Running log of (tool_call, result) pairs\n",
    "\n",
    "    for step in range(1, max_steps + 1):\n",
    "        # Build the prompt from scratch each step, including full history\n",
    "        history_text = \"\\n\".join(f\"  Step {i+1}: {entry}\" for i, entry in enumerate(history))\n",
    "\n",
    "        prompt = f\"\"\"You are answering this restaurant query: {query}\n",
    "\n",
    "{TOOL_DESCRIPTIONS}\n",
    "\n",
    "Steps taken so far:\n",
    "{history_text if history_text else \"  (none yet)\"}\n",
    "\n",
    "What is the NEXT single tool call needed?\n",
    "If the query is fully answered, respond with exactly: DONE\n",
    "Otherwise respond with a single function call only (no explanation, no code fences).\"\"\"\n",
    "\n",
    "        response = generate(prompt).strip().strip(\"`\")\n",
    "\n",
    "        print(f\"  Step {step}: {response}\")\n",
    "\n",
    "        if \"DONE\" in response.upper():\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            result = eval(response, TOOLS_V3)\n",
    "            history.append(f\"{response} → {result}\")\n",
    "        except Exception as e:\n",
    "            history.append(f\"{response} → ERROR: {e}\")\n",
    "\n",
    "    # Generate a natural-language answer from the accumulated results\n",
    "    steps_summary = \"\\n\".join(f\"  {entry}\" for entry in history)\n",
    "    answer = generate(\n",
    "        f\"\"\"The user asked: \"{query}\"\n",
    "Results from tool calls:\n",
    "{steps_summary}\n",
    "\n",
    "Write a clear, concise answer to the user's question.\"\"\",\n",
    "    )\n",
    "\n",
    "    separator()\n",
    "    output_box(answer, label=\"Final Answer\", style=\"success\")\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "973bd429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What's the wait at Olive Garden?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr style=\"border: none; border-top: 1px solid #D1D5DB; margin: 16px 0;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 1: list_restaurants()\n",
      "  Step 2: get_wait_time('Olive Garden')\n",
      "  Step 3: DONE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr style=\"border: none; border-top: 1px solid #D1D5DB; margin: 16px 0;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #F0FDF4; border-left: 4px solid #DCFCE7; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #15803D; margin-bottom: 4px;\">Final Answer</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">The wait at Olive Garden is currently 25 minutes.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The wait at Olive Garden is currently 25 minutes.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple query — completes in 1–2 steps\n",
    "restaurant_agent_v4(\"What's the wait at Olive Garden?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7eccdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What's the best Italian place within 10 minutes of me?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr style=\"border: none; border-top: 1px solid #D1D5DB; margin: 16px 0;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 1: list_restaurants()\n",
      "  Step 2: get_cuisine('Olive Garden')\n",
      "  Step 3: get_distance('Olive Garden')\n",
      "  Step 4: get_wait_time('Olive Garden')\n",
      "  Step 5: get_rating('Olive Garden')\n",
      "  Step 6: get_distance('Sushi Palace')\n",
      "  Step 7: get_cuisine('Sushi Palace')\n",
      "  Step 8: get_distance('Burger Barn')\n",
      "  Step 9: get_cuisine('Burger Barn')\n",
      "  Step 10: get_distance('Taj Mahal')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr style=\"border: none; border-top: 1px solid #D1D5DB; margin: 16px 0;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #F0FDF4; border-left: 4px solid #DCFCE7; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #15803D; margin-bottom: 4px;\">Final Answer</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">The best Italian place within 10 minutes of you is Olive Garden, which is 1.2 miles away. It has a rating of 3.8 and a wait time of about 25 minutes.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The best Italian place within 10 minutes of you is Olive Garden, which is 1.2 miles away. It has a rating of 3.8 and a wait time of about 25 minutes.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complex query — requires multiple steps and dependent arguments\n",
    "restaurant_agent_v4(\"What's the best Italian place within 10 minutes of me?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96da96eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Which restaurant has the best rating-to-wait-time ratio?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr style=\"border: none; border-top: 1px solid #D1D5DB; margin: 16px 0;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 1: list_restaurants()\n",
      "  Step 2: get_wait_time('Olive Garden')\n",
      "  Step 3: get_rating('Olive Garden')\n",
      "  Step 4: get_wait_time('Sushi Palace')\n",
      "  Step 5: get_rating('Sushi Palace')\n",
      "  Step 6: get_wait_time('Burger Barn')\n",
      "  Step 7: get_rating('Burger Barn')\n",
      "  Step 8: get_wait_time('Taj Mahal')\n",
      "  Step 9: get_rating('Taj Mahal')\n",
      "  Step 10: get_wait_time('La Maison')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr style=\"border: none; border-top: 1px solid #D1D5DB; margin: 16px 0;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #F0FDF4; border-left: 4px solid #DCFCE7; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #15803D; margin-bottom: 4px;\">Final Answer</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">To find the best rating-to-wait-time ratio, we can calculate the ratio for each restaurant:\n",
       "\n",
       "1. **Olive Garden**: Rating 3.8, Wait time 25 minutes → Ratio = 3.8 / 25 = 0.152\n",
       "2. **Sushi Palace**: Rating 4.5, Wait time 10 minutes → Ratio = 4.5 / 10 = 0.45\n",
       "3. **Burger Barn**: Rating 3.5, Wait time 5 minutes → Ratio = 3.5 / 5 = 0.7\n",
       "4. **Taj Mahal**: Rating 4.7, Wait time 15 minutes → Ratio = 4.7 / 15 = 0.313\n",
       "5. **La Maison**: Rating not provided, Wait time 40 minutes → Ratio cannot be calculated.\n",
       "\n",
       "The restaurant with the best rating-to-wait-time ratio is **Burger Barn** with a ratio of **0.7**.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'To find the best rating-to-wait-time ratio, we can calculate the ratio for each restaurant:\\n\\n1. **Olive Garden**: Rating 3.8, Wait time 25 minutes → Ratio = 3.8 / 25 = 0.152\\n2. **Sushi Palace**: Rating 4.5, Wait time 10 minutes → Ratio = 4.5 / 10 = 0.45\\n3. **Burger Barn**: Rating 3.5, Wait time 5 minutes → Ratio = 3.5 / 5 = 0.7\\n4. **Taj Mahal**: Rating 4.7, Wait time 15 minutes → Ratio = 4.7 / 15 = 0.313\\n5. **La Maison**: Rating not provided, Wait time 40 minutes → Ratio cannot be calculated.\\n\\nThe restaurant with the best rating-to-wait-time ratio is **Burger Barn** with a ratio of **0.7**.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bonus — a query none of the earlier versions could handle\n",
    "restaurant_agent_v4(\"Which restaurant has the best rating-to-wait-time ratio?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3598038",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6 — The ReAct Pattern\n",
    "\n",
    "Let's look at the evolution we just built:\n",
    "\n",
    "| Version | Approach | Strengths | Weakness |\n",
    "|---|---|---|---|\n",
    "| v1 | Keyword matching | Fast, no API calls | Breaks on any rephrasing |\n",
    "| v2 | LLM classifies intent | Handles natural language | Rigid if/else branches |\n",
    "| v3 | LLM picks the tool | No hardcoded branches | Only one tool call |\n",
    "| v4 | LLM loops until done | Multi-step, flexible | — |\n",
    "\n",
    "**v4 has a name in AI research: ReAct (Reasoning and Acting)**\n",
    "\n",
    "It was introduced in this [paper (Yao et al., 2022)](https://arxiv.org/abs/2210.03629). The loop looks like this:\n",
    "\n",
    "```\n",
    "┌──────────────────────────────┐\n",
    "│         User Query           │\n",
    "└──────────────┬───────────────┘\n",
    "               ▼\n",
    "         ┌──────────┐\n",
    "         │  REASON  │  ← What do I need to know next?\n",
    "         └────┬─────┘\n",
    "              ▼\n",
    "         ┌──────────┐\n",
    "         │   ACT    │  ← Call the right tool\n",
    "         └────┬─────┘\n",
    "              ▼\n",
    "         ┌──────────┐\n",
    "         │ OBSERVE  │  ← What did the tool return?\n",
    "         └────┬─────┘\n",
    "              ▼\n",
    "     ┌────────────────┐\n",
    "     │  Task done?    │\n",
    "     │  No → repeat   │\n",
    "     │  Yes → answer  │\n",
    "     └────────────────┘\n",
    "```\n",
    "\n",
    "The key property: **no hardcoded pipelines**. The LLM dynamically decides what to do next at every step, based on everything it has seen so far.\n",
    "\n",
    "For more detail: [ReAct Prompting Guide](https://www.promptingguide.ai/techniques/react) | [Anthropic on Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bee4d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: #EFF6FF; border-left: 4px solid #DBEAFE; padding: 12px 16px; border-radius: 4px; margin: 8px 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\">\n",
       "        <div style=\"font-weight: 600; color: #1D4ED8; margin-bottom: 4px;\">The Core Idea</div>\n",
       "        <pre style=\"margin: 0; white-space: pre-wrap; font-size: 13px; line-height: 1.5; color: #374151;\">An agent is just a loop:\n",
       "  1. LLM reasons about what to do next\n",
       "  2. System executes the chosen action\n",
       "  3. Result feeds back into the next reasoning step\n",
       "  4. Repeat until the goal is met\n",
       "\n",
       "The LLM provides the intelligence.\n",
       "The tools provide the capabilities.\n",
       "The loop provides the flexibility.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_box(\n",
    "    \"\"\"An agent is just a loop:\n",
    "  1. LLM reasons about what to do next\n",
    "  2. System executes the chosen action\n",
    "  3. Result feeds back into the next reasoning step\n",
    "  4. Repeat until the goal is met\n",
    "\n",
    "The LLM provides the intelligence.\n",
    "The tools provide the capabilities.\n",
    "The loop provides the flexibility.\"\"\",\n",
    "    label=\"The Core Idea\",\n",
    "    style=\"info\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad3130c",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7 — What's Next\n",
    "\n",
    "Today we built agents with *toy tools*: `get_wait_time`, `get_rating`, `get_distance`. These work with hardcoded dictionaries, but the pattern is exactly the same when the tools connect to real data.\n",
    "\n",
    "**Our real project: an AI-powered Analytics Assistant**\n",
    "\n",
    "Instead of a restaurant dictionary, users will have a dataset like this:\n",
    "\n",
    "```\n",
    "date       | product  | category    | price | quantity | region\n",
    "-----------|----------|-------------|-------|----------|--------\n",
    "2024-01-01 | Laptop   | Electronics | 1200  | 2        | North\n",
    "2024-01-02 | Mouse    | Accessories | 25    | 10       | South\n",
    "...\n",
    "```\n",
    "\n",
    "And instead of `get_wait_time`, we'll have tools like:\n",
    "\n",
    "```python\n",
    "load_csv(filepath)\n",
    "show_data(n_rows)\n",
    "filter_rows(condition)\n",
    "group_and_aggregate(group_by, column, operation)\n",
    "create_plot(plot_type, **kwargs)\n",
    "```\n",
    "\n",
    "The user asks: *\"What's the average price by category?\"*\n",
    "The agent: loads the data, groups by category, calculates mean, returns results — automatically.\n",
    "\n",
    "**Before next week, think about:**\n",
    "1. What 3–5 queries would you ask your own data?\n",
    "2. What tools would you need to answer them?\n",
    "3. How granular should those tools be — very broad, very specific, or composable?\n",
    "\n",
    "We'll build it together in Workshop 4.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
