{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 Workshop 5: ReAct and Code Agents\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Today's Agenda\n",
    "\n",
    "Build **multi-step reasoning agents** that can break down complex problems and chain operations.\n",
    "\n",
    "### What We'll Build\n",
    "\n",
    "1. 🧠 **ReAct Agent** - Multi-step reasoning with our tools\n",
    "2. 💾 **Artifact Store** - Tracking intermediate results\n",
    "3. 💻 **CodeAgent** - Generates code that chains operations\n",
    "4. 🔒 **Safe Execution** - Secure code execution environment\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "> Single-step agents can't solve complex queries. We need agents that can **think**, **act**, and **learn** from their actions to tackle real-world problems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from openai) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.11/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install openai pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📦 Part 0: Setup and Recap\n",
    "\n",
    "Last workshop we built 9 tools but only used them **one at a time**. Today we'll make our agent **smarter**.\n",
    "\n",
    "### Core Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Core utilities loaded\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import TypedDict, List, Callable, Dict, Any, Optional, Type, Union\n",
    "from pydantic import BaseModel\n",
    "import inspect\n",
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def generate(\n",
    "    prompt: str,\n",
    "    temperature: float = 0,\n",
    "    response_format: Optional[Type[BaseModel]] = None,\n",
    "    model: str = \"gpt-4o-mini\"\n",
    ") -> Union[str, BaseModel]:\n",
    "    \"\"\"\n",
    "    🎨 Generate text using OpenAI's API with optional structured output\n",
    "\n",
    "    Args:\n",
    "        prompt: The input prompt for generation\n",
    "        temperature: Sampling temperature (0-2), default 0\n",
    "        response_format: Optional Pydantic model class for structured output\n",
    "        model: The model to use, default \"gpt-4o-mini\"\n",
    "\n",
    "    Returns:\n",
    "        Either a string (regular generation) or a Pydantic model instance (structured output)\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    if response_format is not None:\n",
    "        # Use structured output with Pydantic model\n",
    "        response = openai_client.beta.chat.completions.parse(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            response_format=response_format\n",
    "        )\n",
    "        return response.choices[0].message.parsed\n",
    "    else:\n",
    "        # Regular text generation\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "print(\"✅ Core utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Dataset loaded: 800 Pokemon, 13 columns\n",
      "📋 Columns: #, name, type_1, type_2, total, hp, attack, defense, sp_atk, sp_def, speed, generation, legendary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>name</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "      <th>total</th>\n",
       "      <th>hp</th>\n",
       "      <th>attack</th>\n",
       "      <th>defense</th>\n",
       "      <th>sp_atk</th>\n",
       "      <th>sp_def</th>\n",
       "      <th>speed</th>\n",
       "      <th>generation</th>\n",
       "      <th>legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   name type_1  type_2  total  hp  attack  defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   sp_atk  sp_def  speed  generation  legendary  \n",
       "0      65      65     45           1      False  \n",
       "1      80      80     60           1      False  \n",
       "2     100     100     80           1      False  \n",
       "3     122     120     80           1      False  \n",
       "4      60      50     65           1      False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Pokemon dataset\n",
    "df = pd.read_csv('data/pokemon.csv')\n",
    "df.columns = (df.columns\n",
    "              .str.replace(' ', '_', regex=False)\n",
    "              .str.replace('.', '', regex=False)\n",
    "              .str.lower())\n",
    "\n",
    "print(f\"📊 Dataset loaded: {df.shape[0]} Pokemon, {df.shape[1]} columns\")\n",
    "print(f\"📋 Columns: {', '.join(df.columns.tolist())}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔧 Tools from Workshop 4\n",
    "\n",
    "We built 9 tools last week. Let's import them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 9 tools from Workshop 4\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# EXPLORATION TOOLS\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "def load_csv(filepath: str):\n",
    "    \"\"\"📂 Load CSV from a given filepath into global dataframe.\"\"\"\n",
    "    global df\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.columns = (df.columns\n",
    "      .str.replace(' ', '_', regex=False)\n",
    "      .str.replace('.', '', regex=False)\n",
    "      .str.lower())\n",
    "    return f\"✅ Loaded {filepath}: {df.shape[0]} rows, {df.shape[1]} columns\"\n",
    "\n",
    "def show_info():\n",
    "    \"\"\"ℹ️ Show dataframe structure: columns, types, missing values.\"\"\"\n",
    "    import io\n",
    "    buffer = io.StringIO()\n",
    "    df.info(buf=buffer)\n",
    "    return buffer.getvalue()\n",
    "\n",
    "def show_data(n: int = 5, sort_by: str = None, ascending: bool = True):\n",
    "    \"\"\"👀 Show first n rows of dataframe, optionally sorted.\"\"\"\n",
    "    display_df = df\n",
    "    if sort_by:\n",
    "        display_df = df.sort_values(sort_by, ascending=ascending)\n",
    "    return display_df.head(n).to_string()\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# ANALYSIS TOOLS\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "def filter_rows(condition: str):\n",
    "    \"\"\"🔍 Filter dataframe rows using pandas query syntax. The condition string is the query expression for Pandas df.query\"\"\"\n",
    "    result = df.query(condition)\n",
    "    return f\"Found {len(result)} Pokemon:\\n{result.to_string()}\"\n",
    "\n",
    "def calculate_statistics(column: str, stat_type: str):\n",
    "    \"\"\"📊 Calculate statistics on a column.\"\"\"\n",
    "    stat_functions = {\n",
    "        'mean': df[column].mean,\n",
    "        'median': df[column].median,\n",
    "        'max': df[column].max,\n",
    "        'min': df[column].min,\n",
    "        'sum': df[column].sum,\n",
    "        'count': df[column].count,\n",
    "        'std': df[column].std\n",
    "    }\n",
    "    result = stat_functions[stat_type]()\n",
    "    return f\"{stat_type.capitalize()} of {column}: {result:.2f}\"\n",
    "\n",
    "def aggregate_by(group_by: str, agg_col: str, agg_func: str):\n",
    "    \"\"\"📈 Group data and calculate aggregate statistics.\"\"\"\n",
    "    result = df.groupby(group_by)[agg_col].agg(agg_func)\n",
    "    return f\"{agg_func.capitalize()} of {agg_col} by {group_by}:\\n{result.to_string()}\"\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# VISUALIZATION TOOLS\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "def create_bar_chart(category_col: str, value_col: str = None, \n",
    "                     aggregation: str = 'count', title: str = None):\n",
    "    \"\"\"📊 Create a bar chart comparing categories.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if aggregation == 'count':\n",
    "        data = df[category_col].value_counts().sort_index()\n",
    "        ylabel = 'Count'\n",
    "    else:\n",
    "        agg_funcs = {'mean': 'mean', 'sum': 'sum', 'max': 'max', 'min': 'min', 'median': 'median'}\n",
    "        data = df.groupby(category_col)[value_col].agg(agg_funcs[aggregation])\n",
    "        ylabel = f'{aggregation.capitalize()} of {value_col}'\n",
    "    \n",
    "    data.plot(kind='bar')\n",
    "    plt.title(title or f'{ylabel} by {category_col}')\n",
    "    plt.xlabel(category_col)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return f\"✅ Bar chart created: {ylabel} by {category_col}\"\n",
    "\n",
    "def create_scatter_plot(x_col: str, y_col: str, color_by: str = None):\n",
    "    \"\"\"📈 Create a scatter plot to show relationships.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if color_by and color_by in df.columns:\n",
    "        for category in df[color_by].unique():\n",
    "            mask = df[color_by] == category\n",
    "            plt.scatter(df[mask][x_col], df[mask][y_col], label=category, alpha=0.6)\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.scatter(df[x_col], df[y_col], alpha=0.6)\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.title(f'{y_col} vs {x_col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return f\"✅ Scatter plot created: {y_col} vs {x_col}\"\n",
    "\n",
    "def create_histogram(column: str, bins: int = 20):\n",
    "    \"\"\"📊 Create a histogram showing distribution.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df[column].dropna(), bins=bins, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return f\"✅ Histogram created for {column}\"\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# ALL TOOLS\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "all_tools = [\n",
    "    load_csv, show_info, show_data,\n",
    "    filter_rows, calculate_statistics, aggregate_by,\n",
    "    create_bar_chart, create_scatter_plot, create_histogram\n",
    "]\n",
    "\n",
    "print(f\"✅ Loaded {len(all_tools)} tools from Workshop 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🤖 The Single-Step Agent (from Workshop 4)\n",
    "\n",
    "Our current agent can only pick **ONE** tool at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing single-step agent:\n",
      "🤖 Agent chose: calculate_statistics(column=\"attack\", stat_type=\"mean\")\n",
      "\n",
      "Mean of attack: 79.00\n"
     ]
    }
   ],
   "source": [
    "def generate_tool_descriptions(tools: List[Callable]) -> str:\n",
    "    \"\"\"Generate tool descriptions from function introspection.\"\"\"\n",
    "    descriptions = []\n",
    "    for func in tools:\n",
    "        sig = inspect.signature(func)\n",
    "        params = []\n",
    "        for name, param in sig.parameters.items():\n",
    "            param_type = param.annotation.__name__ if param.annotation != inspect.Parameter.empty else \"any\"\n",
    "            default = f\" (default: {param.default})\" if param.default != inspect.Parameter.empty else \"\"\n",
    "            params.append(f\"  - {name}: {param_type}{default}\")\n",
    "\n",
    "        doc_lines = (func.__doc__ or \"No description\").strip().split('\\n')\n",
    "        short_desc = doc_lines[0]\n",
    "\n",
    "        desc = f\"\"\"{func.__name__}: {short_desc}\n",
    "Parameters:\n",
    "{chr(10).join(params) if params else '  None'}\"\"\"\n",
    "        descriptions.append(desc)\n",
    "\n",
    "    return \"\\n\\n\".join(descriptions)\n",
    "\n",
    "# Create tools dictionary\n",
    "tools_dict_v1 = {func.__name__: func for func in all_tools}\n",
    "\n",
    "def single_step_agent(query: str):\n",
    "    \"\"\"🤖 Agent that picks ONE tool.\"\"\"\n",
    "    prompt = f\"\"\"You are a data analysis assistant.\n",
    "\n",
    "Dataset: Pokemon with {len(df)} rows\n",
    "Columns: {df.columns.tolist()}\n",
    "\n",
    "Available tools:\n",
    "{generate_tool_descriptions(all_tools)}\n",
    "\n",
    "User query: \"{query}\"\n",
    "\n",
    "Choose the ONE tool that best answers this query.\n",
    "Respond with ONLY the tool call, no explanation.\n",
    "\n",
    "Format: tool_name(param=\"value\")\n",
    "\n",
    "Your response:\"\"\"\n",
    "\n",
    "    response = generate(prompt).strip()\n",
    "    print(f\"🤖 Agent chose: {response}\\n\")\n",
    "\n",
    "    try:\n",
    "        result = eval(response, {\"__builtins__\": {}}, tools_dict_v1)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test it\n",
    "print(\"🧪 Testing single-step agent:\")\n",
    "print(single_step_agent(\"What's the average attack of all Pokemon?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️ The Problem\n",
    "\n",
    "**What if we need multiple steps?**\n",
    "\n",
    "Query: *\"Which Pokemon type has the highest average attack?\"*\n",
    "\n",
    "- **Step 1:** Group by type and calculate average\n",
    "- **Step 2:** Find the maximum\n",
    "\n",
    "> ❌ Single-step agent can only do step 1!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Part 1: Building a ReAct Agent\n",
    "\n",
    "Let's add multi-step reasoning using the **ReAct pattern**:\n",
    "\n",
    "```\n",
    "Loop:\n",
    "  1. 💭 Thought: \"What should I do next?\"\n",
    "  2. ⚙️  Action: Call a tool\n",
    "  3. 📊 Observation: See the result\n",
    "  4. 🔄 Repeat until done\n",
    "```\n",
    "\n",
    "### Step 1: Define Types\n",
    "\n",
    "We'll use **Pydantic models** for structured data throughout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# PYDANTIC MODELS FOR AGENT HISTORY\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "class ThoughtStep(BaseModel):\n",
    "    \"\"\"💭 What the agent is thinking\"\"\"\n",
    "    reasoning: str\n",
    "\n",
    "class ActionStep(BaseModel):\n",
    "    \"\"\"⚙️ What tool to call\"\"\"\n",
    "    tool_call: str\n",
    "\n",
    "class ObservationStep(BaseModel):\n",
    "    \"\"\"📊 What the tool returned\"\"\"\n",
    "    result: str\n",
    "    success: bool\n",
    "\n",
    "class HistoryEntry(BaseModel):\n",
    "    \"\"\"🔄 One complete step in the ReAct loop\"\"\"\n",
    "    step_number: int\n",
    "    thought: ThoughtStep\n",
    "    action: ActionStep\n",
    "    observation: ObservationStep\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# FOR AGENT REASONING (STRUCTURED LLM OUTPUT)\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "class ReActResponse(BaseModel):\n",
    "    \"\"\"📋 Structured response from ReAct agent\"\"\"\n",
    "    thought: str\n",
    "    action: str  # Tool call OR empty string\n",
    "    is_final_answer: bool  # True when ready to answer\n",
    "    needs_user_input: bool  # True when asking user for clarification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Why Structured Outputs?\n",
    "\n",
    "#### ❌ Old Way (String Parsing)\n",
    "```python\n",
    "response = \"THOUGHT: I need to filter\\nACTION: filter_rows(...)\"\n",
    "# Parse with split(), regex, etc. - fragile!\n",
    "if \"ANSWER\" in response:  # String checking - error-prone!\n",
    "```\n",
    "\n",
    "#### ✅ New Way (Structured Outputs with Pydantic)\n",
    "```python\n",
    "response = generate(prompt, response_format=ReActResponse)\n",
    "response.thought  # ✅ Guaranteed to exist\n",
    "response.action   # ✅ Type-safe access\n",
    "if response.is_final_answer:  # ✅ Boolean check - clean!\n",
    "```\n",
    "\n",
    "#### 🎯 Benefits\n",
    "\n",
    "| Feature | String Parsing | Structured Outputs |\n",
    "|---------|----------------|--------------------|\n",
    "| Markdown issues | ❌ Fragile | ✅ No issues |\n",
    "| Invalid formats | ❌ Possible | ✅ Validated |\n",
    "| Type safety | ❌ Manual | ✅ Automatic |\n",
    "| Control flow | ❌ String checks | ✅ Boolean flags |\n",
    "| Code cleanliness | ❌ Complex parsing | ✅ Simple access |\n",
    "\n",
    "---\n",
    "\n",
    "Now let's build the ReAct agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_react_prompt(query: str, tools: List[Callable], history: List[HistoryEntry]) -> str:\n",
    "    \"\"\"🎨 Build prompt for ReAct agent with history.\"\"\"\n",
    "\n",
    "    # Format history for prompt\n",
    "    history_text = \"\"\n",
    "    if history:\n",
    "        history_text = \"\\n\\nPrevious steps:\\n\"\n",
    "        for entry in history:\n",
    "            history_text += f\"\"\"\n",
    "Step {entry.step_number}:\n",
    "Thought: {entry.thought.reasoning}\n",
    "Action: {entry.action.tool_call}\n",
    "Observation: {entry.observation.result}\n",
    "\"\"\"\n",
    "\n",
    "    # Check if data is loaded\n",
    "    dataset_status = f\"Current dataset: Loaded ({len(df)} rows, {len(df.columns)} columns)\" if len(df) > 0 else \"No dataset loaded\"\n",
    "\n",
    "    prompt = f\"\"\"You are a data analysis agent using the ReAct pattern.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "{dataset_status}\n",
    "\n",
    "Available tools:\n",
    "{generate_tool_descriptions(tools)}\n",
    "{history_text}\n",
    "\n",
    "CORE PRINCIPLE: Only use information you explicitly have.\n",
    "\n",
    "Tool outputs provide:\n",
    "- message: natural language summary\n",
    "- artifact (optional): handle metadata with an `id` you can reuse (e.g., df_0)\n",
    "\n",
    "When you need a prior result, pass the artifact id via the tool's `df_id` (or similar) parameter.\n",
    "\n",
    "If you're missing information, ask the user.\n",
    "If you can answer from existing observations, deliver the final answer instead of calling another tool.\n",
    "\n",
    "Your response JSON:\n",
    "- thought: reasoning about the next step\n",
    "- action: tool call with exact parameter values, or empty string if not calling a tool\n",
    "- is_final_answer: true if you can answer the user's query, otherwise false\n",
    "- needs_user_input: true if you need to ask the user for missing information, otherwise false\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def synthesize_final_answer(query: str, history: List[HistoryEntry], final_thought: str) -> str:\n",
    "    \"\"\"🎯 Synthesize a user-facing answer from the agent's observations.\"\"\"\n",
    "\n",
    "    observations_text = \"\"\n",
    "    for entry in history:\n",
    "        observations_text += f\"\\nStep {entry.step_number}: {entry.action.tool_call}\\nResult: {entry.observation.result}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"You are synthesizing a final answer for a user's data analysis query.\n",
    "\n",
    "Original query: \"{query}\"\n",
    "\n",
    "Agent's final reasoning: {final_thought}\n",
    "\n",
    "Observations from tool executions:\n",
    "{observations_text if observations_text else \"No tool executions\"}\n",
    "\n",
    "Instructions:\n",
    "- Provide a clear, direct answer to the user's query\n",
    "- Base your answer on the observations\n",
    "- Use natural language, not technical jargon\n",
    "- Be concise but complete\n",
    "\n",
    "Final answer:\"\"\"\n",
    "\n",
    "    return generate(prompt, temperature=0.3)\n",
    "\n",
    "\n",
    "def react_agent(query: str, max_steps: int = 10, verbose: bool = True, tools: Optional[List[Callable]] = None) -> str:\n",
    "    \"\"\"🤖 Multi-step ReAct agent using structured outputs.\"\"\"\n",
    "    active_tools = tools or all_tools\n",
    "    tools_dict = {func.__name__: func for func in active_tools}\n",
    "    history: List[HistoryEntry] = []\n",
    "\n",
    "    for step in range(1, max_steps + 1):\n",
    "        if verbose:\n",
    "            print(f\"\\n{'═' * 70}\")\n",
    "            print(f\"🔄 STEP {step}\")\n",
    "            print('═' * 70)\n",
    "\n",
    "        prompt = build_react_prompt(query, active_tools, history)\n",
    "        response = generate(prompt, response_format=ReActResponse)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n💭 THOUGHT: {response.thought}\\n\")\n",
    "\n",
    "        if response.needs_user_input:\n",
    "            if verbose:\n",
    "                print(\"\\n❓ AGENT NEEDS USER INPUT\")\n",
    "            return response.thought\n",
    "\n",
    "        if response.is_final_answer:\n",
    "            if verbose:\n",
    "                print(\"\\n✅ AGENT FINISHED! Synthesizing answer from observations...\")\n",
    "            return synthesize_final_answer(query, history, response.thought)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"⚙️  ACTION: {response.action}\")\n",
    "            print(f\"\\n⚙️  EXECUTING: {response.action}\")\n",
    "\n",
    "        try:\n",
    "            safe_globals = {\"__builtins__\": {}}\n",
    "            safe_globals.update(tools_dict)\n",
    "            evaluation = eval(response.action, safe_globals, {})\n",
    "            if callable(evaluation):\n",
    "                evaluation = evaluation()\n",
    "            observation = ObservationStep(result=str(evaluation), success=True)\n",
    "\n",
    "            if verbose:\n",
    "                preview = str(evaluation)\n",
    "                print(f\"\\n📊 TOOL RESULT:\\n{preview[:300]}...\" if len(preview) > 300 else f\"\\n📊 TOOL RESULT:\\n{preview}\")\n",
    "        except Exception as e:\n",
    "            observation = ObservationStep(result=f\"Error: {e}\", success=False)\n",
    "            if verbose:\n",
    "                print(f\"\\n❌ TOOL ERROR: {e}\")\n",
    "\n",
    "        history.append(HistoryEntry(\n",
    "            step_number=step,\n",
    "            thought=ThoughtStep(reasoning=response.thought),\n",
    "            action=ActionStep(tool_call=response.action),\n",
    "            observation=observation,\n",
    "        ))\n",
    "\n",
    "    final_thought = \"I reached the maximum number of steps. Based on what I've learned:\"\n",
    "    return synthesize_final_answer(query, history, final_thought)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧪 Test the ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 QUERY: Which Pokemon type has the highest average attack?\n",
      "\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 1\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: To find out which Pokemon type has the highest average attack, I need to group the dataset by the Pokemon type and calculate the average attack for each type. Then, I can identify the type with the highest average attack.\n",
      "\n",
      "⚙️  ACTION: aggregate_by(group_by='type', agg_col='attack', agg_func='mean')\n",
      "\n",
      "⚙️  EXECUTING: aggregate_by(group_by='type', agg_col='attack', agg_func='mean')\n",
      "\n",
      "❌ TOOL ERROR: 'type'\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 2\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: I need to check the structure of the dataset to understand the column names and types, especially to find out how the Pokemon types and attack values are represented.\n",
      "\n",
      "⚙️  ACTION: show_info()\n",
      "\n",
      "⚙️  EXECUTING: show_info()\n",
      "\n",
      "📊 TOOL RESULT:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           800 non-null    int64 \n",
      " 1   name        800 non-null    object\n",
      " 2   type_1      800 non-null    ob...\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 3\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: The dataset contains two columns for Pokemon types: 'type_1' and 'type_2'. I will group by 'type_1' to calculate the average attack for each primary type. After that, I can find the type with the highest average attack.\n",
      "\n",
      "⚙️  ACTION: aggregate_by(group_by='type_1', agg_col='attack', agg_func='mean')\n",
      "\n",
      "⚙️  EXECUTING: aggregate_by(group_by='type_1', agg_col='attack', agg_func='mean')\n",
      "\n",
      "📊 TOOL RESULT:\n",
      "Mean of attack by type_1:\n",
      "type_1\n",
      "Bug          70.971014\n",
      "Dark         88.387097\n",
      "Dragon      112.125000\n",
      "Electric     69.090909\n",
      "Fairy        61.529412\n",
      "Fighting     96.777778\n",
      "Fire         84.769231\n",
      "Flying       78.750000\n",
      "Ghost        73.781250\n",
      "Grass        73.214286\n",
      "Ground       95.750000\n",
      "Ice          7...\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 4\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: I have calculated the average attack for each primary Pokemon type. Now, I need to identify which type has the highest average attack from the results I obtained.\n",
      "\n",
      "\n",
      "✅ AGENT FINISHED! Synthesizing answer from observations...\n",
      "\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🎉 FINAL ANSWER: The Pokémon type with the highest average attack is Dragon, with an average attack value of 112.13.\n",
      "══════════════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "source": [
    "query = \"Which Pokemon type has the highest average attack?\"\n",
    "\n",
    "print(f\"🎯 QUERY: {query}\\n\")\n",
    "answer = react_agent(query, max_steps=15)\n",
    "\n",
    "print(f\"\\n\\n{'═'*70}\")\n",
    "print(f\"🎉 FINAL ANSWER: {answer}\")\n",
    "print('═'*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎉 Success!\n",
    "\n",
    "The ReAct agent can take multiple steps:\n",
    "\n",
    "1. **Step 1:** Groups by type and calculates average attack\n",
    "2. **Step 2:** Analyzes the results and signals it's done\n",
    "3. **Synthesis:** System automatically generates user-facing answer from observations\n",
    "\n",
    "> **Key insight:** The agent focuses on *gathering information* (tool execution), then we *synthesize* a clean answer.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚠️ Part 2: The Limitation\n",
    "\n",
    "But wait... let's try a query that needs to **chain operations**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 QUERY: What is the average attack for Fire-type Pokemon?\n",
      "\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 1\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: I need to filter the dataset to include only Fire-type Pokemon and then calculate the average attack for that subset.\n",
      "\n",
      "⚙️  ACTION: filter_rows('type == \"Fire\"')\n",
      "\n",
      "⚙️  EXECUTING: filter_rows('type == \"Fire\"')\n",
      "\n",
      "❌ TOOL ERROR: name 'type' is not defined\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 2\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: I need to check the structure of the dataset to find the correct column name for the Pokemon type before filtering for Fire-type Pokemon.\n",
      "\n",
      "⚙️  ACTION: show_info()\n",
      "\n",
      "⚙️  EXECUTING: show_info()\n",
      "\n",
      "📊 TOOL RESULT:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           800 non-null    int64 \n",
      " 1   name        800 non-null    object\n",
      " 2   type_1      800 non-null    ob...\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 3\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: Now that I know the correct column name for the Pokemon type is 'type_1', I can filter the dataset for Fire-type Pokemon using this column. After filtering, I will calculate the average attack for these Pokemon.\n",
      "\n",
      "⚙️  ACTION: filter_rows('type_1 == \"Fire\"')\n",
      "\n",
      "⚙️  EXECUTING: filter_rows('type_1 == \"Fire\"')\n",
      "\n",
      "📊 TOOL RESULT:\n",
      "Found 52 Pokemon:\n",
      "       #                       name type_1    type_2  total   hp  attack  defense  sp_atk  sp_def  speed  generation  legendary\n",
      "4      4                 Charmander   Fire       NaN    309   39      52       43      60      50     65           1      False\n",
      "5      5                 C...\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 4\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: I have filtered the dataset to include only Fire-type Pokemon. Now, I will calculate the average attack for these Pokemon using the 'attack' column.\n",
      "\n",
      "⚙️  ACTION: calculate_statistics('attack', 'mean')\n",
      "\n",
      "⚙️  EXECUTING: calculate_statistics('attack', 'mean')\n",
      "\n",
      "📊 TOOL RESULT:\n",
      "Mean of attack: 79.00\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 5\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: I have successfully calculated the average attack for Fire-type Pokemon, which is 79.00. This is the final answer to the user's query.\n",
      "\n",
      "\n",
      "✅ AGENT FINISHED! Synthesizing answer from observations...\n",
      "\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🎉 FINAL ANSWER: The average attack for Fire-type Pokémon is 79.00.\n",
      "══════════════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the average attack for Fire-type Pokemon?\"\n",
    "\n",
    "print(f\"🎯 QUERY: {query}\\n\")\n",
    "answer = react_agent(query, max_steps=10)\n",
    "\n",
    "print(f\"\\n\\n{'═'*70}\")\n",
    "print(f\"🎉 FINAL ANSWER: {answer}\")\n",
    "print('═'*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 Let's Check the Correct Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Correct answer: 84.77\n",
      "❌ Agent's answer: 79.00\n"
     ]
    }
   ],
   "source": [
    "# ✅ Correct answer\n",
    "correct_answer = df[df['type_1'] == 'Fire'].attack.mean()\n",
    "print(f\"✅ Correct answer: {correct_answer:.2f}\")\n",
    "\n",
    "# ❌ What the agent gave us\n",
    "print(f\"❌ Agent's answer: 79.00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐛 What Went Wrong?\n",
    "\n",
    "The agent tries:\n",
    "\n",
    "1. **Step 1:** `show_info()` → Understands column names\n",
    "2. **Step 2:** `filter_rows(\"type_1 == 'Fire'\")` → Gets **string** \"Found 52 Pokemon\"\n",
    "3. **Step 3:** `calculate_statistics('attack', 'mean')` → But this uses the **global df**, not filtered data!\n",
    "\n",
    "> **Problem:** The `calculate_statistics` doesn't have access to the filtered data from Step 2!\n",
    "\n",
    "### 🤔 Why Our ReAct Agent Stalled\n",
    "\n",
    "Our current tools return plain **strings**, so a tool call loses the actual DataFrame:\n",
    "\n",
    "```python\n",
    "def filter_rows(condition: str):\n",
    "    result = df.query(condition)\n",
    "    return f\"Found {len(result)} Pokemon:\\n{result.to_string()}\"  # ❌ String only!\n",
    "```\n",
    "\n",
    "After Step 1 returns `\"Found 52 Pokémon...\"`, the agent has no way to pass that filtered DataFrame to Step 2.\n",
    "\n",
    "> **Solution needed:** Give the agent a way to pass around objects (not just strings) so later steps can reuse results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 Part 3: A Simple Solution\n",
    "\n",
    "**What if we tracked objects, assigned IDs to them, and let the agent pass handles (identifiers) to tool calls?**\n",
    "\n",
    "Let's give it a go!\n",
    "\n",
    "### 💡 The Idea\n",
    "\n",
    "Each tool will:\n",
    "\n",
    "1. **Return a friendly `message`** (string) for the LLM to read\n",
    "2. **Optionally attach an `artifact`** with metadata and a handle/id (e.g., `df_0`)\n",
    "3. **Accept `df_id`** (or similar) when it needs to reuse a previous result\n",
    "\n",
    "---\n",
    "\n",
    "### 🏗️ Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Any\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# ARTIFACT STORE\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "artifact_store: Dict[str, Any] = {}\n",
    "artifact_counter = 0\n",
    "\n",
    "def _save_artifact(obj: Any, kind: str = \"df\", metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Save an artifact and return its metadata.\"\"\"\n",
    "    global artifact_counter\n",
    "    handle = f\"{kind}_{artifact_counter}\"\n",
    "    artifact_counter += 1\n",
    "    artifact_store[handle] = obj\n",
    "    meta = metadata.copy() if metadata else {}\n",
    "    meta[\"type\"] = kind\n",
    "    meta[\"id\"] = handle\n",
    "    return meta\n",
    "\n",
    "def _get_artifact(handle: str) -> Any:\n",
    "    \"\"\"Retrieve an artifact by handle.\"\"\"\n",
    "    if handle not in artifact_store:\n",
    "        raise KeyError(f\"Unknown artifact handle: {handle}\")\n",
    "    return artifact_store[handle]\n",
    "\n",
    "def _resolve_df(df_id: Optional[str]):\n",
    "    \"\"\"Resolve a dataframe ID or use global df.\"\"\"\n",
    "    return _get_artifact(df_id) if df_id else df\n",
    "\n",
    "def _artifact_response(message: str, artifact_meta: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Create a tool response with optional artifact.\"\"\"\n",
    "    return {\"message\": message, \"artifact\": artifact_meta}\n",
    "\n",
    "def reset_artifacts():\n",
    "    \"\"\"Clear stored artifacts (helpful between demos).\"\"\"\n",
    "    global artifact_store, artifact_counter\n",
    "    artifact_store = {}\n",
    "    artifact_counter = 0\n",
    "    return \"Cleared artifact registry\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create v2 Tools with Artifact Support\n",
    "\n",
    "Now let's create tools that work with artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# TOOLS V2: WITH ARTIFACT SUPPORT\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "def load_csv_v2(filepath: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load CSV and return a dataframe handle + metadata.\"\"\"\n",
    "    global df\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.columns = (df.columns\n",
    "        .str.replace(' ', '_', regex=False)\n",
    "        .str.replace('.', '', regex=False)\n",
    "        .str.lower())\n",
    "    meta = _save_artifact(df, metadata={\n",
    "        \"rows\": int(df.shape[0]),\n",
    "        \"columns\": df.columns.tolist(),\n",
    "    })\n",
    "    message = f\"Loaded {filepath}: {df.shape[0]} rows, {df.shape[1]} columns\"\n",
    "    return _artifact_response(message, meta)\n",
    "\n",
    "def show_info_v2(df_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"ℹReturn column info; accept df_id from a previous tool.\"\"\"\n",
    "    target = _resolve_df(df_id)\n",
    "    import io\n",
    "    buffer = io.StringIO()\n",
    "    target.info(buf=buffer)\n",
    "    meta = None\n",
    "    if df_id:\n",
    "        meta = {\n",
    "            \"type\": \"dataframe\",\n",
    "            \"id\": df_id,\n",
    "            \"rows\": int(target.shape[0]),\n",
    "            \"columns\": target.columns.tolist(),\n",
    "        }\n",
    "    return _artifact_response(buffer.getvalue(), meta)\n",
    "\n",
    "def show_data_v2(n: int = 5, sort_by: Optional[str] = None, ascending: bool = True, df_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Preview rows and hand back a new dataframe handle.\"\"\"\n",
    "    target = _resolve_df(df_id)\n",
    "    working = target.sort_values(sort_by, ascending=ascending) if sort_by else target\n",
    "    preview = working.head(n)\n",
    "    meta = _save_artifact(preview, metadata={\n",
    "        \"rows\": int(preview.shape[0]),\n",
    "        \"columns\": preview.columns.tolist(),\n",
    "        \"source_df\": df_id or \"df_global\",\n",
    "    })\n",
    "    message = f\"Showing {n} rows\" + (f\" (sorted by {sort_by})\" if sort_by else \"\")\n",
    "    return _artifact_response(message, meta)\n",
    "\n",
    "def filter_rows_v2(condition: str, df_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"🔍 Filter rows using pandas query syntax. You may pass df_id to chain.\"\"\"\n",
    "    target = _resolve_df(df_id)\n",
    "    result = target.query(condition)\n",
    "    meta = _save_artifact(result, metadata={\n",
    "        \"rows\": int(result.shape[0]),\n",
    "        \"columns\": result.columns.tolist(),\n",
    "        \"source_df\": df_id or \"df_global\",\n",
    "        \"condition\": condition,\n",
    "    })\n",
    "    return _artifact_response(f\"Filtered to {len(result)} rows\", meta)\n",
    "\n",
    "def calculate_statistics_v2(column: str, stat_type: str, df_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Compute a statistic and store the numeric result as an artifact.\"\"\"\n",
    "    target = _resolve_df(df_id)\n",
    "    stat_functions = {\n",
    "        'mean': target[column].mean,\n",
    "        'median': target[column].median,\n",
    "        'max': target[column].max,\n",
    "        'min': target[column].min,\n",
    "        'sum': target[column].sum,\n",
    "        'count': target[column].count,\n",
    "        'std': target[column].std,\n",
    "    }\n",
    "    value = float(stat_functions[stat_type]())\n",
    "    meta = _save_artifact({\n",
    "        \"column\": column,\n",
    "        \"stat_type\": stat_type,\n",
    "        \"value\": value,\n",
    "        \"source_df\": df_id or \"df_global\",\n",
    "    }, kind=\"statistic\")\n",
    "    return _artifact_response(f\"{stat_type.capitalize()} of {column}: {value:.2f}\", meta)\n",
    "\n",
    "def aggregate_by_v2(group_by: str, agg_col: str, agg_func: str, df_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Group and aggregate, returning a new dataframe handle.\"\"\"\n",
    "    target = _resolve_df(df_id)\n",
    "    result = target.groupby(group_by)[agg_col].agg(agg_func).reset_index()\n",
    "    meta = _save_artifact(result, metadata={\n",
    "        \"rows\": int(result.shape[0]),\n",
    "        \"columns\": result.columns.tolist(),\n",
    "        \"source_df\": df_id or \"df_global\",\n",
    "        \"group_by\": group_by,\n",
    "        \"agg_col\": agg_col,\n",
    "        \"agg_func\": agg_func,\n",
    "    })\n",
    "    return _artifact_response(f\"{agg_func.capitalize()} of {agg_col} by {group_by}\", meta)\n",
    "\n",
    "def create_bar_chart_v2(category_col: str, value_col: Optional[str] = None, aggregation: str = 'count', title: Optional[str] = None, df_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Build a bar chart; return a figure handle.\"\"\"\n",
    "    target = _resolve_df(df_id)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if aggregation == 'count':\n",
    "        data = target[category_col].value_counts().sort_index()\n",
    "        ylabel = 'Count'\n",
    "    else:\n",
    "        agg_funcs = {'mean': 'mean', 'sum': 'sum', 'max': 'max', 'min': 'min', 'median': 'median'}\n",
    "        data = target.groupby(category_col)[value_col].agg(agg_funcs[aggregation])\n",
    "        ylabel = f'{aggregation.capitalize()} of {value_col}'\n",
    "    ax = data.plot(kind='bar')\n",
    "    plt.title(title or f'{ylabel} by {category_col}')\n",
    "    plt.xlabel(category_col)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    fig = ax.get_figure()\n",
    "    plt.show()\n",
    "    meta = _save_artifact(fig, kind=\"figure\", metadata={\n",
    "        \"title\": title or f'{ylabel} by {category_col}',\n",
    "        \"summary\": f'{aggregation} of {value_col or \"counts\"} by {category_col}',\n",
    "    })\n",
    "    return _artifact_response(\"Bar chart created\", meta)\n",
    "\n",
    "def create_scatter_plot_v2(x_col: str, y_col: str, color_by: Optional[str] = None, df_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Build a scatter plot; optional color_by groups.\"\"\"\n",
    "    target = _resolve_df(df_id)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if color_by and color_by in target.columns:\n",
    "        for category in target[color_by].unique():\n",
    "            mask = target[color_by] == category\n",
    "            plt.scatter(target[mask][x_col], target[mask][y_col], label=category, alpha=0.6)\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.scatter(target[x_col], target[y_col], alpha=0.6)\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.title(f'{y_col} vs {x_col}')\n",
    "    plt.tight_layout()\n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "    meta = _save_artifact(fig, kind=\"figure\", metadata={\n",
    "        \"x\": x_col,\n",
    "        \"y\": y_col,\n",
    "        \"color_by\": color_by,\n",
    "    })\n",
    "    return _artifact_response(f\"Scatter plot created: {y_col} vs {x_col}\", meta)\n",
    "\n",
    "def create_histogram_v2(column: str, bins: int = 20, df_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Plot a histogram and return the figure handle.\"\"\"\n",
    "    target = _resolve_df(df_id)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(target[column].dropna(), bins=bins, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.tight_layout()\n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "    meta = _save_artifact(fig, kind=\"figure\", metadata={\n",
    "        \"column\": column,\n",
    "        \"bins\": bins,\n",
    "    })\n",
    "    return _artifact_response(f\"Histogram created for {column}\", meta)\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# ALL TOOLS V2\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "all_tools_v2 = [\n",
    "    load_csv_v2, show_info_v2, show_data_v2,\n",
    "    filter_rows_v2, calculate_statistics_v2, aggregate_by_v2,\n",
    "    create_bar_chart_v2, create_scatter_plot_v2, create_histogram_v2,\n",
    "]\n",
    "\n",
    "tools_dict_v2 = {func.__name__: func for func in all_tools_v2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧪 Quick Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Loaded data/pokemon.csv: 800 rows, 13 columns\n",
      "🔍 Filtered to 52 rows\n",
      "📊 Mean of attack: 84.77\n"
     ]
    }
   ],
   "source": [
    "# Test: load data, filter, compute a stat with handles\n",
    "reset_artifacts()\n",
    "\n",
    "load_result = load_csv_v2(\"data/pokemon.csv\")\n",
    "print(f\"📂 {load_result['message']}\")\n",
    "\n",
    "fire_df_id = load_result[\"artifact\"][\"id\"]\n",
    "fire_result = filter_rows_v2(\"type_1 == 'Fire'\", df_id=fire_df_id)\n",
    "print(f\"🔍 {fire_result['message']}\")\n",
    "\n",
    "stat_result = calculate_statistics_v2(\"attack\", \"mean\", df_id=fire_result[\"artifact\"][\"id\"])\n",
    "print(f\"📊 {stat_result['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧪 Re-run the ReAct Agent with Tool v2\n",
    "\n",
    "Same question as before, but now the agent can pass `artifact['id']` between steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 QUERY: What is the average attack for Fire-type Pokemon?\n",
      "\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 1\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: I need to filter the dataset to include only Fire-type Pokemon and then calculate the average attack for that subset.\n",
      "\n",
      "⚙️  ACTION: filter_rows_v2(condition='type == \"Fire\"')\n",
      "\n",
      "⚙️  EXECUTING: filter_rows_v2(condition='type == \"Fire\"')\n",
      "\n",
      "❌ TOOL ERROR: name 'type' is not defined\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 2\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: I need to check the column names in the dataset to find the correct name for the type of Pokemon. This will help me filter the dataset correctly for Fire-type Pokemon.\n",
      "\n",
      "⚙️  ACTION: show_info_v2(df_id=None)\n",
      "\n",
      "⚙️  EXECUTING: show_info_v2(df_id=None)\n",
      "\n",
      "📊 TOOL RESULT:\n",
      "{'message': \"<class 'pandas.core.frame.DataFrame'>\\nRangeIndex: 800 entries, 0 to 799\\nData columns (total 13 columns):\\n #   Column      Non-Null Count  Dtype \\n---  ------      --------------  ----- \\n 0   #           800 non-null    int64 \\n 1   name        800 non-null    object\\n 2   type_1    ...\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 3\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: I have identified that the column for the primary type of Pokemon is 'type_1'. I will now filter the dataset to include only Fire-type Pokemon using this column and then calculate the average attack for that subset.\n",
      "\n",
      "⚙️  ACTION: filter_rows_v2(condition='type_1 == \"Fire\"')\n",
      "\n",
      "⚙️  EXECUTING: filter_rows_v2(condition='type_1 == \"Fire\"')\n",
      "\n",
      "📊 TOOL RESULT:\n",
      "{'message': 'Filtered to 52 rows', 'artifact': {'rows': 52, 'columns': ['#', 'name', 'type_1', 'type_2', 'total', 'hp', 'attack', 'defense', 'sp_atk', 'sp_def', 'speed', 'generation', 'legendary'], 'source_df': 'df_global', 'condition': 'type_1 == \"Fire\"', 'type': 'df', 'id': 'df_0'}}\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 4\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: Now that I have filtered the dataset to include only Fire-type Pokemon, I will calculate the average attack for this subset.\n",
      "\n",
      "⚙️  ACTION: calculate_statistics_v2(column='attack', stat_type='mean', df_id='df_0')\n",
      "\n",
      "⚙️  EXECUTING: calculate_statistics_v2(column='attack', stat_type='mean', df_id='df_0')\n",
      "\n",
      "📊 TOOL RESULT:\n",
      "{'message': 'Mean of attack: 84.77', 'artifact': {'type': 'statistic', 'id': 'statistic_1'}}\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🔄 STEP 5\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "💭 THOUGHT: I have successfully calculated the average attack for Fire-type Pokemon, which is 84.77. This is the final answer to the user's query.\n",
      "\n",
      "\n",
      "✅ AGENT FINISHED! Synthesizing answer from observations...\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "🎉 FINAL ANSWER: The average attack for Fire-type Pokémon is 84.77.\n",
      "══════════════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "source": [
    "reset_artifacts()\n",
    "\n",
    "query = \"What is the average attack for Fire-type Pokemon?\"\n",
    "print(f\"🎯 QUERY: {query}\\n\")\n",
    "answer = react_agent(query, max_steps=10, tools=all_tools_v2)\n",
    "\n",
    "print(\"\\n\" + \"═\"*70)\n",
    "print(f\"🎉 FINAL ANSWER: {answer}\")\n",
    "print(\"═\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎉 Success!\n",
    "\n",
    "Now the agent chains naturally:\n",
    "\n",
    "1. `filter_rows_v2` → narrows to Fire types (`df_0`)\n",
    "2. `calculate_statistics_v2` → uses `df_0` to get correct answer\n",
    "\n",
    "### 📊 What This Fix Solves\n",
    "\n",
    "| Feature | Before | After |\n",
    "|---------|--------|-------|\n",
    "| Pass data between steps | ❌ No | ✅ Yes |\n",
    "| Reuse intermediate results | ❌ Lost | ✅ Preserved |\n",
    "| Chain operations | ❌ Broken | ✅ Works |\n",
    "\n",
    "### ⚠️ Drawbacks\n",
    "\n",
    "- **No limits:** Store never expires entries (memory leak risk)\n",
    "- **Global scope:** Concurrent users would overwrite each other\n",
    "- **Learning curve:** Model must learn to use handles from prompt\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💻 Part 4: Building a CodeAgent\n",
    "\n",
    "### 🤔 How Would We Solve This by Hand?\n",
    "\n",
    "**Query:** `What is the average attack for Fire-type Pokemon?`\n",
    "\n",
    "Before asking the agent to chain even more tool calls, let's take a step back and consider how we'd answer ourselves:\n",
    "\n",
    "```python\n",
    "fire_pokemon = df[df['type_1'] == 'Fire']\n",
    "avg_attack = fire_pokemon.attack.mean()\n",
    "```\n",
    "\n",
    "Very simple pandas code! Much simpler than tracking handles.\n",
    "\n",
    "**💡 Actually, what if, instead of dealing with all the handles and keeping track of artifacts,  we let the agent write and execute this kind of code itself?**\n",
    "\n",
    "#### Approaches\n",
    "\n",
    "| Approach | How it works | Composition | Security |\n",
    "|----------|--------------|-------------|----------|\n",
    "| **Tool calls (strings)** | One tool per step, outputs are text | ❌ No | ✅ Very high |\n",
    "| **Tool calls + handles** | Tools return handles (`df_id`) | ✅ Yes | ✅ High |\n",
    "| **Code calling tools** | LLM writes Python with approved helpers | ✅ Yes | ⚠️ Medium |\n",
    "| **Arbitrary code** | LLM can run any Python | ✅ Maximum | ⚠️ Low |\n",
    "\n",
    "> We'll try building **Code calling tools** - a balance between flexibility and security.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Modify Tools to Return Data\n",
    "\n",
    "Tools that can return objects, not just strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# TOOLS V3: RETURN DATA + PRINT FEEDBACK\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "def filter_rows_v3(condition: str):\n",
    "    \"\"\"Filter dataframe rows using pandas query syntax.\"\"\"\n",
    "    result = df.query(condition)\n",
    "    print(f\"Filtered to {len(result)} rows\")  # 👈 LLM sees this when the generated code is executed\n",
    "    return result  # 👈 Code gets DataFrame!\n",
    "\n",
    "def aggregate_by_v3(data, group_by: str, agg_col: str, agg_func: str):\n",
    "    \"\"\"Group data and calculate aggregate statistics. Returns a Series.\"\"\"\n",
    "    result = data.groupby(group_by)[agg_col].agg(agg_func)\n",
    "    print(f\"Aggregated: {agg_func}({agg_col}) by {group_by}\")\n",
    "    return result\n",
    "\n",
    "def calculate_statistics_v3(data, column: str, stat_type: str):\n",
    "    \"\"\"Calculate statistics on a column.\"\"\"\n",
    "    stat_functions = {\n",
    "        'mean': data[column].mean,\n",
    "        'median': data[column].median,\n",
    "        'max': data[column].max,\n",
    "        'min': data[column].min,\n",
    "    }\n",
    "    result = stat_functions[stat_type]()\n",
    "    print(f\"{stat_type.capitalize()} of {column}: {result:.2f}\")\n",
    "    return result\n",
    "\n",
    "def show_info_v3():\n",
    "    \"\"\"ℹShow dataframe structure: columns, types, missing values.\"\"\"\n",
    "    print(df.info())\n",
    "    return df\n",
    "\n",
    "def show_data_v3(data, n: int = 5):\n",
    "    \"\"\"Show first n rows of dataframe.\"\"\"\n",
    "    print(f\"Showing {n} rows\")\n",
    "    return data.head(n)\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "# TOOLS DICTIONARY FOR CODE AGENT\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "\n",
    "code_agent_tools = {\n",
    "    'show_info_v3': show_info_v3,\n",
    "    'show_data_v3': show_data_v3,\n",
    "    'filter_rows_v3': filter_rows_v3,\n",
    "    'aggregate_by_v3': aggregate_by_v3,\n",
    "    'calculate_statistics_v3': calculate_statistics_v3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build a Safe Executor\n",
    "\n",
    "We'll build an execution environment where we can safely execute LLM-generated Python code:\n",
    "\n",
    "#### 🔒 Security Features\n",
    "\n",
    "- ✅ No imports allowed\n",
    "- ✅ Limited builtins (no `open`, `exec`, `eval`)\n",
    "- ✅ Print output capture\n",
    "- ✅ Only our tools and some standard Python libraries available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSafeExecutor:\n",
    "    \"\"\"\n",
    "    🔒 Simple safe Python executor inspired by SmolAgents.\n",
    "    \n",
    "    Security features:\n",
    "    - No imports allowed\n",
    "    - Limited builtins (no open, exec, eval)\n",
    "    - Print output capture\n",
    "    - Only our tools and some standard Python libraries available\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tools: Dict[str, Callable]):\n",
    "        self.tools = tools\n",
    "        \n",
    "        # Build safe builtins\n",
    "        self.safe_builtins = {\n",
    "            # ✅ Safe built-ins only\n",
    "            'len': len,\n",
    "            'range': range,\n",
    "            'enumerate': enumerate,\n",
    "            'zip': zip,\n",
    "            'list': list,\n",
    "            'dict': dict,\n",
    "            'str': str,\n",
    "            'int': int,\n",
    "            'float': float,\n",
    "            'print': print,\n",
    "            'min': min,\n",
    "            'max': max,\n",
    "            'sum': sum,\n",
    "            'sorted': sorted,\n",
    "            # ❌ Explicitly blocked: open, exec, eval, compile, __import__\n",
    "        }\n",
    "    \n",
    "    def execute(self, code: str, df) -> tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Execute code safely and return (success, output).\n",
    "        \n",
    "        Args:\n",
    "            code: Python code to execute\n",
    "            df: DataFrame to provide\n",
    "            \n",
    "        Returns:\n",
    "            (success: bool, output: str)\n",
    "        \"\"\"\n",
    "        # Capture print output (SmolAgents pattern)\n",
    "        output_buffer = StringIO()\n",
    "        original_stdout = sys.stdout\n",
    "        \n",
    "        try:\n",
    "            # Redirect stdout to capture prints\n",
    "            sys.stdout = output_buffer\n",
    "            \n",
    "            # Build safe execution environment\n",
    "            safe_globals = {\n",
    "                '__builtins__': self.safe_builtins,\n",
    "                'df': df,\n",
    "                **self.tools,\n",
    "            }\n",
    "            \n",
    "            # Execute code\n",
    "            exec(code, safe_globals, {})\n",
    "            \n",
    "            # Get captured output\n",
    "            output = output_buffer.getvalue()\n",
    "            return True, output if output else \"✅ Executed successfully\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_output = output_buffer.getvalue()\n",
    "            return False, (error_output + f\"❌ Error: {type(e).__name__}: {str(e)}\")\n",
    "            \n",
    "        finally:\n",
    "            # Restore stdout\n",
    "            sys.stdout = original_stdout\n",
    "            output_buffer.close()\n",
    "\n",
    "# Create executor\n",
    "executor = SimpleSafeExecutor(code_agent_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Test the Executor\n",
    "\n",
    "Let's verify what's safe and what's blocked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test 1: Safe operations (should work)\n",
      "Result: ✅ Success\n",
      "Output: Filtered to 52 rows\n",
      "Got 52 Fire Pokemon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Safe operations\n",
    "print(\"\\n✅ Test 1: Safe operations (should work)\")\n",
    "code = \"\"\"\n",
    "fire = filter_rows_v3(\"type_1 == 'Fire'\")\n",
    "print(f\"Got {len(fire)} Fire Pokemon\")\n",
    "\"\"\"\n",
    "success, output = executor.execute(code, df)\n",
    "print(f\"Result: {'✅ Success' if success else '❌ Failed'}\")\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ Test 2: Try to import (should be blocked)\n",
      "Result: ✅ Blocked (GOOD!)\n",
      "Output: ❌ Error: ImportError: __import__ not found\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Blocked import\n",
    "print(\"\\n❌ Test 2: Try to import (should be blocked)\")\n",
    "code = \"\"\"\n",
    "import os\n",
    "os.system('ls')\n",
    "\"\"\"\n",
    "success, output = executor.execute(code, df)\n",
    "print(f\"Result: {'❌ Passed (BAD!)' if success else '✅ Blocked (GOOD!)'}\")\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ Test 3: Try to open file (should be blocked)\n",
      "Result: ✅ Blocked (GOOD!)\n",
      "Output: ❌ Error: NameError: name 'open' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Blocked file access\n",
    "print(\"\\n❌ Test 3: Try to open file (should be blocked)\")\n",
    "code = \"\"\"\n",
    "data = open('/etc/passwd').read()\n",
    "\"\"\"\n",
    "success, output = executor.execute(code, df)\n",
    "print(f\"Result: {'❌ Passed (BAD!)' if success else '✅ Blocked (GOOD!)'}\")\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test 4: Chaining operations (should work)\n",
      "Result: ✅ Success\n",
      "Output: Filtered to 52 rows\n",
      "Mean of attack: 84.77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test 4: Chaining operations\n",
    "print(\"\\n✅ Test 4: Chaining operations (should work)\")\n",
    "code = \"\"\"\n",
    "fire = filter_rows_v3(\"type_1 == 'Fire'\")\n",
    "avg_attack = calculate_statistics_v3(fire, 'attack', 'mean')\n",
    "\"\"\"\n",
    "success, output = executor.execute(code, df)\n",
    "print(f\"Result: {'✅ Success' if success else '❌ Failed'}\")\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎉 Key Observations\n",
    "\n",
    "| Feature | Status |\n",
    "|---------|--------|\n",
    "| Our tools work | ✅ Yes |\n",
    "| Variables work | ✅ Yes |\n",
    "| Chaining works | ✅ Yes |\n",
    "| Imports blocked | ✅ Yes |\n",
    "| File access blocked | ✅ Yes |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Build the CodeAgent\n",
    "\n",
    "First, define a structured output model for generated code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeResponse(BaseModel):\n",
    "    \"\"\"📋 Structured response for generated Python code\"\"\"\n",
    "    code: str  # Pure Python code as string\n",
    "\n",
    "\n",
    "def generate_code_tool_descriptions(tools: Dict[str, Callable]) -> str:\n",
    "    \"\"\"📚 Generate tool descriptions for CodeAgent.\"\"\"\n",
    "    descriptions = []\n",
    "    for name, func in tools.items():\n",
    "        doc = (func.__doc__ or \"No description\").strip()\n",
    "        sig = inspect.signature(func)\n",
    "        params = str(sig)\n",
    "        descriptions.append(f\"{name}{params}\\n    {doc}\")\n",
    "    return \"\\n\\n\".join(descriptions)\n",
    "\n",
    "\n",
    "def code_agent(query: str, max_attempts: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    🤖 Agent that generates Python code calling our tools (using structured outputs).\n",
    "    \n",
    "    Args:\n",
    "        query: User's question\n",
    "        max_attempts: Maximum retry attempts on errors\n",
    "        \n",
    "    Returns:\n",
    "        Execution output or error message\n",
    "    \"\"\"\n",
    "    \n",
    "    error_context = \"\"\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        # Build prompt\n",
    "        prompt = f\"\"\"You are a Python coding agent that writes code to answer data questions.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Available tools (all return data, use print for feedback):\n",
    "{generate_code_tool_descriptions(code_agent_tools)}\n",
    "\n",
    "Global variables:\n",
    "- df: Pokemon dataset (pandas DataFrame)\n",
    "\n",
    "Instructions:\n",
    "1. Inspect the data structure first (use show_info_v3 or show_data_v3) so you know column names.\n",
    "2. Write Python code using ONLY the provided tools and safe builtins.\n",
    "3. Store intermediate results in variables and reuse them.\n",
    "4. Chain operations logically to answer the query end-to-end.\n",
    "5. Use print() to show intermediate steps or debugging info.\n",
    "6. Do NOT import anything or call pandas methods directly on df.\n",
    "7. Finish with a concise summary that starts with \"FINAL ANSWER:\" describing the result.\n",
    "\n",
    "{error_context}\n",
    "\n",
    "You will respond with pure executable Python code (no markdown formatting, no explanations).\n",
    "The code will be directly executed.\"\"\"\n",
    "        \n",
    "        # Get code from LLM with structured output\n",
    "        response = generate(prompt, temperature=0.1, response_format=CodeResponse)\n",
    "        code = response.code.strip()\n",
    "        \n",
    "        print(f\"\\n{'═'*70}\")\n",
    "        print(f\"📝 GENERATED CODE (Attempt {attempt + 1}):\")\n",
    "        print('═'*70)\n",
    "        print(code)\n",
    "        print('═'*70)\n",
    "        \n",
    "        # Execute safely\n",
    "        success, output = executor.execute(code, df)\n",
    "        \n",
    "        print(f\"\\n📊 EXECUTION RESULT:\")\n",
    "        print(output)\n",
    "        \n",
    "        if success:\n",
    "            return output\n",
    "        else:\n",
    "            # Retry with error context\n",
    "            error_context = f\"\\n\\nPrevious attempt failed with error:\\n{output}\\nPlease fix the code.\"\n",
    "    \n",
    "    return f\"Failed after {max_attempts} attempts\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test the CodeAgent\n",
    "\n",
    "Let's try the query that had issues with ReAct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 QUERY: What is the average attack for Fire-type Pokemon?\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "📝 GENERATED CODE (Attempt 1):\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "show_info_v3()\n",
      "\n",
      "# After inspecting the data structure, we will filter for Fire-type Pokemon.\n",
      "fire_pokemon = filter_rows_v3(\"type == 'Fire'\")\n",
      "\n",
      "# Now we will calculate the average attack for these Fire-type Pokemon.\n",
      "average_attack = calculate_statistics_v3(fire_pokemon, 'attack', 'mean')\n",
      "\n",
      "# Finally, we will print the average attack.\n",
      "print(average_attack)\n",
      "\n",
      "# Summary of the result.\n",
      "print(f'FINAL ANSWER: The average attack for Fire-type Pokemon is {average_attack}.')\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📊 EXECUTION RESULT:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           800 non-null    int64 \n",
      " 1   name        800 non-null    object\n",
      " 2   type_1      800 non-null    object\n",
      " 3   type_2      414 non-null    object\n",
      " 4   total       800 non-null    int64 \n",
      " 5   hp          800 non-null    int64 \n",
      " 6   attack      800 non-null    int64 \n",
      " 7   defense     800 non-null    int64 \n",
      " 8   sp_atk      800 non-null    int64 \n",
      " 9   sp_def      800 non-null    int64 \n",
      " 10  speed       800 non-null    int64 \n",
      " 11  generation  800 non-null    int64 \n",
      " 12  legendary   800 non-null    bool  \n",
      "dtypes: bool(1), int64(9), object(3)\n",
      "memory usage: 75.9+ KB\n",
      "None\n",
      "❌ Error: UndefinedVariableError: name 'type' is not defined\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "📝 GENERATED CODE (Attempt 2):\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "# Step 1: Filter for Fire-type Pokemon\n",
      "fire_pokemon = filter_rows_v3(\"type_1 == 'Fire'\")\n",
      "print(f'Filtered Fire-type Pokemon: {fire_pokemon.shape[0]} entries')\n",
      "\n",
      "# Step 2: Calculate the average attack for Fire-type Pokemon\n",
      "average_attack = calculate_statistics_v3(fire_pokemon, 'attack', 'mean')\n",
      "print(f'Average attack for Fire-type Pokemon: {average_attack}')\n",
      "\n",
      "# Final summary\n",
      "print(f'FINAL ANSWER: The average attack for Fire-type Pokemon is {average_attack}.')\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📊 EXECUTION RESULT:\n",
      "Filtered to 52 rows\n",
      "Filtered Fire-type Pokemon: 52 entries\n",
      "Mean of attack: 84.77\n",
      "Average attack for Fire-type Pokemon: 84.76923076923077\n",
      "FINAL ANSWER: The average attack for Fire-type Pokemon is 84.76923076923077.\n",
      "\n",
      "\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "✅ SUCCESS!\n",
      "══════════════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the average attack for Fire-type Pokemon?\"\n",
    "\n",
    "print(f\"🎯 QUERY: {query}\")\n",
    "result = code_agent(query, max_attempts=10)\n",
    "\n",
    "print(f\"\\n\\n{'═'*70}\")\n",
    "print(f\"✅ SUCCESS!\")\n",
    "print('═'*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎉 What Happened?\n",
    "\n",
    "The CodeAgent generated Python code like:\n",
    "```python\n",
    "fire_pokemon = filter_rows_v3(\"type_1 == 'Fire'\")\n",
    "avg_attack = calculate_statistics_v3(fire_pokemon, 'attack', 'mean')\n",
    "```\n",
    "\n",
    "### 💡 Why Structured Outputs?\n",
    "\n",
    "- ✅ **No markdown parsing**: LLM returns pure Python code in `response.code`\n",
    "- ✅ **Reliability**: Guaranteed JSON format\n",
    "- ✅ **Type safety**: Pydantic validates the response structure\n",
    "- ✅ **Clean control flow**: Boolean flags instead of string checking\n",
    "- ✅ **Error handling**: Invalid formats caught before execution\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Test More Complex Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 QUERY: Show me the top 3 Pokemon types by average speed\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "📝 GENERATED CODE (Attempt 1):\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "show_info_v3()\n",
      "\n",
      "# Assuming the relevant columns are 'Type' and 'Speed', we will proceed to calculate the average speed by type.\n",
      "\n",
      "# Step 1: Group by 'Type' and calculate average speed\n",
      "average_speed_by_type = aggregate_by_v3(df, 'Type', 'Speed', 'mean')\n",
      "\n",
      "# Step 2: Sort the average speeds in descending order and get the top 3 types\n",
      "sorted_average_speed = average_speed_by_type.sort_values(ascending=False)\n",
      "\n",
      "# Step 3: Get the top 3 types\n",
      "top_3_types = sorted_average_speed.head(3)\n",
      "\n",
      "# Print the intermediate results for debugging\n",
      "print(\"Average speed by type:\", average_speed_by_type)\n",
      "print(\"Sorted average speed:\", sorted_average_speed)\n",
      "print(\"Top 3 types by average speed:\", top_3_types)\n",
      "\n",
      "# Final summary\n",
      "print(\"FINAL ANSWER: The top 3 Pokemon types by average speed are:\", top_3_types)\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📊 EXECUTION RESULT:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           800 non-null    int64 \n",
      " 1   name        800 non-null    object\n",
      " 2   type_1      800 non-null    object\n",
      " 3   type_2      414 non-null    object\n",
      " 4   total       800 non-null    int64 \n",
      " 5   hp          800 non-null    int64 \n",
      " 6   attack      800 non-null    int64 \n",
      " 7   defense     800 non-null    int64 \n",
      " 8   sp_atk      800 non-null    int64 \n",
      " 9   sp_def      800 non-null    int64 \n",
      " 10  speed       800 non-null    int64 \n",
      " 11  generation  800 non-null    int64 \n",
      " 12  legendary   800 non-null    bool  \n",
      "dtypes: bool(1), int64(9), object(3)\n",
      "memory usage: 75.9+ KB\n",
      "None\n",
      "❌ Error: KeyError: 'Type'\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "📝 GENERATED CODE (Attempt 2):\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "# Step 1: Inspect the data structure to understand the columns\n",
      "show_info_v3()\n",
      "\n",
      "# Step 2: Group by type_1 and calculate the average speed\n",
      "avg_speed_by_type = aggregate_by_v3(df, 'type_1', 'speed', 'mean')\n",
      "\n",
      "# Step 3: Sort the average speeds in descending order and get the top 3 types\n",
      "sorted_avg_speed = avg_speed_by_type.sort_values(ascending=False)\n",
      "\n",
      "# Step 4: Get the top 3 types\n",
      "top_3_types = sorted_avg_speed.head(3)\n",
      "\n",
      "# Step 5: Print the intermediate results for debugging\n",
      "print(\"Average speed by type:\", avg_speed_by_type)\n",
      "print(\"Sorted average speed:\", sorted_avg_speed)\n",
      "print(\"Top 3 types by average speed:\", top_3_types)\n",
      "\n",
      "# Final summary\n",
      "print(\"FINAL ANSWER:\", top_3_types)\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📊 EXECUTION RESULT:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           800 non-null    int64 \n",
      " 1   name        800 non-null    object\n",
      " 2   type_1      800 non-null    object\n",
      " 3   type_2      414 non-null    object\n",
      " 4   total       800 non-null    int64 \n",
      " 5   hp          800 non-null    int64 \n",
      " 6   attack      800 non-null    int64 \n",
      " 7   defense     800 non-null    int64 \n",
      " 8   sp_atk      800 non-null    int64 \n",
      " 9   sp_def      800 non-null    int64 \n",
      " 10  speed       800 non-null    int64 \n",
      " 11  generation  800 non-null    int64 \n",
      " 12  legendary   800 non-null    bool  \n",
      "dtypes: bool(1), int64(9), object(3)\n",
      "memory usage: 75.9+ KB\n",
      "None\n",
      "Aggregated: mean(speed) by type_1\n",
      "Average speed by type: type_1\n",
      "Bug          61.681159\n",
      "Dark         76.161290\n",
      "Dragon       83.031250\n",
      "Electric     84.500000\n",
      "Fairy        48.588235\n",
      "Fighting     66.074074\n",
      "Fire         74.442308\n",
      "Flying      102.500000\n",
      "Ghost        64.343750\n",
      "Grass        61.928571\n",
      "Ground       63.906250\n",
      "Ice          63.458333\n",
      "Normal       71.551020\n",
      "Poison       63.571429\n",
      "Psychic      81.491228\n",
      "Rock         55.909091\n",
      "Steel        55.259259\n",
      "Water        65.964286\n",
      "Name: speed, dtype: float64\n",
      "Sorted average speed: type_1\n",
      "Flying      102.500000\n",
      "Electric     84.500000\n",
      "Dragon       83.031250\n",
      "Psychic      81.491228\n",
      "Dark         76.161290\n",
      "Fire         74.442308\n",
      "Normal       71.551020\n",
      "Fighting     66.074074\n",
      "Water        65.964286\n",
      "Ghost        64.343750\n",
      "Ground       63.906250\n",
      "Poison       63.571429\n",
      "Ice          63.458333\n",
      "Grass        61.928571\n",
      "Bug          61.681159\n",
      "Rock         55.909091\n",
      "Steel        55.259259\n",
      "Fairy        48.588235\n",
      "Name: speed, dtype: float64\n",
      "Top 3 types by average speed: type_1\n",
      "Flying      102.50000\n",
      "Electric     84.50000\n",
      "Dragon       83.03125\n",
      "Name: speed, dtype: float64\n",
      "FINAL ANSWER: type_1\n",
      "Flying      102.50000\n",
      "Electric     84.50000\n",
      "Dragon       83.03125\n",
      "Name: speed, dtype: float64\n",
      "\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Multi-step analysis\n",
    "query = \"Show me the top 3 Pokemon types by average speed\"\n",
    "print(f\"\\n🎯 QUERY: {query}\")\n",
    "result = code_agent(query, max_attempts=10)\n",
    "print(\"\\n\" + \"═\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 QUERY: What's the highest defense stat among legendary Pokemon?\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "📝 GENERATED CODE (Attempt 1):\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "show_info_v3()\n",
      "\n",
      "# Filter for legendary Pokemon\n",
      "legendary_condition = \"is_legendary == True\"\n",
      "filtered_legendary = filter_rows_v3(legendary_condition)\n",
      "\n",
      "# Calculate the maximum defense stat among legendary Pokemon\n",
      "max_defense = calculate_statistics_v3(filtered_legendary, 'defense', 'max')\n",
      "\n",
      "print(f'Highest defense stat among legendary Pokemon: {max_defense}')\n",
      "\n",
      "# Final summary\n",
      "print(f'FINAL ANSWER: The highest defense stat among legendary Pokemon is {max_defense}.')\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📊 EXECUTION RESULT:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           800 non-null    int64 \n",
      " 1   name        800 non-null    object\n",
      " 2   type_1      800 non-null    object\n",
      " 3   type_2      414 non-null    object\n",
      " 4   total       800 non-null    int64 \n",
      " 5   hp          800 non-null    int64 \n",
      " 6   attack      800 non-null    int64 \n",
      " 7   defense     800 non-null    int64 \n",
      " 8   sp_atk      800 non-null    int64 \n",
      " 9   sp_def      800 non-null    int64 \n",
      " 10  speed       800 non-null    int64 \n",
      " 11  generation  800 non-null    int64 \n",
      " 12  legendary   800 non-null    bool  \n",
      "dtypes: bool(1), int64(9), object(3)\n",
      "memory usage: 75.9+ KB\n",
      "None\n",
      "❌ Error: UndefinedVariableError: name 'is_legendary' is not defined\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "📝 GENERATED CODE (Attempt 2):\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "# Step 1: Filter the rows to get only legendary Pokemon\n",
      "legendary_pokemon = filter_rows_v3('legendary == True')\n",
      "print(legendary_pokemon)\n",
      "\n",
      "# Step 2: Aggregate to find the maximum defense stat among legendary Pokemon\n",
      "highest_defense = aggregate_by_v3(legendary_pokemon, group_by='name', agg_col='defense', agg_func='max')\n",
      "print(highest_defense)\n",
      "\n",
      "# Step 3: Get the maximum value from the aggregated results\n",
      "max_defense_value = highest_defense.max()\n",
      "print(max_defense_value)\n",
      "\n",
      "# Final output\n",
      "FINAL ANSWER: The highest defense stat among legendary Pokemon is {max_defense_value}.\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📊 EXECUTION RESULT:\n",
      "❌ Error: SyntaxError: invalid syntax (<string>, line 14)\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "📝 GENERATED CODE (Attempt 3):\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "# Step 1: Show the structure of the dataframe to understand its columns\n",
      "show_info_v3()\n",
      "\n",
      "# Step 2: Filter the rows to get only legendary Pokemon\n",
      "legendary_condition = 'is_legendary == True'\n",
      "filtered_legendary = filter_rows_v3(legendary_condition)\n",
      "\n",
      "# Step 3: Calculate the maximum defense stat among the legendary Pokemon\n",
      "max_defense = calculate_statistics_v3(filtered_legendary, 'defense', 'max')\n",
      "\n",
      "# Step 4: Print the maximum defense value\n",
      "print(max_defense)\n",
      "\n",
      "# Final summary\n",
      "print(f'FINAL ANSWER: The highest defense stat among legendary Pokemon is {max_defense}.')\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📊 EXECUTION RESULT:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           800 non-null    int64 \n",
      " 1   name        800 non-null    object\n",
      " 2   type_1      800 non-null    object\n",
      " 3   type_2      414 non-null    object\n",
      " 4   total       800 non-null    int64 \n",
      " 5   hp          800 non-null    int64 \n",
      " 6   attack      800 non-null    int64 \n",
      " 7   defense     800 non-null    int64 \n",
      " 8   sp_atk      800 non-null    int64 \n",
      " 9   sp_def      800 non-null    int64 \n",
      " 10  speed       800 non-null    int64 \n",
      " 11  generation  800 non-null    int64 \n",
      " 12  legendary   800 non-null    bool  \n",
      "dtypes: bool(1), int64(9), object(3)\n",
      "memory usage: 75.9+ KB\n",
      "None\n",
      "❌ Error: UndefinedVariableError: name 'is_legendary' is not defined\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "📝 GENERATED CODE (Attempt 4):\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "# Step 1: Filter the rows to get only legendary Pokémon\n",
      "legendary_pokemon = filter_rows_v3('legendary == True')\n",
      "print(legendary_pokemon)\n",
      "\n",
      "# Step 2: Aggregate to find the maximum defense stat among legendary Pokémon\n",
      "highest_defense = aggregate_by_v3(legendary_pokemon, 'name', 'defense', 'max')\n",
      "print(highest_defense)\n",
      "\n",
      "# Step 3: Get the maximum defense value\n",
      "max_defense_value = highest_defense.max()\n",
      "print(max_defense_value)\n",
      "\n",
      "# Final summary\n",
      "FINAL ANSWER: The highest defense stat among legendary Pokémon is {max_defense_value}.\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📊 EXECUTION RESULT:\n",
      "❌ Error: SyntaxError: invalid syntax (<string>, line 14)\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "📝 GENERATED CODE (Attempt 5):\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "# Step 1: Show the structure of the dataframe to understand its columns\n",
      "show_info_v3()\n",
      "\n",
      "# Step 2: Filter the rows to get only legendary Pokemon\n",
      "legendary_condition = \"is_legendary == True\"\n",
      "filtered_legendary = filter_rows_v3(legendary_condition)\n",
      "\n",
      "# Step 3: Aggregate to find the maximum defense stat among legendary Pokemon\n",
      "max_defense = aggregate_by_v3(filtered_legendary, 'name', 'defense', 'max')\n",
      "\n",
      "# Step 4: Print the maximum defense value\n",
      "print(max_defense)\n",
      "\n",
      "# Final summary\n",
      "print(f'FINAL ANSWER: The highest defense stat among legendary Pokemon is {max_defense.max()}')\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📊 EXECUTION RESULT:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           800 non-null    int64 \n",
      " 1   name        800 non-null    object\n",
      " 2   type_1      800 non-null    object\n",
      " 3   type_2      414 non-null    object\n",
      " 4   total       800 non-null    int64 \n",
      " 5   hp          800 non-null    int64 \n",
      " 6   attack      800 non-null    int64 \n",
      " 7   defense     800 non-null    int64 \n",
      " 8   sp_atk      800 non-null    int64 \n",
      " 9   sp_def      800 non-null    int64 \n",
      " 10  speed       800 non-null    int64 \n",
      " 11  generation  800 non-null    int64 \n",
      " 12  legendary   800 non-null    bool  \n",
      "dtypes: bool(1), int64(9), object(3)\n",
      "memory usage: 75.9+ KB\n",
      "None\n",
      "❌ Error: UndefinedVariableError: name 'is_legendary' is not defined\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "📝 GENERATED CODE (Attempt 6):\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "# Step 1: Filter the rows to get only legendary Pokémon\n",
      "legendary_pokemon = filter_rows_v3('legendary == True')\n",
      "print(legendary_pokemon)\n",
      "\n",
      "# Step 2: Aggregate to find the maximum defense stat among legendary Pokémon\n",
      "highest_defense = aggregate_by_v3(legendary_pokemon, 'name', 'defense', 'max')\n",
      "print(highest_defense)\n",
      "\n",
      "# Step 3: Get the maximum defense value\n",
      "max_defense_value = highest_defense.max()\n",
      "print(max_defense_value)\n",
      "\n",
      "# Final summary\n",
      "print(f'FINAL ANSWER: The highest defense stat among legendary Pokémon is {max_defense_value}.')\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📊 EXECUTION RESULT:\n",
      "Filtered to 65 rows\n",
      "       #                 name    type_1    type_2  total   hp  attack  \\\n",
      "156  144             Articuno       Ice    Flying    580   90      85   \n",
      "157  145               Zapdos  Electric    Flying    580   90      90   \n",
      "158  146              Moltres      Fire    Flying    580   90     100   \n",
      "162  150               Mewtwo   Psychic       NaN    680  106     110   \n",
      "163  150  MewtwoMega Mewtwo X   Psychic  Fighting    780  106     190   \n",
      "..   ...                  ...       ...       ...    ...  ...     ...   \n",
      "795  719              Diancie      Rock     Fairy    600   50     100   \n",
      "796  719  DiancieMega Diancie      Rock     Fairy    700   50     160   \n",
      "797  720  HoopaHoopa Confined   Psychic     Ghost    600   80     110   \n",
      "798  720   HoopaHoopa Unbound   Psychic      Dark    680   80     160   \n",
      "799  721            Volcanion      Fire     Water    600   80     110   \n",
      "\n",
      "     defense  sp_atk  sp_def  speed  generation  legendary  \n",
      "156      100      95     125     85           1       True  \n",
      "157       85     125      90    100           1       True  \n",
      "158       90     125      85     90           1       True  \n",
      "162       90     154      90    130           1       True  \n",
      "163      100     154     100    130           1       True  \n",
      "..       ...     ...     ...    ...         ...        ...  \n",
      "795      150     100     150     50           6       True  \n",
      "796      110     160     110    110           6       True  \n",
      "797       60     150     130     70           6       True  \n",
      "798       60     170     130     80           6       True  \n",
      "799      120     130      90     70           6       True  \n",
      "\n",
      "[65 rows x 13 columns]\n",
      "Aggregated: max(defense) by name\n",
      "name\n",
      "Arceus              120\n",
      "Articuno            100\n",
      "Azelf                70\n",
      "Cobalion            129\n",
      "Darkrai              90\n",
      "                   ... \n",
      "Xerneas              95\n",
      "Yveltal              95\n",
      "Zapdos               85\n",
      "Zekrom              120\n",
      "Zygarde50% Forme    121\n",
      "Name: defense, Length: 65, dtype: int64\n",
      "200\n",
      "FINAL ANSWER: The highest defense stat among legendary Pokémon is 200.\n",
      "\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Filter and calculate\n",
    "query = \"What's the highest defense stat among legendary Pokemon?\"\n",
    "print(f\"\\n🎯 QUERY: {query}\")\n",
    "result = code_agent(query, max_attempts=10)\n",
    "print(\"\\n\" + \"═\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🔒 Part 5: Security Analysis\n",
    "\n",
    "Let's understand what makes our CodeAgent safe (and what doesn't).\n",
    "\n",
    "### ✅ What's Blocked\n",
    "\n",
    "Our `SimpleSafeExecutor` blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔒 Security Tests\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "🧪 Test: Import os\n",
      "  ✅ BLOCKED (GOOD!)\n",
      "  Error: __import__ not found\n",
      "\n",
      "🧪 Test: Open file\n",
      "  ✅ BLOCKED (GOOD!)\n",
      "  Error: name 'open' is not defined\n",
      "\n",
      "🧪 Test: Use exec\n",
      "  ✅ BLOCKED (GOOD!)\n",
      "  Error: name 'exec' is not defined\n",
      "\n",
      "🧪 Test: Use eval\n",
      "  ✅ BLOCKED (GOOD!)\n",
      "  Error: name 'eval' is not defined\n",
      "\n",
      "🧪 Test: Use __import__\n",
      "  ✅ BLOCKED (GOOD!)\n",
      "  Error: name '__import__' is not defined\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "source": [
    "print(\"🔒 Security Tests\\n\")\n",
    "print(\"═\" * 70)\n",
    "\n",
    "tests = [\n",
    "    (\"Import os\", \"import os\\nos.system('ls')\"),\n",
    "    (\"Open file\", \"open('/etc/passwd').read()\"),\n",
    "    (\"Use exec\", \"exec('print(123)')\"),\n",
    "    (\"Use eval\", \"eval('1+1')\"),\n",
    "    (\"Use __import__\", \"__import__('os').system('ls')\"),\n",
    "]\n",
    "\n",
    "for name, code in tests:\n",
    "    print(f\"\\n🧪 Test: {name}\")\n",
    "    success, output = executor.execute(code, df)\n",
    "    status = \"❌ PASSED (BAD!)\" if success else \"✅ BLOCKED (GOOD!)\"\n",
    "    print(f\"  {status}\")\n",
    "    if not success:\n",
    "        print(f\"  Error: {output.split(':')[-1].strip()}\")\n",
    "\n",
    "print(\"\\n\" + \"═\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️ What's Still Risky\n",
    "\n",
    "However, DataFrame methods are still accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Direct pandas access works: True\n",
      "📊 Output: Filtered using pandas directly: 52 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code = \"\"\"\n",
    "# Agent could still use pandas methods on df:\n",
    "result = df[df['type_1'] == 'Fire']\n",
    "print(f\"Filtered using pandas directly: {len(result)} rows\")\n",
    "\"\"\"\n",
    "\n",
    "success, output = executor.execute(code, df)\n",
    "print(f\"⚠️  Direct pandas access works: {success}\")\n",
    "print(f\"📊 Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚨 Security Risk\n",
    "\n",
    "**The problem:** We expose a pandas DataFrame (`df`) in the execution environment, which includes methods that can perform dangerous operations:\n",
    "\n",
    "- `.to_csv()`, `.to_sql()`, `.to_pickle()` – write files to disk\n",
    "- `.to_clipboard()` – access system clipboard\n",
    "- SQL methods – execute arbitrary database queries\n",
    "\n",
    "### 🛡️ Potential Solutions\n",
    "\n",
    "For secure code execution, consider some of these options:\n",
    "\n",
    "#### 📦 Sandboxed Execution Environments\n",
    "\n",
    "- **[E2B](https://github.com/e2b-dev/E2B)** – Docker-based code sandboxes with resource limits\n",
    "- **[Firecracker](https://firecracker-microvm.github.io/)** – Lightweight VMs for isolation\n",
    "- **[gVisor](https://gvisor.dev/)** – Container sandbox with good isolation\n",
    "\n",
    "#### 🐳 Container-Based Isolation\n",
    "\n",
    "- Docker with restricted volumes and network policies\n",
    "- Podman for rootless containers\n",
    "\n",
    "#### ☁️ Cloud Sandboxes\n",
    "\n",
    "- AWS Lambda (isolated serverless execution)\n",
    "- Google Cloud Run (containerized execution)\n",
    "- Azure Container Instances\n",
    "\n",
    "#### 🐍 Python-Specific Sandboxes\n",
    "\n",
    "- **[RestrictedPython](https://github.com/zopefoundation/RestrictedPython)** – Restricted Python execution\n",
    "- **[PyPy sandbox](https://doc.pypy.org/en/latest/sandbox.html)** – Isolated Python interpreter\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 Part 6: Comparison and Takeaways\n",
    "\n",
    "### 📊 ReAct vs CodeAgent\n",
    "\n",
    "| Feature | ReAct (JSON + Handles) | CodeAgent |\n",
    "|---------|----------------------|------------|\n",
    "| **Multi-step reasoning** | ✅ Yes | ✅ Yes |\n",
    "| **Composition** | ✅ Pass artifact handles | ✅ Native variables |\n",
    "| **Variables** | Handles (IDs) | Python variables |\n",
    "| **Intermediate results** | ✅ Preserved via store | ✅ Preserved |\n",
    "| **Structured outputs** | ✅ JSON (thought + action) | ✅ JSON (code) |\n",
    "| **Answer synthesis** | ✅ Auto-synthesize | ✅ Print statements |\n",
    "| **Security** | ✅ Simple (tool calls) | ⚠️ Needs sandbox |\n",
    "| **Flexibility** | ⚠️ Limited to tools | ✅ High |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 What We Built Today\n",
    "\n",
    "1. ✅ **ReAct Agent** – Multi-step reasoning with structured outputs + answer synthesis\n",
    "2. ✅ **Discovered limitation** – Tools can't pass state between steps\n",
    "3. ✅ **Artifact Store** – Simple solution for tracking intermediate results\n",
    "4. ✅ **CodeAgent** – Generates Python code with structured outputs\n",
    "5. ✅ **SimpleSafeExecutor** – Safe execution environment inspired by SmolAgents\n",
    "6. ✅ **Security awareness** – Understanding constraints and production solutions\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 Key Insights\n",
    "\n",
    "#### Why Structured Outputs?\n",
    "\n",
    "- ✅ No string parsing\n",
    "- ✅ Type safety with Pydantic models\n",
    "- ✅ Cleaner code (no regex or split logic)\n",
    "- ✅ Boolean flags for control flow\n",
    "- ✅ Runtime validation\n",
    "\n",
    "#### Why Code Generation?\n",
    "\n",
    "- ✅ Variables enable composition\n",
    "- ✅ One execution context preserves state\n",
    "- ✅ Natural way to chain operations\n",
    "- ✅ More flexible than rigid tool sequences\n",
    "\n",
    "#### Why Code Calling Tools (not arbitrary code)?\n",
    "\n",
    "- ✅ Tools are vetted and safe\n",
    "- ✅ Limited attack surface\n",
    "- ✅ Balance between flexibility and security\n",
    "- ⚠️ Still needs proper sandboxing for production\n",
    "\n",
    "---\n",
    "\n",
    "### 🚀 Next Steps\n",
    "\n",
    "**Workshop 6:** Memory & Conversations\n",
    "- Agent remembers context across multiple queries\n",
    "- Conversation history management\n",
    "- Long-term memory strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
